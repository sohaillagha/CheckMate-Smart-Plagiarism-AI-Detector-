TypeDis: A Type System for Disentanglement Extended Version ALEXANDRE MOINE, New York University, USA STEPHANIE BALZER, Carnegie Mellon University, USA ALEX XU, Carnegie Mellon University, USA SAM WESTRICK, New York University, USA Disentanglement is a runtime property of parallel programs guaranteeing that parallel tasks remain oblivious to each otherâ€™s allocations. As demonstrated in the MaPLe compiler and run-time system, disentanglement can be exploited for fast automatic memory management, especially task-local garbage collection with no synchronization between parallel tasks. However, as a low-level property, disentanglement can be difficult to reason about for programmers. The only means of statically verifying disentanglement so far has been DisLog, an Iris-fueled variant of separation logic, mechanized in the Rocq proof assistant. DisLog is a fully-featured program logic, allowing for proof of functional correctness as well as verification of disentanglement. Yet its employment requires significant expertise and per-program proof effort. This paper explores the route of automatic verification via a type system, ensuring that any well-typed program is disentangled and lifting the burden of carrying out manual proofs from the programmer. It contributes TypeDis, a type system inspired by region types, where each type is annotated with a timestamp, identifying the task that allocated it. TypeDis supports iso-recursive types as well as polymorphism over both types and timestamps. Crucially, timestamps are allowed to change during type-checking, at join points as well as via a form of subtyping, dubbed subtiming. The paper illustrates TypeDis and its features on a range of examples. The soundness of TypeDis and the examples are mechanized in the Rocq proof assistant, using an improved version of DisLog, dubbed DisLog2. CCS Concepts: â€¢ Software and its engineering â†’Parallel programming languages; â€¢ Theory of computation â†’Type theory; Separation logic. Additional Key Words and Phrases: disentanglement, parallelism, type system, separation logic ACM Reference Format: Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick. 2026. TypeDis: A Type System for Dis- entanglement: Extended Version. Proc. ACM Program. Lang. 10, POPL, Article 13 (January 2026), 34 pages. https://doi.org/10.1145/3776655 1 Introduction A recent line of work has identified a key memory property of parallel programs called disen- tanglement [Acar et al. 2015; Arora et al. 2024, 2021, 2023; Guatto et al. 2018; Moine et al. 2024; Raghunathan et al. 2016; Westrick et al. 2022, 2020]. Roughly speaking, disentanglement is the prop- erty that concurrent tasks remain oblivious to each otherâ€™s memory allocations. As demonstrated by the MaPLe compiler [Acar et al. 2020], this property makes it possible to perform task-local memory management (allocations and garbage collection) independently, in parallel, without any synchronization between concurrent tasks. MaPLe in particular features a provably efficient Authorsâ€™ Contact Information: Alexandre Moine, alexandre.moine@nyu.edu, New York University, New York, USA; Stephanie Balzer, balzers@cs.cmu.edu, Carnegie Mellon University, Pittsburgh, USA; Alex Xu, alexxu@andrew.cmu.edu, Carnegie Mellon University, Pittsburgh, USA; Sam Westrick, shw8119@nyu.edu, New York University, New York, USA. This work is licensed under a Creative Commons Attribution 4.0 International License. Â© 2026 Copyright held by the owner/author(s). ACM 2475-1421/2026/1-ART13 https://doi.org/10.1145/3776655 Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. arXiv:2511.23358v2 [cs.PL] 2 Dec 2025 13:2 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick let r = ref "" let rec write_max x = let current = !r in if x <= current || compare_and_swap r current x then () else write_max x let entangled = par(fun () -> write_max (Int.to_string 1234), fun () -> write_max (Int.to_string 5678)) r â€œâ€ â€œ1234â€ let current = !r in â€¦ â€œ5678â€ task-local heap heap object pointer Fig. 1. Entanglement example memory management system for a dialect of Parallel MLâ€”a parallel functional programming languageâ€”and offers competitive performance in practice relative to low-level parallel code written in languages such as C/C++ [Arora et al. 2023]. This line of work aims to gain control over the synchronization costs of parallel garbage collection by taking advantage of structured fork-join parallelism. The idea is to synchronize the garbage collector only at application-level forks and joins, thereby making these synchronization costs predictable at the source level, and avoiding the need for any global synchronization of the garbage collector. At each fork and join, the runtime system performs ğ‘‚(1) work to maintain a dynamic tree of heaps which mirrors the parent/child relationships between tasks. Each task thus has its own task- local heap, in which it allocates memory objects and may perform garbage collection independently, in parallel. The independence of these task-local garbage collections hinges upon disentanglement, which can be defined as a â€œno cross-pointersâ€ invariant. Specifically, disentanglement allows for up- pointers from descendant heaps to ancestors, as well as down-pointers from ancestors to descendants, but disallows cross-pointers between concurrent tasks (siblings, cousins, etc.). The existence of cross-pointers is called entanglement. When two tasks become entangled with a cross-pointer, neither task can perform garbage collection without synchronizing with the other. These additional synchronizations lead to significant performance degradations [Arora et al. 2023], and in this sense, entanglement is a performance hazard. Entanglement arises from a particular communication pattern, where one task allocates a local heap object and then another task (executing concurrently, relative to the first task) acquires a pointer to the object. An example is shown in Figure 1. The example uses the fork-join primitive par(f1,f2) to execute two functions in parallel; these two function calls correspond to two child tasks. In the example, the two child tasks perform write_max concurrently, both attempting to update r to point to a locally allocated string. After one task finishes, the other task reads the updated r and acquires a cross-pointer, which constitutes entanglement. As shown below, this example could be rewritten to be disentangled by moving the allocations of the strings â€œupâ€ into the parent task (making all pointers involved up-pointers). ... (* same definitions of r and write_max, as in Figure 1 *) ... let disentangled = let a = Int.to_string 1234 in let b = Int.to_string 5678 in par(fun () -> write_max a, fun () -> write_max b) Preventing entanglement. One way to rule out entanglement is to disallow side effects entirely. Indeed, the original study of disentanglement emerged out of an interest in improving the perfor- mance of parallel functional programming techniques, which naturally have a high rate of allocation and whose scalability and efficiency is largely determined by the performance of automatic memory management. In this setting, disentanglement is guaranteed by construction due to a lack of side effects. But the full power of disentanglement lies in its expressivity beyond purely functional programmingâ€”in particular, disentanglement allows for judicious utilization of side effects such as in-place updates and irregular and/or data-dependent access patterns in shared memory. These side Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:3 effects are crucial for efficiency in state-of-the-art implementations of parallel algorithms, such as those in the PBBS Benchmark Suite [Abdi et al. 2024; Anderson et al. 2022; Shun et al. 2012], which have been found to be naturally disentangled [Westrick et al. 2022]. In these more general settings, where there are numerous opportunities to efficiently utilize side effects, it is easy for a programmer to accidentally entangle concurrent tasks. Ideally, it would be evident at the source level where entanglement may or may not occur. However, in practice, this is not the case. To reason about entanglement, the programmer effectively has to know the memory allocation and access patterns of the entire program. This makes it especially difficult to reason about higher-order functions, because the memory effects of a function taken as argument are unknown. Other high-level programming features also complicate the matter, such as parametric polymorphism which allows for code to be specialized for both â€œboxedâ€ (heap-allocated) and â€œunboxedâ€ types, potentially resulting in entanglement in one case but not the other. These details can be formally considered using the program logic DisLog [Moine et al. 2024], but verifying disentanglement using DisLog requires significant expertise and effort, even in small examples. An interesting question therefore is whether it is possible to guarantee disentanglement statically through a type system. This would have the advantage of being mostly automatic, requiring (ideally) only a modest amount of type annotation. Most importantly, a type system would raise the level of abstraction at which the programmer can reason about disentanglement, clarifying how the property interacts with high-level abstractions such as parametric polymorphism, higher-order functions, algebraic datatypes, and other desirable features. A type system for disentanglement. In this paper, we present TypeDis, the first static type sys- tem for disentanglement. We intend for TypeDis to be the type system for a high-level ML-like language with structured fork-join parallelism, in-place atomic operations on shared memory, and disentangled parallel garbage collection. The language features a single parallel construct, written par(ğ‘“1, ğ‘“2), which calls ğ‘“1() and ğ‘“2() in parallel, waits for both to complete, and returns their results as a pair. Here, we think of the execution of the two function calls as two child tasks, which themselves might execute par(...) recursively, creating a dynamic tree (parent-child) relationship between tasks. TypeDis identifies tasks with timestamp variables ğ›¿, and annotates every value computed during execution with the timestamp of the task that allocated that value. This is tracked explicitly in the type of the value. For example, ğ‘ : string@ğ›¿indicates that the value ğ‘ is a string that was allocated by a task ğ›¿. The type system implicitly maintains a partial order over timestamps, written ğ›¿â€² â‰¼ğ›¿, intuitively corresponding to the tree relationship between tasks. Crucially, TypeDis guarantees an invariant that we call the up-pointer invariant: for every task running at timestamp ğ›¿, every value accessed by this task must have a timestamp ğ›¿â€² â‰¼ğ›¿, i.e., the value must have been allocated â€œbeforeâ€ the current timestamp. In other words, the key insight in this paper is to restrict all memory references to point backwards in time, which is checked statically. This restriction is a deep invariant over values: every data structure will only contain values allocated at the same timestamp or a preceding timestamp. As a result, all loads in the language are guaranteed to be safe for disentanglement. The up-pointer invariant statically rules out one feature of disentanglement: down-pointers. This restriction is mild, however, because down-pointers are fairly rare. Quantitatively, there has been at least one relevant study: in their work on entanglement detection, Westrick et al. [2022] observe in multiple benchmarks that down-pointers do not arise at all, and more broadly they measure that the number of objects containing down-pointers is small. The creation of a down-pointer requires a combination of dynamic allocation and pointer indirection, each of which is typically avoided in parallel performance-sensitive code to reduce memory pressure and improve cache efficiency. In this paper, we have found the up-pointer invariant to be sufficiently expressive to encode a number Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:4 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick of interesting examples (Â§6), fully typed within TypeDis, and therefore guaranteed disentangled. The up-pointer invariant is especially well-suited for immutable data (which naturally adheres to the invariant), as well as parallel batch processing of pre-allocated data. The up-pointer invariant also allows for structure sharing, even in the presence of mutable state. Maintaining the up-pointer invariant. To maintain the up-pointer invariant in the presence of mutable state, TypeDis places a restriction on writes (in-place updates), requiring that the timestamp of the written value precedes the timestamp of the reference pointing to it. This restriction is implemented in the type system with a form of subtyping, dubbed subtiming, which affects only the timestamps of values within their types. The idea is to allow for any value to be (conservatively) restamped with a newer timestamp. Subtiming makes it possible to express the restriction on writes as a simple unification over the type of the contents of a mutable reference or array. Restamping with an older timestamp would be unsound in TypeDis, as it would allow for a childâ€™s (heap-allocated) value to be written into a parentâ€™s container, potentially making that value accessible to a concurrent sibling. This is prevented throughout the type system, except in one place: at the join point of par. At this point, the two sub-tasks have completed and their parent inherits the values they allocated. To allow the parent task to access these values, TypeDis restamps the result of par with the timestamp of the parent. We dub this operation backtiming. TypeDis features first-class function types (ğ›¼â†’ğ›¿ğ›½), annotated by a timestamp variable ğ›¿, indicating which task the function may be called by. Timestamp variables can be universally quantified, effectively allowing for timestamp polymorphism. For example, pure functions that have no side-effects are type-able as (âˆ€ğ›¿. ğ›¼â†’ğ›¿ğ›½), indicating that the function may be safely called by any task. TypeDis also allows for constrained timestamp polymorphism. For example, a function of type (âˆ€ğ›¿â€² â‰¼ğ›¿. string@ğ›¿â€² â†’ğ›¿()) only accepts as argument strings timestamped at some ğ›¿â€² that precede the timestamp ğ›¿of the calling task. Typically, such constraints arise from the use of closures, especially those that close over mutable state. Soundness. The soundness of TypeDis is verified in the Rocq prover (the new name of the Coq proof assistant) on top of the Iris higher-order concurrent separation logic framework [Jung et al. 2018b]. We use the approach of semantic typing [Constable et al. 1986; Martin-LÃ¶f 1982; Timany et al. 2024], and define a logical relation targeting a variation of DisLog [Moine et al. 2024], from which we reuse the technical parts. As illustrated by RustBelt [Jung et al. 2018a], semantic typing facilitates manual verification of programs that are correct (e.g. disentangled), but ill-typed, by carrying out a logical relation inhabitation proof using the program logicâ€”overcoming incompleteness inherent to any type system. For example, in the case of TypeDis, this allows the user to verify part of the code that use down-pointers. We note that, similar to many other type systems (such as those in OCaml and Haskell), TypeDis relies on dynamic checks in the operational semantics to enforce memory safety for out-of-bounds (OOB) array accesses. The formal statement of soundness (Â§5.1) therefore explicitly distinguishes between three kinds of program states: those that have terminated, those that can step, and those that are stuck due to OOB. The soundness theorem states that all executions of programs typed within TypeDis always remain disentangled throughout execution. Contributions. Our contributions include: â€¢ TypeDis, the first static type system for disentanglement. It includes the notion of a timestamp to track which object is accessible by which task. TypeDis offers (iso-)recursive types as well as polymorphism over types and over timestamps. Moreover, TypeDis supports polymorphic recursion over timestamps, and offers a relaxation of the value restriction. Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:5 â€¢ Two mechanisms to update a timestamp annotation: via subtiming, a form of subtyping, and specifically at join points via the new operation of backtiming. â€¢ A new model for disentanglement with cyclic computation graphs. We prove this model equivalent to the standard one and explain why it is more amenable to verification. â€¢ A soundness proof of TypeDis mechanized in the Rocq prover using the Iris framework. We use semantic typing [Timany et al. 2024] and DisLog2, an improved version of DisLog. â€¢ A range of case studies, including building and iterating over an immutable tree in parallel, as well the challenging example of deduplication via concurrent hashing. 2 Key Ideas In this section, we cover the key ideas of our work. We start by recalling the definition of disen- tanglement (Â§2.1). We then present the main idea of TypeDis: adding task identifiers, specifically timestamp variables, to types (Â§2.2). Based on examples, we then illustrate two core principles of TypeDis, allowing for updating timestamps within types: backtiming (Â§2.3) and subtiming (Â§2.4). 2.1 Preliminaries Nested fork-join parallelism and task trees. We consider programs written in terms of a single parallel primitive: par(ğ‘“1, ğ‘“2), which creates two new child tasks ğ‘“1() and ğ‘“2() to execute in parallel, waits for both of the child tasks to complete, and then returns the results of the two calls as an immutable pair. Creating the two child tasks is called a fork, and waiting for the two children to complete is called a join. The behavior of the par primitive guarantees that every fork has a corresponding join. Any task may (recursively) fork and join, facilitating nested parallelism and giving rise to a dynamic tree during execution called the task tree. The nodes of the task tree correspond to (parent) tasks that are waiting for their children to join, and the leaves of the task tree correspond to tasks which may actively take a step. Whenever two sibling tasks join, the children are removed from the tree and the parent resumes as a leaf task. The task tree therefore dynamically grows and shrinks as tasks fork and join. In this paper, we will use the letter ğ‘¡to denote tasks (leaves of the task tree), and will equivalently refer to these as timestamps. Computation graphs. The evolution of the task tree over time can be recorded as a computation graph, where vertices correspond to tasks and edges correspond to scheduling dependencies. The computation graph records not just the current task tree, but also the history of tasks that have joined. When a task ğ‘¡forks into two children ğ‘¡1 and ğ‘¡2, two edges (ğ‘¡,ğ‘¡1) and (ğ‘¡,ğ‘¡2) are added to the graph; later when ğ‘¡1 and ğ‘¡2 join, two edges (ğ‘¡1,ğ‘¡) and (ğ‘¡2,ğ‘¡) are added to the graph. We say that ğ‘¡precedes ğ‘¡â€² in graph ğºand write ğºâŠ¢ğ‘¡â‰¼ğ‘¡â€², when there exists a sequence of edges from ğ‘¡to ğ‘¡â€². Note that â‰¼is reflexive. Two tasks are concurrent when neither precedes the other. Cyclic versus standard computation graphs. We contribute a new definition of computation graphs, which we call the cyclic approach, that differs slightly from the standard presentation used in prior work [Acar et al. 2016; Moine et al. 2024; Westrick et al. 2020]. The standard approach is to use a fresh task identifier at each join point, effectively renaming the resumed parent task. In the cyclic approach, we instead use the same task identifier after the join point. Figure 2 illustrates the difference between the two approaches. It presents two computation graphs representing the same computation: Figure 2a shows the standard approach, and Figure 2b shows the (new) cyclic approach. The distinction occurs when two tasks join. In Figure 2a tasks ğ‘¡3 and ğ‘¡4 join and form a new task ğ‘¡â€² 2 whereas in Figure 2b the two tasks join by going back to task ğ‘¡2. This distinction occurs again when ğ‘¡â€² 2 (resp. ğ‘¡2) join to form ğ‘¡â€² 0 (resp. ğ‘¡0). The cyclic approach considerably reduces the need to manipulate timestamps, not only in our proofs (for example the soundness proof of backtiming), but also in the design of the type system Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:6 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick ğ‘¡0 ğ‘¡1 ğ‘¡2 ğ‘¡3 ğ‘¡4 ğ‘¡â€² 2 ğ‘¡â€² 0 ğ‘¡5 ğ‘¡6 (a) Standard computation graph ğ‘¡0 ğ‘¡1 ğ‘¡2 ğ‘¡3 ğ‘¡4 ğ‘¡5 ğ‘¡6 (b) Equivalent â€œcyclicâ€ approach used in this paper Fig. 2. Comparison of two computation graphs equivalent for disentanglement itself as well as in the underlying program logic (Â§5.3). We prove the two approaches equivalent for the purpose of verifying disentanglement [Moine et al. 2025]. Intuitively, the two approaches are equivalent because we never need to check reachability between two tasks that have both completed. We have formally proven this equivalence with a simulation theorem: every reduction in the semantics with the standard approach implies the existence of a reduction with the same scheduling reaching the same expression in the semantics with the cyclic approach, and vice-versa. Moreover, if one state is disentangled in one semantics, so it is in the other. Roots. At any moment, every task has a set of task-local roots which are the memory locations directly mentioned within a subexpression of that task. For example, the expression â€˜letğ‘¥= (â„“1, â„“2) in fst(ğ‘¥)â€™ has roots {â„“1, â„“2}, where (formally) â„“1 and â„“2 are locations within the memory store. Note that the roots of a task change over time: for example, the above expression eventually steps to â„“1 at which point it only has one root, {â„“1}. The set of roots can grow due to allocations and loads from memory. Disentanglement. Disentanglement restricts the set of possible task-local roots. A program state is disentangled if each root of a task has been allocated by some preceding task. More precisely, a program state with a computation graph ğºis disentangled if, for a root â„“of a task ğ‘¡, â„“ has been allocated by a task ğ‘¡â€² such that ğºâŠ¢ğ‘¡â€² â‰¼ğ‘¡, that is, such that ğ‘¡â€² precedes ğ‘¡in ğº. Following the computation graph definition, preceding tasks include ğ‘¡itself, parent tasks, but also children tasks that have terminated. The formal definition of disentanglement appears in Section 3.3. TypeDis, the type system we present, verifies that a program is disentangled, that is, every reachable program state is disentangled. 2.2 TypeDis 101: Timestamps in Types In order to keep track of which task allocated which location, TypeDis incorporates timestamps in types. More precisely, every heap-allocated (â€œboxedâ€) type is annotated by a timestamp variable, written ğ›¿, which can be understood as the timestamp of the task that allocated the underlying location. For example, a reference allocated by task ğ›¿on an (unboxed) integer has type ref(int)@ğ›¿. Timestamp polymorphism. Functions in TypeDis are annotated by a timestamp variable, re- stricting which task they may run on. Such a variable can be universally quantified, allowing for functions to be run by different tasks. For example, consider the function fun x -> newref(x) which allocates a new mutable reference containing an integer x. This function can be given the type âˆ€ğ›¿. int â†’ğ›¿ref(int)@ğ›¿. The superscript ğ›¿on the arrow indicates that the function must run on a task at timestamp ğ›¿, and the result type ref(int)@ğ›¿indicates that the resulting reference will be allocated at the same timestamp ğ›¿. By universally quantifying ğ›¿, the function is permitted to run on any task, with the type system tracking that the resulting reference will be allocated at the same timestamp as the caller. Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:7 newref : âˆ€ğ›¼. âˆ€ğ›¿. ğ›¼â†’ğ›¿ref(ğ›¼)@ğ›¿ get : âˆ€ğ›¼. âˆ€ğ›¿ğ›¿â€². ref(ğ›¼)@ğ›¿â€² â†’ğ›¿ğ›¼ set : âˆ€ğ›¼. âˆ€ğ›¿ğ›¿â€². ref(ğ›¼)@ğ›¿â€² â†’ğ›¼â†’ğ›¿() Fig. 3. Example: typing reference primitives let r = newref "hello" ğ‘Ÿ: ref(string@ğ›¿0)@ğ›¿0 let w = "world" ğ‘¤: string@ğ›¿0 let f () = set r w ğ‘“: (âˆ€ğ›¿. () â†’ğ›¿())@ğ›¿0 let g i = ğ‘”: (int â†’ğ›¿0 ())@ğ›¿0 set r (Int.to_string i) Fig. 4. Example: typing closures type tree@ğ›¿= ( int + (tree@ğ›¿Ã— tree@ğ›¿)@ğ›¿)@ğ›¿ let leaf x = inj1 x leaf : (âˆ€ğ›¿. int â†’ğ›¿tree@ğ›¿)@ğ›¿0 let node x y = inj2 (x,y) node : (âˆ€ğ›¿. tree@ğ›¿â†’tree@ğ›¿â†’ğ›¿tree@ğ›¿)@ğ›¿0 let rec build n x = build : (âˆ€ğ›¿. int â†’int â†’ğ›¿tree@ğ›¿)@ğ›¿0 if n <= 0 then leaf x else let n' = n - 1 in let (l,r) = par (fun () -> build n' x) (fun () -> build n' (x + pow2 n')) in node l r Fig. 5. Example: building a tree in parallel Type polymorphism. TypeDis allows type variables ğ›¼to be universally quantified. Using type poly- morphism, we can now give the function fun x -> newref(x) the more general type âˆ€ğ›¼.âˆ€ğ›¿. ğ›¼â†’ğ›¿ ref(ğ›¼)@ğ›¿, indicating that it is polymorphic in the type ğ›¼of the contents of the mutable reference. Corresponding get and set primitives for mutable references are then typed as shown in Figure 3, all of which are polymorphic in the type variable ğ›¼. For functions with multiple arguments, such as set, we adopt the notational convention to only specify the timestamp variable on the last arrow. The up-pointer invariant. In Figure 3, the type of get is given as âˆ€ğ›¼. âˆ€ğ›¿ğ›¿â€². ref(ğ›¼)@ğ›¿â€² â†’ğ›¿ğ›¼. Note that this type is parameterized over both a caller time ğ›¿as well as a (potentially different) timestamp ğ›¿â€² associated with the input reference. Intuitively, this type specifies that get is safe to call at any moment, by any task, with any reference given as argument. The design of TypeDis in general guarantees that all loads from memory, both mutable and immutable, are always safe. Specifically, this is guaranteed by enforcing an invariant that we call the up-pointer invariant: all data structures in the language may only contain values allocated at the same timestamp or a preceding timestamp. For example, given two non-equal timestamps ğ›¿1 and ğ›¿2 where ğ›¿1 â‰ºğ›¿2, the type ref(ref(int)@ğ›¿1)@ğ›¿2 is valid, but ref(ref(int)@ğ›¿2)@ğ›¿1 is not. Closures. In TypeDis, functions are first-class values and may be passed as arguments to other functions, or stored in data structures, etc. Function values are implemented as heap-allocated closures [Appel 1992; Landin 1964], and must be given a timestamp indicating when they were allocated. For example, consider the definition of function ğ‘“in Figure 4, which closes over a mutable reference ğ‘Ÿand an immutable string ğ‘¤, both allocated at timestamps ğ›¿0 which (in this example) is the timestamp of the current task. We can give ğ‘“the type (âˆ€ğ›¿. () â†’ğ›¿())@ğ›¿0, indicating that ğ‘“ itself was allocated at timestamp ğ›¿0. Additionally, the type of ğ‘“specifies that it may be freely called at any timestamp; this is safe for disentanglement because ğ‘“preserves the up-pointer invariant, regardless of when it will be called. Contrast this with the definition of function ğ‘”, which (when called) allocates a new string and writes this string into the reference ğ‘Ÿ. If ğ‘”were called at some timestamp ğ›¿1 where ğ›¿0 â‰ºğ›¿1, then this would violate the up-pointer invariant for ğ‘Ÿ. The function ğ‘” does however admit the type (int â†’ğ›¿0 ())@ğ›¿0, indicating that ğ‘”may be safely called only by tasks at time ğ›¿0 (the same timestamp as the reference ğ‘Ÿ). 2.3 Backtiming the Result of a par As explained earlier (Â§2.1), we consider in this paper the parallel primitive par(...), which executes two closures in parallel and returns their result as an immutable pair. The par primitive can be Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:8 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick let rec selectmap p f t = selectmap : (âˆ€ğ›¿ğ›¿ğ‘ğ›¿ğ‘“ğ›¿ğ‘¡. (âˆ€ğ›¿â€². int â†’ğ›¿â€² bool)@ğ›¿ğ‘ match t with â†’(âˆ€ğ›¿â€². int â†’ğ›¿â€² int)@ğ›¿ğ‘“ | inj1 x -> if p x then leaf (f x) else t â†’tree@ğ›¿ğ‘¡â†’ğ›¿tree@ğ›¿)@ğ›¿0 | inj2 (l,r) -> let (nl,nr) = par (fun () -> selectmap p f l) (fun () -> selectmap p f r) in if nl == l && nr == r then t else node nl nr Fig. 6. Example: the selectmap function used to build data structures in parallel. Consider the code presented in Figure 5. The recursive type tree@ğ›¿= ( int + (tree@ğ›¿Ã— tree@ğ›¿)@ğ›¿)@ğ›¿describes a binary tree with integer leaves. It consists of an immutable sum of either an integer (a leaf) or a product of two subtrees (a node). All the parts of a tree are specified in the type to have been allocated at the same timestamp ğ›¿. A leaf is built with the first injection, and a node with the second injection. The function build n x builds in parallel a binary tree of depth ğ‘›, with leaves labeled from ğ‘¥to ğ‘¥+ 2ğ‘›âˆ’1 in left-to-right order. TypeDis type-checks build with the type âˆ€ğ›¿. int â†’int â†’ğ›¿tree@ğ›¿. The reader may be surprised: we announced that the type tree@ğ›¿has all of its parts allocated at the same timestamp ğ›¿, but we are showing a function that builds a tree in parallel, hence with some parts allocated by different tasks at different timestamps. Whatâ€™s the trick? The key observation is that we can pretend that the objects allocated by a completed sub-task were instead allocated by its parent. Indeed, disentanglement prevents sharing of data allocated in parallel, but as soon as the parallel phase has ended, there is no restriction anymore! In TypeDis, the par primitive implements backtiming, meaning that it replaces the timestamp of the child task by the timestamp of the parent task in the return type of the closures executed in parallel. Indeed, the par primitive admits the following, specialized for build, type: âˆ€ğ›¿ğ›¿ğ‘™ğ›¿ğ‘Ÿ. (âˆ€ğ›¿â€². () â†’ğ›¿â€² tree@ğ›¿â€²)@ğ›¿ğ‘™â†’(âˆ€ğ›¿â€². () â†’ğ›¿â€² tree@ğ›¿â€²)@ğ›¿ğ‘Ÿâ†’ğ›¿(tree@ğ›¿Ã— tree@ğ›¿)@ğ›¿ This type for par does exactly what we need: it returns the result of the two closures in a pair as if they were called at time ğ›¿. Backtiming is a powerful feature: it reduces parallelism to almost an implementation detail. Indeed, the type of build does not reveal its internal use of parallelism. 2.4 Making Something New out of Something Old with Subtiming A common practice (especially in functional programming) is data structural sharing, where components of an old structure are reused inside part of a new structure. In the context of TypeDis, data structural sharing is interesting in that it mixes data of potentially different timestamps within the same structure. Here we consider one such example and describe a key feature of TypeDis which enables such â€œmixingâ€ of timestamps. Figure 6 presents the selectmap p f t function, which selectively applies the function f to the leaves of the tree t, following a predicate p on integers. The selectmap function traverses the tree in parallel and crucially preserves sharing as much as possible. Specifically, when none of the leaves of the tree satisfy the predicate, the function returns the original input tree as-is, instead of building another identical tree. To type this function in TypeDis, it may not be immediately clear what the timestamp of the resulting tree should be: selectmap might directly return the argument passed as argument (potentially coming from an older task), or it might return a new tree. TypeDis type-checks selectmap with the type âˆ€ğ›¿ğ›¿ğ‘ğ›¿ğ‘“ğ›¿ğ‘¡. (âˆ€ğ›¿â€². int â†’ğ›¿â€² bool)@ğ›¿ğ‘â†’(âˆ€ğ›¿â€². int â†’ğ›¿â€² int)@ğ›¿ğ‘“â†’tree@ğ›¿ğ‘¡â†’ğ›¿tree@ğ›¿ This type universally quantifies over ğ›¿(the timestamp at which selectmap will run), ğ›¿ğ‘and ğ›¿ğ‘“(the timestamps of the two closure arguments), and ğ›¿ğ‘¡(the timestamp of the tree argument). Crucially, the result is of type tree@ğ›¿, as if the whole result tree was allocated by ğ›¿. Whatâ€™s the trick? Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:9 Values ğ‘£,ğ‘¤::= () | ğ‘âˆˆ{true, false} | ğ‘–âˆˆZ | â„“âˆˆL | vfoldğ‘£ Blocks ğ‘Ÿ::= Â®ğ‘¤| (ğ‘£, ğ‘£) | injğœ„âˆˆ{0,1} ğ‘£| Ë†ğœ‡ğ‘“. ğœ†Â®ğ‘¥.ğ‘’ Primitives âŠ²âŠ³::= + | âˆ’| Ã— | Ã· | mod | == | < | â‰¤| > | â‰¥| âˆ¨| âˆ§ Expressions ğ‘’::= ğ‘£| ğ‘¥âˆˆV | letğ‘¥= ğ‘’inğ‘’| ifğ‘’thenğ‘’elseğ‘’| ğ‘’âŠ²âŠ³ğ‘’ | ğœ‡ğ‘“. ğœ†Â®ğ‘¥.ğ‘’| ğ‘’Â®ğ‘’ closures | (ğ‘’,ğ‘’) | projğœ„âˆˆ{1,2} ğ‘’ pairs | injğ‘–âˆˆ{1,2} ğ‘’| matchğ‘’with inj1 ğ‘¥â‡’ğ‘’| inj2 ğ‘¥â‡’ğ‘’end sums | alloc ğ‘’ğ‘’| ğ‘’.[ğ‘’] | ğ‘’.[ğ‘’] â†ğ‘’| lengthğ‘’ arrays | foldğ‘’| unfoldğ‘’ iso-recursive types | par(ğ‘’,ğ‘’) | ğ‘’âˆ¥ğ‘’| CASğ‘’ğ‘’ğ‘’ğ‘’ parallelism and concurrency Contexts ğ¾::= letğ‘¥= â–¡inğ‘’ | if â–¡thenğ‘’elseğ‘’ | alloc â–¡ğ‘’ | alloc ğ‘£â–¡ | length â–¡ | â–¡.[ğ‘’] | ğ‘£.[â–¡] | â–¡.[ğ‘’] â†ğ‘’ | ğ‘£.[â–¡] â†ğ‘’ | ğ‘£.[ğ‘£] â†â–¡ | â–¡âŠ²âŠ³ğ‘’ | ğ‘£âŠ²âŠ³â–¡ | â–¡Â®ğ‘’ | ğ‘£(Â®ğ‘£++ â–¡++ Â®ğ‘’) | fold â–¡ | unfold â–¡ | (â–¡,ğ‘’) | (ğ‘£, â–¡) | projğœ„â–¡ | injğ‘–â–¡ | match â–¡with inj1 ğ‘¥â‡’ğ‘’| inj2 ğ‘¥â‡’ğ‘’end | par(â–¡,ğ‘’) | par(ğ‘£, â–¡) | CAS â–¡ğ‘’ğ‘’ğ‘’ | CASğ‘£â–¡ğ‘’ğ‘’ | CASğ‘£ğ‘£â–¡ğ‘’ | CASğ‘£ğ‘£ğ‘£â–¡ Fig. 7. Syntax of DisLang2. Constructs in blue are runtime-level. TypeDis supports subtiming, that is, a way of â€œadvancingâ€ timestamps within a type, following the precedence. The rules of subtiming are as follows. For a mutable type (e.g. an array or a reference), subtiming is shallow: the outermost timestamp can be updated, but not the inner timestamps; this is due to well-known variance issues [Pierce 2002, Â§15]. For an immutable type (e.g. products and sums), subtiming is deep: any timestamp within the type can be advanced, as long as the up-pointer invariant is preserved. For selectmap, we need to use deep subtiming on the recursive immutable type tree@ğ›¿ğ‘¡in order to update it to tree@ğ›¿. How can we be sure that ğ›¿ğ‘¡, the timestamp of the tree, precedes ğ›¿, the timestamp at which we call selectmap? We unveil a key invariant of TypeDis: every timestamp of every memory location in scope precedes the â€œcurrentâ€ timestamp, that is, the timestamp of the task executing the function. In our case the current timestamp is precisely ğ›¿. We hence deduce that ğ›¿ğ‘¡precedes ğ›¿, allowing us to use subtiming to â€œrestampâ€ the value ğ‘¡: tree@ğ›¿ğ‘¡as ğ‘¡: tree@ğ›¿. To allow the user to express additional knowledge about the dependencies between timestamps, TypeDis annotates universal timestamp quantification with a set of constraints, which are supposed to hold while typing the function body, and are verified at call sites. For example, the following function let par' f g = ignore (par f g) that executes two closures f and g from unit to unit in parallel and ignores the result can be given the type: âˆ€ğ›¿ğ›¿1 ğ›¿2. (âˆ€ğ›¿â€² ğ›¿â‰¼ğ›¿â€². () â†’ğ›¿â€² ())@ğ›¿1 â†’(âˆ€ğ›¿â€² ğ›¿â‰¼ğ›¿â€². () â†’ğ›¿â€² ())@ğ›¿2 â†’ğ›¿() This type says that, if par' gets called at timestamp ğ›¿with arguments ğ‘“and ğ‘”, then ğ‘“and ğ‘”can assume that they will be called at timestamp ğ›¿â€² such that ğ›¿â‰¼ğ›¿â€². These constraints are discussed in Section 4, and the fully general type of par is presented in Section 4.6. 3 Syntax and Semantics The formal language we study, dubbed DisLang2, can be understood as an extension of DisLang, the language studied by Moine et al. [2024]. DisLang2 adds support for immutable pairs and sums, iso-recursive types, and directly offers the par primitive for fork-join parallelism. We present the syntax of DisLang2 (Â§3.1), its semantics (Â§3.2), and the formal definition of disentanglement (Â§3.3). Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:10 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick 3.1 Syntax The syntax of DisLang2 appears in Figure 7. The constructs in blue are forbidden in the source program and occur only at runtime. A value ğ‘£âˆˆV can be the unit value (), a boolean ğ‘âˆˆ{true, false}, an idealized integer ğ‘–âˆˆZ, a memory location â„“âˆˆL, where L is an infinite set of locations, or a folded value vfoldğ‘£, witnessing our use of iso-recursive types [Pierce 2002, Â§20]. A block describes the contents of a heap cell, amounting to either an array of values, written Â®ğ‘¤, an immutable pair (ğ‘£, ğ‘£), the first injection inj1 ğ‘£or the second injection inj2 ğ‘£of an immutable sum, or a ğœ†-abstraction Ë†ğœ‡ğ‘“. ğœ†Â®ğ‘¥.ğ‘’. Lambdas can close over free variables, compilers of functional languages usually implement them as closures [Appel 1992; Landin 1964]. A closure is a heap-allocated object carrying a code pointer as well as an environment, recording the values of the free variable. Thus, acquiring a closure can create entanglement. Moreover, because functions and tuples are heap allocated, currying and uncurryingâ€”that is, converting a function taking multiple arguments to a function taking a tuple of arguments and vice-versaâ€”does not come for free. Hence, we chose to support a version of the language were every function takes possibly multiple arguments. Closure allocation is written ğœ‡ğ‘“. ğœ†Â®ğ‘¥.ğ‘’. This notation binds a recursive name ğ‘“, argument names Â®ğ‘¥in the expression ğ‘’. A function call is written ğ‘’Â®ğ‘’. In DisLang2, fork-join parallelism is available via the parallel primitive par(ğ‘’1,ğ‘’2), which re- duces ğ‘’1 and ğ‘’2 to closures, calls them in parallel, and returns their result as an immutable pair. This parallel computation is represented by the active parallel pair ğ‘’1 âˆ¥ğ‘’2, appearing only at runtime. DisLang2 supports a compare-and-swap instruction CASğ‘’ğ‘’ğ‘’ğ‘’, which targets an array, and is parameterized by 4 arguments: the location of the array, the index in the array, the old value and the new value. A (sequential) evaluation context ğ¾describes a term with a hole, written â–¡. The syntax of evaluation contexts dictates a left-to-right call-by-value evaluation strategy. Note that evaluation contexts ğ¾in this presentation are sequential. Specifically, we intentionally excluded active parallel pairs (âˆ’âˆ¥âˆ’) from the grammar of ğ¾. The evaluation strategy for active parallel pairs allows for interleaving of small steps, which is handled separately by a â€œscheduler reductionâ€ relation in the operational semantics (Â§3.2). 3.2 Operational Semantics Head reduction relation. A head configuration ğœ\ğ›¼\ğ‘’is composed of a store ğœ, an allocation map ğ›¼, and an expression ğ‘’. The store ğœrepresents the heap and consists of a finite map of locations to blocks. The allocation map ğ›¼is a finite map of locations to timestamps, recording the timestamps at which locations were allocated. Figure 8 presents parts of the definition of the head reduction relation between two head configurations ğº,ğ‘¡âŠ¢ğœ\ğ›¼\ğ‘’âˆ’â†’ğœâ€² \ğ›¼â€² \ğ‘’â€² occurring at the (local) task of timestamp ğ‘¡in the (global) computation graph ğº. A head configuration consists of the expression ğ‘’being evaluated, the store ğœ, and an allocation map ğ›¼. Figure 8 omits rules for the length array primitive as well as the atomic compare-and-swap on arrays. We write ğœ(â„“) to denote the block stored at the location â„“in the store ğœ. We write [â„“:= ğ‘Ÿ]ğœfor the insertion of block ğ‘Ÿat location â„“in ğœ. Note that only arrays can be updated; closures, pairs and sums are immutable. We write Â®ğ‘¤(ğ‘–) to refer to the index ğ‘–of an array Â®ğ‘¤. We write [ğ‘–:= ğ‘£] Â®ğ‘¤for an update to an array, and we similarly write [â„“:= ğ‘¡]ğ›¼for an insertion in the allocation map. We write ğ‘£ğ‘›for an array of length ğ‘›, where each element of the array is initialized with the value ğ‘£. HeadAlloc allocates an array, extending the store and the allocation map. HeadLoad acquires the value ğ‘£from an index of an array. HeadStore, HeadLetVal, HeadIfTrue and HeadIfFalse are standard. HeadClosure allocates a closure and HeadCall calls a closure. HeadCallPrim calls a primitive, whose result is computed at the meta-level by the pure âˆ’âˆ’âˆ’â†’relation. HeadPair and Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:11 HeadAlloc 0 < ğ‘› â„“âˆ‰dom(ğœ) â„“âˆ‰dom(ğ›¼) ğº,ğ‘¡âŠ¢ğœ\ğ›¼\alloc ğ‘›ğ‘£âˆ’â†’[â„“:= ğ‘£ğ‘›]ğœ\ [â„“:= ğ‘¡]ğ›¼\â„“ HeadLoad ğœ(â„“) = Â®ğ‘¤ 0 â‰¤ğ‘–< | Â®ğ‘¤| Â®ğ‘¤(ğ‘–) = ğ‘£ ğº,ğ‘¡âŠ¢ğœ\ğ›¼\â„“.[ğ‘–] âˆ’â†’ğœ\ğ›¼\ğ‘£ HeadStore ğœ(â„“) = Â®ğ‘¤ 0 â‰¤ğ‘–< | Â®ğ‘¤| ğº,ğ‘¡âŠ¢ğœ\ğ›¼\â„“.[ğ‘–] â†ğ‘£âˆ’â†’[â„“:= [ğ‘–:= ğ‘£] Â®ğ‘¤]ğœ\ğ›¼\ () HeadLetVal ğº,ğ‘¡âŠ¢ğœ\ğ›¼\letğ‘¥= ğ‘£inğ‘’âˆ’â†’ğœ\ğ›¼\ [ğ‘£/ğ‘¥]ğ‘’ HeadIfTrue ğº,ğ‘¡âŠ¢ğœ\ğ›¼\if true thenğ‘’1 elseğ‘’2 âˆ’â†’ğœ\ğ›¼\ğ‘’1 HeadIfFalse ğº,ğ‘¡âŠ¢ğœ\ğ›¼\if false thenğ‘’1 elseğ‘’2 âˆ’â†’ğœ\ğ›¼\ğ‘’2 HeadClosure â„“âˆ‰dom(ğœ) â„“âˆ‰dom(ğ›¼) ğº,ğ‘¡âŠ¢ğœ\ğ›¼\ Ë†ğœ‡ğ‘“. ğœ†Â®ğ‘¥.ğ‘’âˆ’â†’[â„“:= Ë†ğœ‡ğ‘“. ğœ†Â®ğ‘¥.ğ‘’]ğœ\ [â„“:= ğ‘¡]ğ›¼\â„“ HeadCall ğœ(â„“) = Ë†ğœ‡ğ‘“. ğœ†Â®ğ‘¥.ğ‘’ |Â®ğ‘¥| = | Â®ğ‘¤| ğº,ğ‘¡âŠ¢ğœ\ğ›¼\â„“Â®ğ‘¤âˆ’â†’ğœ\ğ›¼\ [â„“/ğ‘“][ Â®ğ‘¤/Â®ğ‘¥]ğ‘’ HeadCallPrim ğ‘£1 âŠ²âŠ³ğ‘£2 pure âˆ’âˆ’âˆ’â†’ğ‘£ ğº,ğ‘¡âŠ¢ğœ\ğ›¼\ğ‘£1 âŠ²âŠ³ğ‘£2 âˆ’â†’ğœ\ğ›¼\ğ‘£ HeadPair â„“âˆ‰dom(ğœ) â„“âˆ‰dom(ğ›¼) ğº,ğ‘¡âŠ¢ğœ\ğ›¼\ (ğ‘£1, ğ‘£2) âˆ’â†’[â„“:= (ğ‘£1, ğ‘£2)]ğœ\ [â„“:= ğ‘¡]ğ›¼\â„“ HeadProj ğœ(â„“) = (ğ‘£1, ğ‘£2) ğº,ğ‘¡âŠ¢ğœ\ğ›¼\projğœ„â„“âˆ’â†’ğœ\ğ›¼\ğ‘£ğœ„ HeadInj â„“âˆ‰dom(ğœ) â„“âˆ‰dom(ğ›¼) ğº,ğ‘¡âŠ¢ğœ\ğ›¼\injğ‘–ğ‘£âˆ’â†’[â„“:= injğ‘–ğ‘£]ğœ\ [â„“:= ğ‘¡]ğ›¼\â„“ HeadCase ğœ(â„“) = injğœ„ğ‘£ ğº,ğ‘¡âŠ¢ğœ\ğ›¼\ (match â„“with inj1 ğ‘¥1 â‡’ğ‘’1 | inj2 ğ‘¥2 â‡’ğ‘’2 end) âˆ’â†’ğœ\ğ›¼\ [ğ‘£/ğ‘¥ğœ„]ğ‘’ğœ„ HeadFold ğº,ğ‘¡âŠ¢ğœ\ğ›¼\foldğ‘£âˆ’â†’ğœ\ğ›¼\vfoldğ‘£ HeadUnfold ğº,ğ‘¡âŠ¢ğœ\ğ›¼\unfold (vfoldğ‘£) âˆ’â†’ğœ\ğ›¼\ğ‘£ Fig. 8. Head reduction (selected rules) HeadProj allocate and project immutable pairs, respectively. HeadInj and HeadCase allocate and case over immutable sums, respectively. HeadFold and HeadUnfold handle iso-recursive types in a standard way. Scheduler reduction relation. In order to keep track of the timestamp of each task and whether the task is activated or suspended, we follow Westrick et al. [2020] and enrich the semantics with an aux- iliary structure called a task tree, written ğ‘‡, of the following formal grammar: ğ‘‡â‰œğ‘¡âˆˆT | ğ‘‡âŠ—ğ‘¡ğ‘‡. A leaf ğ‘¡indicates an active task denoted by its timestamp. A node ğ‘‡1 âŠ—ğ‘¡ğ‘‡2 represents a suspended task ğ‘¡that has forked two parallel computations, recursively described by the task trees ğ‘‡1 and ğ‘‡2. Figure 9 presents the scheduling reduction relation ğœ/ğ›¼/ğº/ğ‘‡/ğ‘’ sched âˆ’âˆ’âˆ’âˆ’â†’ğœâ€² /ğ›¼â€² /ğºâ€² /ğ‘‡â€² /ğ‘’â€² as either a head step, a fork, or a join. In this reduction relation, ğœis a store, ğ›¼an allocation map, ğº a computation graph, ğ‘‡a task tree, and ğ‘’an expression. SchedHead reduction describes a head reduction. SchedFork reduction describes a fork: the task tree consists of a leaf ğ‘¡and the ex- pression par(ğ‘£1, ğ‘£2), where both ğ‘£1 and ğ‘£2 are closures to be executed in parallel. The reduction generates two fresh timestamps ğ‘¡1 and ğ‘¡2, adds the corresponding edges to the computation graph, and updates the task tree to comprise the node with two leaves ğ‘¡1 âŠ—ğ‘¡ğ‘¡2. The reduction then updates the expression to the active parallel pair ğ‘£1 [()] âˆ¥ğ‘£2 [()], reflecting the parallel call of the two closures ğ‘£1 and ğ‘£2, each one called with a single argument, the unit value (). SchedJoin reduction describes a join and differs from prior semantics for disentanglement [Moine et al. 2024; Westrick et al. 2022] because it reuses a timestamp (Â§2.1). The task tree is at a node ğ‘¡with two leaves ğ‘¡1 âŠ—ğ‘¡ğ‘¡2, and both leaves reached a value. The reduction adds edges (ğ‘¡1,ğ‘¡) and (ğ‘¡2,ğ‘¡) to the computation Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:12 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick SchedHead ğº,ğ‘¡âŠ¢ğœ\ğ›¼\ğ‘’âˆ’â†’ğœâ€² \ğ›¼â€² \ğ‘’â€² ğœ/ğ›¼/ğº/ğ‘¡/ğ‘’ sched âˆ’âˆ’âˆ’âˆ’â†’ğœâ€² /ğ›¼â€² /ğº/ğ‘¡/ğ‘’â€² SchedFork ğ‘¡1,ğ‘¡2 âˆ‰vertices(ğº) ğºâ€² = ğºâˆª{(ğ‘¡,ğ‘¡1), (ğ‘¡,ğ‘¡2)} ğ‘’â€² = ğ‘£1 [()] âˆ¥ğ‘£2 [()] ğœ/ğ›¼/ğº/ğ‘¡/par(ğ‘£1, ğ‘£2) sched âˆ’âˆ’âˆ’âˆ’â†’ğœ/ğ›¼/ğºâ€² /ğ‘¡1 âŠ—ğ‘¡ğ‘¡2 /ğ‘’â€² SchedJoin â„“âˆ‰dom(ğœ) â„“âˆ‰dom(ğ›¼) ğºâ€² = ğºâˆª{(ğ‘¡1,ğ‘¡), (ğ‘¡2,ğ‘¡)} ğœ/ğ›¼/ğº/ğ‘¡1 âŠ—ğ‘¡ğ‘¡2 /ğ‘£1 âˆ¥ğ‘£2 sched âˆ’âˆ’âˆ’âˆ’â†’[â„“:= (ğ‘£1, ğ‘£2)]ğœ/ [â„“:= ğ‘¡]ğ›¼/ğºâ€² /ğ‘¡/â„“ StepSched ğœ/ğ›¼/ğº/ğ‘‡/ğ‘’ sched âˆ’âˆ’âˆ’âˆ’â†’ğœâ€² /ğ›¼â€² /ğºâ€² /ğ‘‡â€² /ğ‘’â€² (ğœ, ğ›¼,ğº) /ğ‘‡/ğ‘’ step âˆ’âˆ’âˆ’â†’(ğœâ€², ğ›¼â€²,ğºâ€²) /ğ‘‡â€² /ğ‘’â€² StepBind ğ‘†/ğ‘‡/ğ‘’ step âˆ’âˆ’âˆ’â†’ğ‘†â€² /ğ‘‡â€² /ğ‘’â€² ğ‘†/ğ‘‡/ğ¾[ğ‘’] step âˆ’âˆ’âˆ’â†’ğ‘†â€² /ğ‘‡â€² /ğ¾[ğ‘’â€²] StepParL ğ‘†/ğ‘‡1 /ğ‘’1 step âˆ’âˆ’âˆ’â†’ğ‘†â€² /ğ‘‡â€² 1 /ğ‘’â€² 1 ğ‘†/ğ‘‡1 âŠ—ğ‘¡ğ‘‡2 /ğ‘’1 âˆ¥ğ‘’2 step âˆ’âˆ’âˆ’â†’ğ‘†â€² /ğ‘‡â€² 1 âŠ—ğ‘¡ğ‘‡2 /ğ‘’â€² 1 âˆ¥ğ‘’2 StepParR ğ‘†/ğ‘‡2 /ğ‘’2 step âˆ’âˆ’âˆ’â†’ğ‘†â€² /ğ‘‡â€² 2 /ğ‘’â€² 2 ğ‘†/ğ‘‡1 âŠ—ğ‘¡ğ‘‡2 /ğ‘’1 âˆ¥ğ‘’2 step âˆ’âˆ’âˆ’â†’ğ‘†â€² /ğ‘‡1 âŠ—ğ‘¡ğ‘‡â€² 2 /ğ‘’1 âˆ¥ğ‘’â€² 2 Fig. 9. Reduction under a context and parallelism DELeaf âˆ€â„“. â„“âˆˆğ‘Ÿğ‘œğ‘œğ‘¡ğ‘ (ğ‘’) =â‡’ğºâŠ¢ğ›¼(â„“) â‰¼ğ‘¡ Disentangled (_, ğ›¼,ğº) /ğ‘¡/ğ‘’ DEPar Disentangled ğ‘†/ğ‘‡1 /ğ‘’1 Disentangled ğ‘†/ğ‘‡2 /ğ‘’2 Disentangled ğ‘†/ğ‘‡1 âŠ—ğ‘¡ğ‘‡2 /ğ‘’1 âˆ¥ğ‘’2 DEBind ğ‘†= (_, ğ›¼,ğº) Disentangled ğ‘†/ğ‘‡1 âŠ—ğ‘¡ğ‘‡2 /ğ‘’ âˆ€â„“. â„“âˆˆğ‘Ÿğ‘œğ‘œğ‘¡ğ‘ (ğ¾) =â‡’âˆ€ğ‘¡â€².ğ‘¡â€² âˆˆleaves(ğ‘‡1) âˆªleaves(ğ‘‡2) =â‡’ğºâŠ¢ğ›¼(â„“) â‰¼ğ‘¡â€² Disentangled ğ‘†/ğ‘‡1 âŠ—ğ‘¡ğ‘‡2 /ğ¾[ğ‘’] Fig. 10. Definition of Disentanglement graph, and allocates a memory cell to store the result of the (active) parallel pair. It then updates the task tree to the leaf ğ‘¡. Parallelism and reduction under a context. The lower part of Figure 9 presents the main reduction relation ğ‘†/ğ‘‡/ğ‘’ step âˆ’âˆ’âˆ’â†’ğ‘†â€² /ğ‘‡â€² /ğ‘’â€², which describes a scheduling reduction inside the whole parallel program [Moine et al. 2024]. A configuration ğ‘†/ğ‘‡/ğ‘’consists of the program state ğ‘†, the task tree ğ‘‡, and an expression ğ‘’. This expression ğ‘’can consist of multiple tasks, governed by the nesting of active parallel pairs (ğ‘’1 âˆ¥ğ‘’2). The corresponding timestamps of these tasks are given by the accompanying task tree ğ‘‡. A state ğ‘†consists of the tuple (ğœ, ğ›¼,ğº), denoting a store ğœ, an allocation map ğ›¼, and a computation graph ğº. StepSched reduction describes a scheduling step. The other reductions describe where the scheduling reduction takes place in the whole parallel program. StepBind reduction describes a reduction under an evaluation context. StepParL and StepParR reductions are non-deterministic: if a node of the task tree is encountered facing an active parallel pair, the left side or the right side can reduce. 3.3 Definition of Disentanglement The property Disentangled ğ‘†/ğ‘‡/ğ‘’asserts that, given a program state ğ‘†and a task tree ğ‘‡, the expression ğ‘’is disentangledâ€”that is, the roots of each task in ğ‘’were allocated by preceding tasks. Figure 10 gives the inductive definition of Disentangled ğ‘†/ğ‘‡/ğ‘’. If the program state has an allocation map ğ›¼and a computation graph ğº, and if the task tree is a leaf ğ‘¡, DELeaf requires Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:13 Timestamp variables ğ›¿ Type variables ğ›¼ Logical graphs Î” â‰œ Î”, ğ›¿â‰¼ğ›¿| âˆ… Kinds ğœ… â‰œ â˜…| âŠ²âŠ³ â‡’ğœ… Unboxed types ğœ â‰œ () | bool | int Boxed types ğœ â‰œ array(ğœŒ) | (ğœŒÃ— ğœŒ) | (ğœŒ+ ğœŒ) | âˆ€Â®ğ›¿Î”. Â®ğœŒâ†’ğ›¿ğœŒ Types ğœŒ â‰œ ğœ| ğœ†ğ›¿. ğœŒ| ğœŒğ›¿| âˆ€ğ›¼:: ğœ…. ğœŒ| ğœ‡ğ›¼. ğœ@ğ›¿| ğ›¼| ğœ@ğ›¿ Environments Î“ â‰œ ğ‘¥: ğœŒ, Î“ | ğ›¼:: ğœ…, Î“ | âˆ… Fig. 11. Syntax of types for every location â„“in ğ‘Ÿğ‘œğ‘œğ‘¡ğ‘ (ğ‘’), that is, the set of locations syntactically occurring in ğ‘’, that the location â„“has been allocated by a task ğ›¼(ğ‘¡) preceding ğ‘¡in ğº. If the task tree is a nodeğ‘‡1 âŠ—ğ‘¡ğ‘‡2, there are two cases. In the first case, if the expression is an active parallel pair, DEPar requires that the two sub-expressions are disentangled. Otherwise, the expression must be of the form ğ¾[ğ‘’], and then DEBind requires that ğ‘’itself is disentangled and that for every location â„“occurring in the evaluation context ğ¾, the location â„“has been allocated before every leaf ğ‘¡â€² of ğ‘‡1 and ğ‘‡2. Difference with Previous Semantics for Disentanglement. Inspired by Westrick et al. [2022], we equip DisLang2 with a mostly standard semantics, instrumented with a computation graph and an allocation map. We then distinguish disentangled states using the Disentangled property, resem- bling the â€œrootsdeâ€ invariant proposed by Westrick et al. [2022]. The novelty of our approach resides in the instrumentation with the, more amenable to verification, cyclic computation graph (Â§2.1). DisLog [Moine et al. 2024] chooses a slightly different formalization in which the semantics gets stuck if entanglements is detected. Each time a task acquires a location from the heap, the semantics performs a check to verify that the location was allocated by a preceding task. Intuitively, this check ensures by construction that a programâ€™s evaluation reaches only states satisfying the Disentangled property. Conversely, guaranteeing the Disentangled property at every step ensures that a disentanglement check cannot fail. 4 Type System In this section, we describe TypeDis in depth. First, we present the formal syntax of types (Â§4.1) as well as the typing judgment (Â§4.2). We then comment on typing rules for mutable heap blocks (Â§4.3), which enforce disentanglement. Next, we present the rules for creating and calling closures (Â§4.4), which are crucial for understanding our approach for typing the par primitive (Â§4.5). We then focus on advanced features of TypeDis: general recursive types and type polymorphism (Â§4.6). We conclude by presenting subtiming (Â§4.7). 4.1 Syntax of Types To reason statically about the runtime notions of timestamps ğ‘¡and computation graphs ğº(Â§3.2), we introduce their corresponding static notions: timestamp variables ğ›¿and logical graphs Î”, respectively. A logical graph Î” is a set of pairs ğ›¿1 â‰¼ğ›¿2, asserting that the timestamp ğ›¿1 precedes the timestamp ğ›¿2, that is, everything allocated by the task atğ›¿1 is safe to acquire for the task atğ›¿2. Figure 11 summarizes these notions together with the syntax of types. A powerful feature of our type system is its support for timestamp polymorphism, facilitated through higher-order types. This higher-order feature is instrumental in typing the par primi- tive (Â§4.5), and thus supporting the cyclic approach detailed in Â§2.1. Because our system is higher- order, we introduce kinds, written ğœ…, which capture the number of timestamps a type expects as Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:14 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick arguments. The ground kind, written â˜…, indicates that the type does not take a timestamp argument. The successor kind, written âŠ²âŠ³ â‡’ğœ…, indicates that the type expects ğœ…+ 1 timestamp arguments. A base type ğœdescribes an unboxed value, that is, a value that is not allocated on the heap. Base types include the unit type, Booleans, and integers. The syntax of types ğœŒis mutually inductive with the syntax of boxed types ğœ. A type ğœŒis either a base type ğœ, a type taking a timestamp argument ğœ†ğ›¿. ğœŒ, an application of a type to a timestamp ğœŒğ›¿, a universal quantification of a type variable with some kind âˆ€ğ›¼:: ğœ…. ğœŒ, a recursive type ğœ‡ğ›¼. ğœ@ğ›¿, a type variable ğ›¼, or a boxed type annotated with a timestamp ğœ@ğ›¿. When the timestamp ğ›¿does not matter, we write ğœ@_. A boxed type ğœis either an array array(ğœŒ), an immutable pair (ğœŒÃ— ğœŒ), an immutable sum (ğœŒ+ ğœŒ), or a function âˆ€Â®ğ›¿Î”. Â®ğœŒâ†’ğ›¿ğœŒ. Types support ğ›¼-equivalence for both type and timestamp variables, as well as ğ›½-reduction. 4.2 The Typing Judgment A typing environment Î“ is a map from free program variables to types, and from free type variables to kinds. The general form of the typing judgment of TypeDis is: Î” | Î“ âŠ¢ğ‘’: ğœŒâŠ²ğ›¿ where Î” is a logical graph, Î“ a typing environment, ğ‘’the expression being type-checked at type ğœŒ and at current timestamp ğ›¿. Selected rules of the type system appear in Figure 12. The rules adopt Barendregtâ€™s conven- tion [Barendregt 1984], assuming bound variables to be distinct from already existing free variables in scope. The reader might notice that several rules (for example, T-Abs or T-TAbs) require the user to manually decide where to apply these rules and with which arguments. We leave to future work the design of syntactic features together with a type inference mechanism for simplifying this process. Various rules are standard: T-Var type-checks variables and T-Unit, T-Int, and T-Bool type-check base types. The structural rules T-Let and T-If are also standard, and type-check let bindings and if statements, respectively. In the remainder, we discuss the rules that deserve special attention with regard to disentanglement. 4.3 Typing Rules for Heap Blocks Heap blocks must be handled with care to guarantee disentanglement: every time the program acquires a locationâ€”that is, the address of a heap blockâ€”we must ensure that this location has been allocated by a preceding task. Otherwise, this newly created root would break the disentanglement invariant (Â§3.3). Because load operations are so common in programming languages, we chose to enforce the following invariant on the typing judgment Î” | Î“ âŠ¢ğ‘’: ğœŒâŠ²ğ›¿: every location that can be acquired from Î“ was allocated before the current timestamp ğ›¿(Â§2.4). Hence, load operations (from immutable blocks and from mutable blocks) do not have any timestamp check. Operations on immutable blocks are type-checked by T-Pair and T-Proj, for pairs, and by T-Inj and T-Case, for sums. In particular, T-Pair and T-Inj reflect that pair creation and injection allocate heap blocks, hence, the resulting type is annotated with @ğ›¿, denoting the allocating timestamp. Operations on mutable blocks are type-checked by T-Array, T-Store, and T-Load. 4.4 Abstractions and Timestamp Polymorphism A function can be seen as a delayed computation. In our case, this notion of â€œdelayâ€ plays an interesting role: a function can run on a task distinct from the one that allocated it. Hence, functions in TypeDis have three non-standard features related to timestamps, roughly describing the status of the computation graph when the function will run. First, a function takes timestamp parameters, Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:15 T-Var Î“(ğ‘¥) = ğœŒ Î” | Î“ âŠ¢ğ‘¥: ğœŒâŠ²ğ›¿ T-Unit Î” | Î“ âŠ¢() : unit âŠ²ğ›¿ T-Int Î” | Î“ âŠ¢ğ‘–: int âŠ²ğ›¿ T-Bool Î” | Î“ âŠ¢ğ‘: bool âŠ²ğ›¿ T-Let Î” | Î“ âŠ¢ğ‘’1 : ğœŒâ€² âŠ²ğ›¿ Î” | ğ‘¥: ğœŒâ€², Î“ âŠ¢ğ‘’2 : ğœŒâŠ²ğ›¿ Î” | Î“ âŠ¢letğ‘¥= ğ‘’1 inğ‘’2 : ğœŒâŠ²ğ›¿ T-If Î” | Î“ âŠ¢ğ‘’1 : bool âŠ²ğ›¿ Î” | Î“ âŠ¢ğ‘’2 : ğœŒâŠ²ğ›¿ Î” | Î“ âŠ¢ğ‘’3 : ğœŒâŠ²ğ›¿ Î” | Î“ âŠ¢ifğ‘’1 thenğ‘’2 elseğ‘’3 : ğœŒâŠ²ğ›¿ T-Pair Î” | Î“ âŠ¢ğ‘’1 : ğœŒ1 âŠ²ğ›¿ Î” | Î“ âŠ¢ğ‘’2 : ğœŒ2 âŠ²ğ›¿ Î” | Î“ âŠ¢(ğ‘’1,ğ‘’2) : (ğœŒ1 Ã— ğœŒ2)@ğ›¿âŠ²ğ›¿ T-Proj Î” | Î“ âŠ¢ğ‘’: (ğœŒ1 Ã— ğœŒ2)@_ âŠ²ğ›¿ Î” | Î“ âŠ¢projğœ„ğ‘’: ğœŒğ‘–âŠ²ğ›¿ T-Inj Î” | Î“ âŠ¢ğ‘’: ğœŒğ‘–âŠ²ğ›¿ Î” | Î“ âŠ¢injğœ„ğ‘’: (ğœŒ1 + ğœŒ2)@ğ›¿âŠ²ğ›¿ T-Case Î” | Î“ âŠ¢ğ‘’: (ğœŒ1 + ğœŒ2)@_ âŠ²ğ›¿ Î” | ğ‘¥1 : ğœŒ1, Î“ âŠ¢ğ‘’1 : ğœŒâŠ²ğ›¿ Î” | ğ‘¥2 : ğœŒ2, Î“ âŠ¢ğ‘’2 : ğœŒâŠ²ğ›¿ Î” | Î“ âŠ¢matchğ‘’with inj1 ğ‘¥1 â‡’ğ‘’1 | inj2 ğ‘¥2 â‡’ğ‘’2 end : ğœŒâŠ²ğ›¿ T-Array Î” | Î“ âŠ¢ğ‘’1 : int âŠ²ğ›¿ Î” | Î“ âŠ¢ğ‘’2 : ğœŒâŠ²ğ›¿ Î” | Î“ âŠ¢alloc ğ‘’1 ğ‘’2 : array(ğœŒ)@ğ›¿âŠ²ğ›¿ T-Store Î” | Î“ âŠ¢ğ‘’1 : array(ğœŒ)@_ âŠ²ğ›¿ Î” | Î“ âŠ¢ğ‘’2 : int âŠ²ğ›¿ Î” | Î“ âŠ¢ğ‘’3 : ğœŒâŠ²ğ›¿ Î” | Î“ âŠ¢ğ‘’1.[ğ‘’2] â†ğ‘’3 : () âŠ²ğ›¿ T-Load Î” | Î“ âŠ¢ğ‘’1 : array(ğœŒ)@_ âŠ²ğ›¿ Î” | Î“ âŠ¢ğ‘’2 : int âŠ²ğ›¿ Î” | Î“ âŠ¢ğ‘’1.[ğ‘’2] : ğœŒâŠ²ğ›¿ T-Abs Î”, Î”1,ğ›¿â‰¼ğ›¿ğ‘“| ğ‘“: (âˆ€Â®ğ›¿1 Î”1. Â®ğœŒ1 â†’ğ›¿ğ‘“ğœŒ2)@ğ›¿, (Â®ğ‘¥: Â®ğœŒ1), Î“ âŠ¢ğ‘’: ğœŒ2 âŠ²ğ›¿ğ‘“ Î” | Î“ âŠ¢ğœ‡ğ‘“. ğœ†Â®ğ‘¥.ğ‘’: (âˆ€Â®ğ›¿1 Î”1. Â®ğœŒ1 â†’ğ›¿ğ‘“ğœŒ2)@ğ›¿âŠ²ğ›¿ T-App ğ›¿= [ Â®ğ›¿â€² 1/ Â®ğ›¿1]ğ›¿ğ‘“ Â®ğœŒâ€² 1 = [ Â®ğ›¿â€² 1/ Â®ğ›¿1] Â®ğœŒ1 ğœŒâ€² 2 = [ Â®ğ›¿â€² 1/ Â®ğ›¿1]ğœŒ2 Î”â€² 1 = [ Â®ğ›¿â€² 1/ Â®ğ›¿1]Î”1 Î” | Î“ âŠ¢ğ‘’: (âˆ€Â®ğ›¿1 Î”1. Â®ğœŒ1 â†’ğ›¿ğ‘“ğœŒ2)@_ âŠ²ğ›¿ Î” âŠ¢Î”â€² 1 Î” | Î“ âŠ¢Â®ğ‘’â€² : Â®ğœŒâ€² 1 âŠ²ğ›¿ Î” | Î“ âŠ¢ğ‘’Â®ğ‘’â€² : ğœŒâ€² 2 âŠ²ğ›¿ T-Par Î“ âŠ¢ğœ‘1 :: âŠ²âŠ³ â‡’â˜… Î“ âŠ¢ğœ‘2 :: âŠ²âŠ³ â‡’â˜… Î” | Î“ âŠ¢ğ‘’1 : (âˆ€ğ›¿â€² ğ›¿â‰¼ğ›¿â€². () â†’ğ›¿â€² ğœ‘1 ğ›¿â€²)@_ âŠ²ğ›¿ Î” | Î“ âŠ¢ğ‘’2 : (âˆ€ğ›¿â€² ğ›¿â‰¼ğ›¿â€². () â†’ğ›¿â€² ğœ‘2 ğ›¿â€²)@_ âŠ²ğ›¿ Î” | Î“ âŠ¢par(ğ‘’1,ğ‘’2) : (ğœ‘1 ğ›¿Ã— ğœ‘2 ğ›¿)@ğ›¿âŠ²ğ›¿ T-Fold Î“ âŠ¢ğœ‡ğ›¼. ğœ@ğ›¿:: â˜… Î” | Î“ âŠ¢ğ‘’: ([ğœ‡ğ›¼. ğœ@ğ›¿/ğ›¼]ğœ)@ğ›¿âŠ²ğ›¿ Î” | Î“ âŠ¢foldğ‘’: ğœ‡ğ›¼. ğœ@ğ›¿âŠ²ğ›¿ T-Unfold Î“ âŠ¢ğœ‡ğ›¼. ğœ@ğ›¿:: â˜… Î” | Î“ âŠ¢ğ‘’: ğœ‡ğ›¼. ğœ@ğ›¿âŠ²ğ›¿ Î” | Î“ âŠ¢unfoldğ‘’: ([ğœ‡ğ›¼. ğœ@ğ›¿/ğ›¼]ğœ)@ğ›¿âŠ²ğ›¿ T-TAbs Î” | ğ›¼:: ğœ…, Î“ âŠ¢ğ‘’: ğœŒâŠ²ğ›¿ veryPureğ‘’ Î” | Î“ âŠ¢ğ‘’: âˆ€ğ›¼:: ğœ…. ğœŒâŠ²ğ›¿ T-TApp Î“ âŠ¢ğœŒâ€² :: ğœ… Î” | Î“ âŠ¢ğ‘’: âˆ€ğ›¼:: ğœ…. ğœŒâŠ²ğ›¿ Î” | Î“ âŠ¢ğ‘’: [ğœŒâ€²/ğ›¼]ğœŒâŠ²ğ›¿ T-GetRoot Î“(ğ‘¥) = array(ğœâ€²)@ğ›¿â€² âˆ¨Î“(ğ‘¥) = ğœ‡ğ›¼. ğœâ€²@ğ›¿â€² Î”, ğ›¿â€² â‰¼ğ›¿| Î“ âŠ¢ğ‘’: ğœŒâŠ²ğ›¿ Î” | Î“ âŠ¢ğ‘’: ğœŒâŠ²ğ›¿ T-Subtiming Î” | Î“ âŠ¢ğ‘’: ğœŒâŠ²ğ›¿ Î” âŠ¢ğœŒâŠ†ğ›¿ğœŒâ€² Î” | Î“ âŠ¢ğ‘’: ğœŒâ€² âŠ²ğ›¿ Fig. 12. The type system (selected rules) Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:16 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick which are universally quantified. Second, a function takes a constraint over these timestamps, as a logical graph. Third, a function is annotated with a timestamp representing the task it will run on. Let us focus on the abstraction rule T-Abs. This rule type-checks a function definition of the form ğœ‡ğ‘“. ğœ†Â®ğ‘¥.ğ‘’, and requires the user to provide timestamp parameters Â®ğ›¿1, logical graph Î”1, and a running timestamp ğ›¿ğ‘“. The current timestamp is ğ›¿and the type associated to the function is (âˆ€Â®ğ›¿1 Î”1. Â®ğœŒ1 â†’ğ›¿ğ‘“ğœŒ2)@ğ›¿. This type asserts that, if (i) there is some instantiation of Â®ğ›¿1 satisfying Î”1, (ii) there are some arguments of type Â®ğœŒ1, and (iii) the timestamp of the calling task is ğ›¿ğ‘“, then the function will produce a result of type ğœŒ2. This type also reminds us that a function is a heap-allocated object, and is hence annotated with the task that allocated it, here ğ›¿. The premise of T-Abs changes the current timestamp to be ğ›¿ğ‘“, the timestamp of the invoking task, and requires the body ğ‘’to be of type ğœŒ2. T-Abs is in fact the sole rule of the system â€œchangingâ€ the current timestamp while type-checking. The logical graph is augmented with Î”1 plus the knowledge that ğ›¿ precedes ğ›¿ğ‘“, conveying the fact that a function can only be called at a subsequent timestamp. The environment Î“ is extended with the parameters (Â®ğ‘¥: Â®ğœŒ1) as well as the recursive name ğ‘“. Note that timestamp parameters Â®ğ›¿1 and logical graph Î”1 are before the arguments Â®ğ‘¥. This means that the body ğ‘’will be able to recursively call ğ‘“with different timestamp arguments (potentially including a different ğ›¿ğ‘“), for example after it forked. We already saw such an example for the build and selectmap functions in Sections 2.3 and 2.4. Let us now focus on T-App, type-checking a function application. The conclusion type-checks the expression ğ‘’Â®ğ‘’â€² to be of type ğœŒâ€² 2 at the current timestamp ğ›¿. The premise of T-App requires ğ‘’ to be a function of type âˆ€Â®ğ›¿1 Î”1. Â®ğœŒ1 â†’ğ›¿ğ‘“ğœŒ2, allocated by some irrelevant task. The premise then substitutes in all the relevant parts the user-supplied timestamps Â®ğ›¿â€² 1 in place of Â®ğ›¿1. Hence, the result type ğœŒâ€² 2 is equal to [ Â®ğ›¿â€² 1/ Â®ğ›¿1]ğœŒ2. In particular, the premise ğ›¿= [ Â®ğ›¿â€² 1/ Â®ğ›¿1]ğ›¿ğ‘“requires that the running timestamp ğ›¿ğ‘“to be equal to ğ›¿, the current timestamp. The premise also requires the logical graph Î”â€² 1 to be a subgraph of the logical graph Î”, written Î” âŠ¢Î”â€² 1, meaning that every pair of vertices reachable in Î”â€² 1 must also be reachable in Î”. This property is formally defined in Appendix A.3. Finally, the premise requires the arguments Â®ğ‘’to be of the correct type Â®ğœŒâ€² 1. 4.5 The Par Rule The typing rule for the par primitive is at the core of TypeDis. T-Par type-checks par(ğ‘’1,ğ‘’2) at cur- rent timestamp ğ›¿. Recall (Â§3.2) that the results of ğ‘’1 and ğ‘’2 must be closures; these closures are then called in parallel and their results are returned as an immutable pair. To preserve disentanglement, the two closures must not communicate allocations they make with each other. Hence, the premise of T-Par requires the two expressions ğ‘’1 and ğ‘’2 to be of type âˆ€ğ›¿â€² ğ›¿â‰¼ğ›¿â€². () â†’ğ›¿â€² . . . , signaling that they must be closures that are expected to run on a task ğ›¿â€², universally quantified, and subsequent to ğ›¿. Because of this universal quantification over the running timestamp ğ›¿â€² and because the rules allocating blocks (T-Array, T-Pair, T-Proj and T-Abs) always tag the value they allocate with the running timestamp, the tasks will not be able to communicate allocations they make. After these two closure calls terminate, and their underlying tasks join, the parent task gains access to everything the two children allocated. In fact, from the point of view of disentanglement, we can even pretend that the parent task itself allocated these locations! T-Par does more than pretending and backtimes the return types of the two closures, by substituting the running timestamp of the children ğ›¿â€² by the running timestamp of the parent ğ›¿. Indeed, the return types of the closures, ğœ‘1 ğ›¿â€² for ğ‘’1 and ğœ‘2 ğ›¿â€² for ğ‘’2, signal that these two closures will return some type, parametrized by the running timestamp ğ›¿â€². This formulation allows the rule to type-check the original par(ğ‘’1,ğ‘’2) as (ğœ‘1 ğ›¿Ã— ğœ‘2 ğ›¿)@ğ›¿, that is, a pair of the two types returned by the closures, but where the running timestamp of the child ğ›¿â€² was replaced by the running timestamp of the parent ğ›¿. Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:17 4.6 Recursive Types and Type Polymorphism Recursive types. TypeDis supports iso-recursive types [Pierce 2002, Â§20.2]. In TypeDis, a recursive type takes the form ğœ‡ğ›¼. ğœ@ğ›¿, binding the recursive name ğ›¼in the boxed type ğœwhich must have been allocated at ğ›¿. This syntax ensures that types are well-formed, and forbids meaningless types ğœ‡ğ›¼. ğ›¼as well as useless types ğœ‡ğ›¼. ğœ‡ğ›½. ğœŒ. T-Fold and T-Unfold allow for going from ğœ‡ğ›¼. ğœ@ğ›¿to ([ğœ‡ğ›¼. ğœ@ğ›¿/ğ›¼]ğœ)@ğ›¿and vice-versa. Note that this approach requires that the recursive occurrences of ğ›¼are all allocated at the same timestamp; all the nodes of the recursive data structures must have been allocated at the same timestamp. This may seem restrictive, but subtiming will relax this requirement (Â§4.7). Let us give an example. The type of lists allocated at timestamp ğ›¿containing integers is: ğœ‡ğ›¼. (() + (int Ã— ğ›¼)@ğ›¿)@ğ›¿ This type describes that a list of integers is either the unit value (describing the nil case), or the pair of an integer and a list of integers (describing the cons case). Type polymorphism. TypeDis supports type polymorphism, through type abstraction T-TAbs and type application T-TApp. Whereas the former is standard, the latter has an unusual premise veryPureğ‘’, our variant of the value restriction. The value restriction [Wright 1995] is a simple syntactic restriction guaranteeing soundness of polymorphism in the presence of mutable stateâ€”a combination that is well known to be unsound if unrestricted. In particular, the value restriction permits only values to be polymorphic. However, DisLang2 has an unusual aspect: functions are not values, they are allocated on the heap (Â§3.1). Hence, the value restriction is not applicable as-is, yet it is crucial to allow universal type quantification in front of functions. We contribute a variant of the value restriction, that allows type quantification in front of any pure expression that does not call a function, project a pair, case over a sum, or fork new tasks. This includes function allocation, pair allocation, sums injection, as well as other control-flow constructs. This syntactic check is ensured by the predicate veryPureğ‘’that appears as a premise of the type abstraction rule T-TAbs. The predicate veryPureğ‘’is defined in Appendix A.2. It can be seen as an alternative to the solution proposed by de Vilhena [2022], in which every arrow has a purity attribute, indicating if the function interacts with the store. Contrary to de Vilhenaâ€™s solution, we support some benign interactions with the store: the allocation of immutable data structures. TypeDis supports higher-kind type polymorphism. For example, reminding of the typing rule T-Par, one could present par as a higher-order function of the following type par : âˆ€(ğœ‘1 :: âŠ²âŠ³ â‡’â˜…) (ğœ‘2 :: âŠ²âŠ³ â‡’â˜…). âˆ€ğ›¿ğ›¿1 ğ›¿2. (âˆ€ğ›¿â€² ğ›¿â‰¼ğ›¿â€². () â†’ğ›¿â€² ğœ‘1 ğ›¿â€²)@ğ›¿1 â†’(âˆ€ğ›¿â€² ğ›¿â‰¼ğ›¿â€². () â†’ğ›¿â€² ğœ‘2 ğ›¿â€²)@ğ›¿2 â†’ğ›¿(ğœ‘1 ğ›¿Ã— ğœ‘2 ğ›¿)@ğ›¿ Taking ğœ‘1 = ğœ‘2 = ğœ†ğ›¿. tree@ğ›¿and doing ğ›½-reduction matches the type presented in Section 2.3. 4.7 Subtiming As presented so far, backtimingâ€”that is, substituting the timestamp of a child task by the one of its parent task at the join pointâ€”is the only way of changing a timestamp inside a type (Â§4.5). We propose here another mechanism that we dub subtiming. As the name suggests, subtiming is a form of subtyping [Pierce 2002, Â§15] for timestamps. At a high-level, subtiming allows for â€œadvancingâ€ a timestamp within a type, as long as this update makes sense. This notion of â€œadvancingâ€ relates to the notion of precedence, describing reachability between two timestamps. We write Î” âŠ¢ğ›¿1 â‰¼ğ›¿2 to describe that ğ›¿1 can reach ğ›¿2 in Î” (Appendix A.3). Equipped with this reachability predicate, we make a first attempt at capturing Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:18 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick S-Refl Î” âŠ¢ğœŒâŠ†ğ›¿ğœŒ S-ReflAt Î” âŠ¢ğœâŠ†ğ›¿ğœ S-TAbs Î” âŠ¢ğœŒ1 âŠ†ğ›¿ğœŒ2 Î” âŠ¢âˆ€ğ›¼:: ğœ…. ğœŒ1 âŠ†ğ›¿âˆ€ğ›¼:: ğœ…. ğœŒ2 S-Pair Î” âŠ¢ğœŒğ‘™1 âŠ†ğ›¿ğœŒğ‘™2 Î” âŠ¢ğœŒğ‘Ÿ1 âŠ†ğ›¿ğœŒğ‘Ÿ2 Î” âŠ¢(ğœŒğ‘™1 Ã— ğœŒğ‘Ÿ1) âŠ†ğ›¿(ğœŒğ‘™2 Ã— ğœŒğ‘Ÿ2) S-Sum Î” âŠ¢ğœŒğ‘™1 âŠ†ğ›¿ğœŒğ‘™2 Î” âŠ¢ğœŒğ‘Ÿ1 âŠ†ğ›¿ğœŒğ‘Ÿ2 Î” âŠ¢(ğœŒğ‘™1 + ğœŒğ‘Ÿ1) âŠ†ğ›¿(ğœŒğ‘™2 + ğœŒğ‘Ÿ2) S-At Î” âŠ¢ğ›¿1 â‰¼ğ›¿2 (ğ›¿1 â‰ ğ›¿2 =â‡’Î” âŠ¢ğ›¿2 â‰¼ğ›¿) Î” âŠ¢ğœ1 âŠ†ğ›¿2 ğœ2 Î” âŠ¢ğœ1@ğ›¿1 âŠ†ğ›¿ğœ2@ğ›¿2 S-Rec Î” âŠ¢ğ›¿1 â‰¼ğ›¿2 (ğ›¿1 â‰ ğ›¿2 =â‡’Î” âŠ¢ğ›¿2 â‰¼ğ›¿) Î” âŠ¢ğœ1 âŠ†ğ›¿2 ğœ2 Î” | ğ›¼â†¦â†’ğ›¿2 âŠ¢ğ›¿2 ğœ2 Î” âŠ¢ğœ‡ğ›¼. ğœ1@ğ›¿1 âŠ†ğ›¿ğœ‡ğ›¼. ğœ2@ğ›¿2 S-Abs Î”â€² = Î” âˆªÎ”2 Î”â€² âŠ¢Î”1 Î”â€² âŠ¢Â® ğœŒğ‘ 2 âŠ†ğ›¿ğ‘“ Â® ğœŒğ‘ 1 Î”â€² âŠ¢ğœŒ1 âŠ†ğ›¿ğ‘“ğœŒ2 Î” âŠ¢âˆ€Â®ğ›¿ğ‘ Î”1. Â® ğœŒğ‘ 1 â†’ğ›¿ğ‘“ğœŒ1 âŠ†ğ›¿âˆ€Â®ğ›¿ğ‘ Î”2. Â® ğœŒğ‘ 2 â†’ğ›¿ğ‘“ğœŒ2 S-Inst ğ›¿2 = [ğ›¿ğ‘¦/ğ›¿ğ‘¥]ğ›¿1 Â® ğœŒğ‘ 2 = [ğ›¿ğ‘¦/ğ›¿ğ‘¥] Â® ğœŒğ‘ 1 Î”2 = [ğ›¿ğ‘¦/ğ›¿ğ‘¥]Î”1 Î” âŠ¢âˆ€( Â® ğ›¿ğ‘ ğ‘™++[ğ›¿ğ‘¥] ++ Â® ğ›¿ğ‘ ğ‘Ÿ) Î”1. Â® ğœŒğ‘ 1 â†’ğ›¿1 ğœŒ1 âŠ†ğ›¿âˆ€( Â® ğ›¿ğ‘ ğ‘™++ Â® ğ›¿ğ‘ ğ‘Ÿ) Î”2. Â® ğœŒğ‘ 2 â†’ğ›¿2 ğœŒ2 Fig. 13. The subtiming judgment the idea of subtiming as follows: Specialized-Subtiming Î” | Î“ âŠ¢ğ‘’: ğœ@ğ›¿1 âŠ²ğ›¿ Î” âŠ¢ğ›¿1 â‰¼ğ›¿2 Î” âŠ¢ğ›¿2 â‰¼ğ›¿ Î” | Î“ âŠ¢ğ‘’: ğœ@ğ›¿2 âŠ²ğ›¿ Specialized-Subtiming asserts that an expression of type ğœ@ğ›¿1 can be viewed as an expression of type ğœ@ğ›¿2 as long as ğ›¿1 precedes ğ›¿2 and ğ›¿2 is not ahead of time, that is ğ›¿2 precedes the current timestamp ğ›¿. Indeed, TypeDis enforces that, if Î” | Î“ âŠ¢ğ‘’: ğœ@ğ›¿â€² âŠ²ğ›¿holds, then ğ›¿â€² precedes ğ›¿. While Specialized-Subtiming is admissible in TypeDis, it is not general enough, as it only considers the timestamp at the root of a type. This motivates rule T-Subtiming in Figure 12, which relies on the subtiming judgment Î” âŠ¢ğœŒâŠ†ğ›¿ğœŒâ€², given in Figure 13, and acts as a subsumption rule. Intuitively, the judgment Î” âŠ¢ğœŒâŠ†ğ›¿ğœŒâ€² captures the fact the timestamps in ğœŒprecede the timestamps in ğœŒâ€² under logical graph Î”, knowing that every timestamp occurring in ğœŒâ€² must precede ğ›¿. The definition of the judgment now allows changing the timestamps inside immutable types. Because of variance issues (see [Pierce 2002, Â§15.5]), however, subtiming for mutable types is only shallow: a timestamp can be changed only at the root of an array type. The subtiming judgment Î” âŠ¢ğœŒâŠ†ğ›¿ğœŒâ€² assumes that types are in ğ›½-normal form. S-Refl and S-ReflAt assert that the subtiming judgment is reflexive. S-TAbs asserts that subtiming goes below type quantifiers (which are irrelevant here, the subtiming judgment tolerates open terms). S-Pair and S-Sum reflect that subtiming for immutable types is deep. S-At illustrates the case presented in Specialized-Subtiming. This rule asserts that, with logical graph Î” and maximum allowed timestamp ğ›¿, the boxed type ğœ1@ğ›¿1 is a subtype of ğœ2@ğ›¿2 if three conditions are met. First, ğ›¿1 must precede ğ›¿2. Second, if subtiming is applied here, that is, if ğ›¿1 â‰ ğ›¿2, then ğ›¿2 must precede ğ›¿, the maximum timestamp allowed. Third, ğœ1 must recursively be a subtype of ğœ2, with maximum timestamp allowed ğ›¿2. Indeed, recall that TypeDis allows only for up-pointers: every timestamp in ğœ2 must precede ğ›¿2. S-Rec allows subtiming for recursive types ğœ‡ğ›¼. ğœ1@ğ›¿1 and ğœ‡ğ›¼. ğœ2@ğ›¿2. The first three premises (in the left-to-right, top-to-bottom order) are the same as for S-At. The fourth premise Î” | ğ›¼â†¦â†’ğ›¿2 âŠ¢ğ›¿2 ğœ2 requires explanations. This predicate, dubbed the â€œvalid variableâ€ judgment and formally defined in Appendix A.4, ensures two properties. First, that ğ›¼does not appear in an array type (because subtiming is not allowed at this position) or in an arrow or another recursive type (for simplicity). Second, that if ğ›¼appears under a timestamp ğ›¿, then ğ›¿2 must precede ğ›¿. Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:19 OOB-Alloc ğ‘–< 0 OOBğœ(alloc ğ‘–ğ‘£) OOB-Load ğœ(â„“) = Â®ğ‘£ ğ‘–< 0 âˆ¨ğ‘–â‰¥|Â®ğ‘£| OOBğœ(â„“.[ğ‘–]) OOB-Store ğœ(â„“) = Â®ğ‘£ ğ‘–< 0 âˆ¨ğ‘–â‰¥|Â®ğ‘£| OOBğœ(â„“.[ğ‘–] â†ğ‘¤) OOB-CAS ğœ(â„“) = Â®ğ‘£ ğ‘–< 0 âˆ¨ğ‘–â‰¥|Â®ğ‘£| OOBğœ(CAS â„“ğ‘–ğ‘¤1 ğ‘¤2) Red-Sched ğ‘†/ğ‘‡/ğ‘’ sched âˆ’âˆ’âˆ’âˆ’â†’ğ‘†â€² /ğ‘‡â€² /ğ‘’â€² AllRedOrOOB ğ‘†/ğ‘‡/ğ‘’ Red-OOB OOBğœğ‘’ AllRedOrOOB (ğœ, ğ›¼,ğº) /ğ‘¡/ğ‘’ Red-Ctx AllRedOrOOB ğ‘†/ğ‘‡/ğ‘’ AllRedOrOOB ğ‘†/ğ‘‡/ğ¾[ğ‘’] Red-Par (ğ‘’1 âˆ‰V âˆ¨ğ‘’2 âˆ‰V) (ğ‘’1 âˆ‰V =â‡’AllRedOrOOB ğ‘†/ğ‘‡1 /ğ‘’1) (ğ‘’2 âˆ‰V =â‡’AllRedOrOOB ğ‘†/ğ‘‡2 /ğ‘’2) AllRedOrOOB ğ‘†/ğ‘‡1 âŠ—ğ‘¡ğ‘‡2 /ğ‘’1 âˆ¥ğ‘’2 Safe-Final Safe ğ‘†/ğ‘¡/ğ‘£ Safe-NonFinal AllRedOrOOB ğ‘†/ğ‘‡/ğ‘’ Safe ğ‘†/ğ‘‡/ğ‘’ Fig. 14. The OOB, AllRedOrOOB and Safe predicates S-Abs allows subtiming for function types âˆ€Â®ğ›¿ğ‘ Î”1. Â® ğœŒğ‘ 1 â†’ğ›¿ğ‘“ğœŒ1 and âˆ€Â®ğ›¿ğ‘ Î”2. Â® ğœŒğ‘ 2 â†’ğ›¿ğ‘“ğœŒ2. The quantified timestamps Â®ğ›¿ğ‘ and the calling timestamp ğ›¿ğ‘“must be the same. The extended logical graph Î”â€², equal to Î” âˆªÎ”2, must subsume Î”1. Moreover, the arguments Â® ğœŒğ‘ 2 must subtime Â® ğœŒğ‘ 1 (note the polarity inversion). The return type ğœŒ1 must subtime ğœŒ2. S-Inst allows for specializing a universally-quantified timestamp and has a more standard subtyping flavor. In this rule, the quantified timestamp ğ›¿ğ‘¥is being instantiated with ğ›¿ğ‘¦(similarly to the instantiation occurring in T-App). Before using subtiming, information about precedence may be needed. TypeDis guarantees a strong invariant: every timestamp occurring in the typing environment comes before the current timestamp. Such an invariant is illustrated by T-GetRoot, which allows adding to the logical graph Î” an edge (ğ›¿â€²,ğ›¿), where ğ›¿â€² is a timestamp in the environment and ğ›¿the current timestamp. 5 Soundness In this section, we state the soundness of TypeDis and give an intuition for its proof, which takes the form of a logical relation in Iris and is mechanized in Rocq [Moine et al. 2025]. We first enunciate the soundness theorem (Â§ 5.1). We then recall the concepts of Iris we need (Â§ 5.2) and present DisLog2 (Â§5.3), the verification logic we use. We then devote our attention to the formal proof, by presenting the high-level ideas of the logical relation (Â§5.4) we developed and its fundamental theorem (Â§5.5). We conclude by assembling all the building blocks we presented and sketching the soundness proof of TypeDis (Â§5.6). 5.1 Soundness Statement of TypeDis Our soundness statement adapts Milner [1978]â€™ slogan â€œwell-typed programs cannot go wrongâ€ by proving that the reduction of a well-typed program reaches only configurations that are safe and disentangled. We already formally defined the concept of disentanglement (Â§3.3). What about safety? Intuitively, a configuration is safe if all tasks can take a step or, conversely, no task is stuck. However, this property is too strong for our type system due to reasons unrelated to disentanglement. Being purposefully designed for disentanglement, our type system is not capable of verifying arbitrary functional correctness conditions. In particular, while the semantics of DisLang2 ensures that accesses to arrays by load and store operations are within bounds and thus cannot cause a task to get stuck, our type system does not enforce that. This restriction comes at the advantage of freeing Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:20 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick programmers from carrying out correctness proofs themselves, which are carried out by the type- checker instead. Intuitively, we say that a configuration is safe if it is final, or each task can either take a step or encounters a load or a store operation out-of-bounds. We formalize these properties in Figure 14. The property OOBğœğ‘’asserts that the expression ğ‘’faces an out-of-bounds operation: that is, an allocation, a load, a store, or a CAS outside the bounds. The property AllRedOrOOB ğ‘†/ğ‘‡/ğ‘’ asserts that, within the configuration of the program state ğ‘†, the task tree ğ‘‡and the expression ğ‘’, every task of the task tree can either take a step or faces an out-of-bounds operation. Red-Sched asserts that the configuration can take a scheduling step (that is, either a head step, a fork, or a join). Red-OOB asserts that the configuration is at a leaf and faces an out-of-bounds operation. Red-Ctx asserts that an expression under evaluation is reducible if this very expression is reducible. Red-Par asserts that an active parallel pair ğ‘’1 âˆ¥ğ‘’2 is reducible if at least one of its components ğ‘’ğ‘–is not a value and any ğ‘’ğ‘–that is not a value is reducible. (If both expressions are values, a join is possible). The property Safe ğ‘†/ğ‘‡/ğ‘’asserts that the configuration ğ‘†/ğ‘‡/ğ‘’is either final (Safe-Final), that is, the task tree is at a leaf and the expression is a value, or that every task of the task tree can either take a step or faces an out-of-bounds operation (Safe-NonFinal). An expression ğ‘’is always safe and disentangled if (âˆ…, âˆ…, {(ğ‘¡0,ğ‘¡0)})/ğ‘¡/ğ‘’ step âˆ’âˆ’âˆ’â†’âˆ—ğ‘†â€² /ğ‘‡â€² /ğ‘’â€² im- plies that Safe ğ‘†â€² /ğ‘‡â€² /ğ‘’â€² and Disentangled ğ‘†â€² /ğ‘‡â€² /ğ‘’â€² hold, for some initial timestamp ğ‘¡0. Theorem 5.1 (Soundness of TypeDis). If âˆ…| âˆ…âŠ¢ğ‘’: ğœŒâŠ²ğ›¿then ğ‘’is always safe and disentangled. Proof. We prove this theorem using a logical relation [Timany et al. 2024], which makes use of DisLog2, a variation of DisLog [Moine et al. 2024]. We present the proof sketch in Section 5.6. â–¡ 5.2 Iris Primer We set up our proofs in Iris [Jung et al. 2018b], and recall here the base notations. Irisâ€™ assertions are of type iProp. We write Î¦ for an assertion, âŒœğ‘ƒâŒfor an assertion of the meta-logic (that is, Rocq), Î¦1 âˆ—Î¦2 for a separating conjunction, and Î¦1 âˆ’âˆ—Î¦2 for a separating implication. We write a postconditionâ€”that is, a predicate over valuesâ€”using Î¨. One of the most important features of Iris are invariants. An invariant assertion Î¦, written Î¦ , holds true in-between every computation step. (Formally, invariants are annotated with so- called masks [Jung et al. 2018b, Â§2.2], we omit them for brevity.) Invariants, as well as other logical resources in Iris, are implemented using ghost state. We write Î¦1 â‡›Î¦2 to denote a ghost updateâ€”that is, an update of the ghost state between Î¦1 and Î¦2. Iris features a variety of modalities. In this work we use two of them extensively. First, the persistence modality, written Î¦, asserts that the assertion Î¦ is persistent, meaning in particular that Î¦ is duplicable. Second, the later modality, written âŠ²Î¦, asserts that Î¦ holds â€œone step of computation laterâ€. We write â„“â†¦â†’Â®ğ‘£to denote that â„“points-to an array with contents Â®ğ‘£. We write â„“â†¦â†’ ğ‘Ÿ, with a discarded fraction [Vindum and Birkedal 2021], to denote that â„“points-to an immutable block ğ‘Ÿ(that is, either a closure, an immutable pair, or an immutable sum). This latter assertion is persistent. 5.3 Taking Advantage of the Cyclic Approach with DisLog2 Moine et al. [2024] contributed DisLog, the first program logic for verifying disentanglement. DisLog depends on the very definition of disentanglement, and uses the standard approach presented in Section 2.1: when two tasks join, they form a new task with a fresh timestamp. This choice impacts the logic: the weakest precondition (WP) modality of DisLog takes the form wp âŸ¨ğ‘¡, ğ‘’âŸ©{ğœ†ğ‘¡â€² ğ‘£. Î¦} and asserts that the expression ğ‘’running on current timestamp ğ‘¡is disentangled, and if the evaluation of ğ‘’terminates, it does so on the end timestamp ğ‘¡â€², with final value ğ‘£and satisfying the assertion Î¦. In particular, ğ‘¡and ğ‘¡â€² may not be the same, for example if ğ‘’contains a call to par. Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:21 D-Load âŒœ0 â‰¤ğ‘–< | Â®ğ‘¤| âˆ§Â®ğ‘¤(ğ‘–) = ğ‘£âŒ â„“â†¦â†’ğ‘Â®ğ‘¤ ğ‘£ ğ‘¡ wp âŸ¨ğ‘¡, â„“.[ğ‘–]âŸ©{ğœ†ğ‘£â€². âŒœğ‘£â€² = ğ‘£âŒâˆ—â„“â†¦â†’ğ‘Â®ğ‘¤} D-LoadOOB âŒœğ‘–< 0 âˆ¨ğ‘–â‰¥| Â®ğ‘¤|âŒ â„“â†¦â†’ğ‘Â®ğ‘¤ wp âŸ¨ğ‘¡, â„“.[ğ‘–]âŸ©{ğœ†_. âŠ¥} D-Par âˆ€ğ‘¡1 ğ‘¡2. ğ‘¡â‰¼ğ‘¡1 âˆ—ğ‘¡â‰¼ğ‘¡2 â‡›âˆƒÎ¨1 Î¨2. wp âŸ¨ğ‘¡1, â„“1 [()]âŸ©{Î¨1} âˆ—wp âŸ¨ğ‘¡2, â„“2 [()]âŸ©{Î¨2} âˆ—  âˆ€ğ‘£1 ğ‘£2 â„“. Î¨1 ğ‘£1 âˆ—Î¨2 ğ‘£2 âˆ—ğ‘¡1 â‰¼ğ‘¡âˆ—ğ‘¡2 â‰¼ğ‘¡âˆ—â„“â†¦â†’(ğ‘£1, ğ‘£2) âˆ’âˆ—Î¨ â„“ wp âŸ¨ğ‘¡, par(â„“1, â„“2)âŸ©{Î¨} D-ClockMono ğ‘£ ğ‘¡1 ğ‘¡1 â‰¼ğ‘¡2 ğ‘£ ğ‘¡2 Fig. 15. Selected rules of DisLog2 To take advantage of the cyclic approach for disentanglement (Â§2.1), we had to develop a new version of DisLog, yielding the logic DisLog2. DisLog2 allows reusing the timestamp of the forking task for the child tasks upon join. As a result, the current timestamp and end timestamp of an expression always coincide, allowing us to simplify the WP of DisLog by simply removing the end timestamp parameter of the postcondition. Formally, the WP of DisLog2 then takes the form wp âŸ¨ğ‘¡, ğ‘’âŸ©{ğœ†ğ‘£. Î¦} and asserts that the expression ğ‘’running on timestamp ğ‘¡is disentangled, and if the evaluation of ğ‘’terminates, it does so with final value ğ‘£and satisfying the assertion Î¦. In contrast to DisLog, DisLog2 tolerate out-of-bounds accesses to cater to the TypeDis type system which only enforces disentanglement. (In practice, DisLog2 is parameterized by a boolean flag which can be used to enable or disable inboundedness proof obligations; when such obligations are enabled, DisLog2 has the same expressive power as DisLog.) Otherwise, DisLog2 adapts all the ideas of DisLog. In particular, the logic features two persistent assertions related to timestamps. First, the clock assertion â„“ ğ‘¡asserts that location â„“was allocated by a task that precedes ğ‘¡. Similarly, ğ‘£ ğ‘¡has the same meaning, if ğ‘£is a location â„“, or otherwise denotes âŒœğ‘‡ğ‘Ÿğ‘¢ğ‘’âŒ. Second, the precedence assertion ğ‘¡1 â‰¼ğ‘¡2 asserts that task ğ‘¡1 precedes task ğ‘¡2 in the underlying computation graph. The precedence assertion forms a pre-order: it is reflexive and transitive. Crucially, the clock assertion is monotonic with respect to the precedence pre-order [Moine et al. 2024]. In the remainder of the paper, we write ğ‘¡1 â‰ˆğ‘¡2 to denote that ğ‘¡1 and ğ‘¡2 are equivalent, that is, both ğ‘¡1 â‰¼ğ‘¡2 and ğ‘¡2 â‰¼ğ‘¡1 hold. Selected rules of DisLog2. Figure 15 presents four key rules of DisLog2. The premise of these rules are implicitly separated by a separating conjunction âˆ—. D-Load, targeting a load operation on the array â„“at offset ğ‘–on task ğ‘¡, ensures disentanglement. Indeed, the rule requires that â„“points-to the array Â®ğ‘¤and that the offset ğ‘–in Â®ğ‘¤corresponds to the value ğ‘£. It also requires the assertion ğ‘£ ğ‘¡, witnessing that if ğ‘£is a location, then this location must have been allocated by a preceding task. D-LoadOOB is unusual for a program logic and reflects that we purposefully allow for OOB accesses in verified programs, because our type system does. Because an OOB access results in a crash, the postcondition of the WP is âŒœğ¹ğ‘ğ‘™ğ‘ ğ‘’âŒ, allowing the user to conclude anything. D-Par is at the heart of DisLog2 and allows verifying a parallel call to two closures â„“1 and â„“2 at timestamp ğ‘¡. The premise universally quantifies over ğ‘¡1 and ğ‘¡2, the two timestamps of the forked tasks, that are both preceded by ğ‘¡. Then, the user must provide two postconditions, Î¨1 and Î¨2 for the two tasks, and verify that the closure call â„“1 [()] (resp. â„“2 [()]) is safe at timestamp ğ‘¡1 (resp. ğ‘¡2) with postcondition Î¨1 (resp. Î¨2). The second line of the premise requires the user to prove that, after the two tasks terminated and joined, the initial postcondition Î¨ â„“must hold, for some location â„“pointing to the pair (ğ‘£1, ğ‘£2) where ğ‘£1 is the final result of ğ‘¡1 andğ‘£2 of ğ‘¡2. D-ClockMono formalizes monotonicity of the clock assertion. Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:22 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick The adequacy theorem of DisLog2. The adequacy theorem of DisLog2 asserts that if ğ‘’can be verified using the program logic, then ğ‘’is always safe and disentangled. Theorem 5.2 (Adeqacy of DisLog2). If wp âŸ¨ğ‘¡, ğ‘’âŸ©{Î¨} holds then ğ‘’is always safe and dis- entangled. Proof. Similar to the adequacy proof of DisLog; see our mechanization [Moine et al. 2025]. â–¡ 5.4 A Logical Relation The very heart of the soundness proof of TypeDis is a logical relation, set up in Iris using DisLog2. Logical relations [Girard 1972; Pitts and Stark 1998; Plotkin 1973; Statman 1985; Tait 1967] are a technique that allows one to prescribe properties of valid programs in terms of their behavior, as opposed to solely their static properties. We adopt the semantic approach [Constable et al. 1986; Martin-LÃ¶f 1982; Timany et al. 2024], which admits terms that are not necessarily (syntactically) well-typed to be an inhabitant of the logical relation and has been successfully deployed in the RustBelt project [Jung et al. 2018a], for example. Our logical relation is presented in Appendix A.6; we comment next on the high-level ideas. As usual, our (unary) logical relation gives the interpretation of a type ğœŒwith kind â˜…as a predicate on values. Values satisfying the predicate are said to inhabit the relation. Because our types have higher kinds, our logical relation includes predicates on timestamps. In particular, the interpretation of a type ğœŒwith kind ğœ…is a function taking ğœ…timestamp arguments (where â˜…indicates zero timestamps and âŠ²âŠ³ â‡’ğœ…indicates ğœ…+ 1 timestamps) and producing a predicate over values. The presented relations involve two sorts of closing substitutions for variables occurring in types. First, a timestamp substitution, written â„, which is a finite map from timestamp variables ğ›¿ to concrete timestamps ğ‘¡. Second, a type substitution, written ğ‘š, which is a finite map from type variables to tuples of a kind ğœ…and a tuple of two functions depending on ğœ…. The first function takes ğœ…timestamps and produces a predicate over values; it represents the semantic interpretation of the type by which the variable will be instantiated. The second function takes ğœ…timestamps and produces a timestamp; its result corresponds to the root timestamp of the type by which the variable will be instantiated. The interpretation of a type guarantees that the type only contains up-pointers (Â§2.2), that is, the interpretation of ğœ@ğ›¿ensures that if ğ›¿â€² appears in ğœ, then ğ›¿â€² precedes ğ›¿. To enforce this invariant, our approach makes use of transitivity: the interpretation of ğœ@ğ›¿ ensures that, for each outermost ğœŒencountered in ğœ, the root timestamp of ğœŒâ€”conceptually, the outermost timestamp in ğœŒâ€”precedes ğ›¿. Because this invariant is enforced at each stage of the type interpretation, and because precedence is transitive, we guarantee that there are only up-pointers. Appendix A.5 presents a function that computes the root timestamp of a type and defines the assertion root ğœŒâ‰¼â„ ğ‘šğ›¿, asserting that the root timestamp of ğœŒcomes before ğ›¿with the mappings â„ and ğ‘š. The main relation is the type relation JğœŒKâ„ ğ‘šğœ…. It produces a predicate waiting for ğœ…timestamps, a value ğ‘£, and captures that ğ‘£is of type ğœŒ, given the timestamp mapping â„and type mapping ğ‘š. Apart from timestamps, the seasoned reader of logical relations in Iris will not be surprised by our approach, as it follows the standard recipe [Timany et al. 2024]: a recursive type is interpreted using a guarded fixpoint, universal type quantification is interpreted as a universal quantification in the logic, an array is interpreted using an invariant, and an arrow using WP. Moreover, every predicate is designed such that it is persistent. 5.5 Interpretation of Typing Judgments We now focus on the interpretation of the TypeDis typing judgment, paving our way to state the fundamental theorem of the logical relation. Figure 16 gives its interpretation, appealing to the WP of Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:23 J Î” | Î“ âŠ¢ğ‘’: ğœŒâŠ²ğ›¿K â‰œ âˆ€â„ğ‘šğ‘¢. âŒœdom Î“ = domğ‘¢âŒâˆ’âˆ— âŒœâˆ€ğ›¼ğœ…Î¨ğ‘Ÿ. ğ‘š(ğ›¼) = (ğœ…, (Î¨,ğ‘Ÿ)) =â‡’properğœ…Î¨ âˆ§regularğœ…ğ‘ŸâŒâˆ’âˆ— âˆ—(ğ‘¡1,ğ‘¡2)âˆˆÎ” â„(ğ‘¡1) â‰¼â„(ğ‘¡2) âˆ’âˆ— âˆ—(ğ‘¥,ğœŒ)âˆˆÎ“, (ğ‘¥,ğ‘£)âˆˆğ‘¢(root ğœŒâ‰¼â„ ğ‘šğ›¿âˆ—JğœŒKâ„ ğ‘šâ˜…ğ‘£) âˆ’âˆ— âˆ€ğ‘¡. ğ‘¡â‰ˆâ„(ğ›¿) âˆ’âˆ—wp âŸ¨ğ‘¡, [ğ‘¢/]ğ‘’âŸ©{ğœ†ğ‘£. root ğœŒâ‰¼â„ ğ‘šğ›¿âˆ—JğœŒKâ„ ğ‘šâ˜…ğ‘£} Fig. 16. The interpretation of typing judgments DisLog2. For the judgment with logical graph Î”, type environment Î“, and expression ğ‘’with type ğœŒat timestamp ğ›¿, the interpretation starts by quantifying over three closing substitutions: the timestamp mappingâ„, the type mappingğ‘š, as well as a variable mapping ğ‘¢, a map from term variables to values. The variable mapping must have the same domain as the environment Î“. The type mapping ğ‘š is restricted such that type variables are given only a proper interpretation (via the properğœ…Î¨ property) and a regular root function (via the regularğœ…ğ‘Ÿproperty). The property properğœ…Î¨ captures that any timestamp parameter of Î¨ can be replaced by an equivalent one. The property regularğœ…ğ‘Ÿ captures that the function ğ‘Ÿeither ignores all its arguments or returns one of them. These two properties are needed in order to prove the correctness of T-Par. Then, the interpretation requires that Î” is a valid logical graph, that is, each edge between two timestamp variables in Î” corresponds to an edge between their mapping. The interpretation also requires that, for every variable ğ‘¥that has type ğœŒin Î“ and is associated to value ğ‘£in ğ‘¢, the root timestamp of ğ‘£precedes the interpretation of ğ›¿and ğ‘£inhabits the interpretation of ğœŒ. Next, the definition quantifies over a timestamp ğ‘¡, equivalent to the interpretation of ğ›¿, and asserts WP at timestamp ğ‘¡of the expression ğ‘’in which variables are substituted by values following the variable mapping ğ‘¢. The postcondition asserts that the root timestamp of ğ‘£precedes the interpretation of ğ›¿ and that the returned value ğ‘£inhabits the interpretation of type ğœŒ. Having the interpretation of typing judgment defined, we can state the fundamental theorem, ensuring that syntactically well-typed terms (Â§4) inhabit the logical relation. Theorem 5.3 (Fundamental). If Î” | Î“ âŠ¢ğ‘’: ğœŒâŠ²ğ›¿holds, then J Î” | Î“ âŠ¢ğ‘’: ğœŒâŠ²ğ›¿K holds too. Proof. By induction over the typing derivation; see our mechanization [Moine et al. 2025]. â–¡ 5.6 Putting Pieces Together: The Soundness Proof of TypeDis We can finally unveil the proof of the soundness Theorem 5.1 of TypeDis, which we formally establish in Rocq. Let us suppose that âˆ…| âˆ…âŠ¢ğ‘’: ğœŒâŠ²ğ›¿holds. Making use of the fundamental Theorem 5.3, we deduce that J âˆ…| âˆ…âŠ¢ğ‘’: ğœŒâŠ²ğ›¿K holds too. Unfolding the definition (Fig- ure 16), instantiating the timestamp mapping â„with the singleton map [ğ›¿:= ğ‘¡0]â€”for some initial timestamp ğ‘¡0â€”and the type mapping ğ‘šand the variable mapping ğ‘¢with empty maps, and simplifying trivial premises concerning these mappings, we are left with the statement âˆ€ğ‘¡. ğ‘¡â‰ˆğ‘¡0 âˆ’âˆ— wp âŸ¨ğ‘¡, ğ‘’âŸ©{ğœ†ğ‘£. root ğœŒâ‰¼â„ ğ‘šğ›¿âˆ—JğœŒK[ğ›¿:=ğ‘¡0] âˆ… â˜…ğ‘£}. Instantiating ğ‘¡with ğ‘¡0, we deduce that wp âŸ¨ğ‘¡0, ğ‘’âŸ©{ğœ†ğ‘£. root ğœŒâ‰¼â„ ğ‘šğ›¿âˆ—JğœŒK[ğ›¿:=ğ‘¡0] âˆ… â˜…ğ‘£} holds. We finally use the adequacy Theorem 5.2 of DisLog2 and deduce that ğ‘’is always safe and disentangled. 6 Case Studies We evaluate the usefulness of TypeDis by type-checking several case studies in Rocq using the rules presented in Section 4. We verify the examples presented in the â€œKey Ideasâ€ Section 2. These examples illustrate: simple mechanics of the type system (Â§2.2), backtiming (Â§2.3), and subtiming (Â§2.4). In particular, the last two examples, build and selectmap, illustrate the use of TypeDis with higher-order functions and Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:24 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick parfor â‰œğœ‡ğ‘“. ğœ†[ğ‘;ğ‘;ğ‘˜]. if ğ‘â‰¤ğ‘then () else if (ğ‘âˆ’ğ‘) ==1 then ğ‘˜[ğ‘] else let ğ‘šğ‘–ğ‘‘= ğ‘+ ((ğ‘âˆ’ğ‘)/2) in par(ğ‘“[ğ‘;ğ‘šğ‘–ğ‘‘;ğ‘˜], ğ‘“[ğ‘šğ‘–ğ‘‘;ğ‘;ğ‘˜]) parfor : âˆ€ğ›¿ğ›¿ğ‘˜. int â†’int â†’(âˆ€ğ›¿â€² ğ›¿â‰¼ğ›¿â€². int â†’ğ›¿â€² ())@ğ›¿ğ‘“â†’ğ›¿() Fig. 17. Implementation and type of the parfor primitive a recursive immutable type (a binary tree with integer leaves). For more details than the intuitions we already gave for these examples, we refer the reader to our formalization [Moine et al. 2025]. Our largest case study consists of the typing of a parallel deduplication algorithm via concurrent hashing. This example is a case study of DisLog [Moine et al. 2024, Â§6.3]. Deduplication consists of removing duplicates from an arrayâ€”something that can be done efficiently in a parallel, disentangled setting [Westrick 2022]. The algorithm relies on a folklore [VerifyThis 2022] concurrent, lock-free, fixed-capacity hash set using open addressing and linear probing to handle collisions [Knuth 1998]. The main deduplication function allocates a new hash set, inserts in parallel every element into the hash set using a parallel for loop, and finally returns the elements of the set. We first comment on the parallel for loop (Â§6.1) and then on the main deduplication algorithm (Â§6.2). 6.1 The Parallel For Loop Our implementation of the parallel for loop appears in the upper part of Figure 17 and is a direct translation of MaPLe standard libraryâ€™s implementation [Acar et al. 2020], The function parfor takes three arguments: a lower bound ğ‘, a higher bound ğ‘, and a closure ğ‘˜to execute at each index between these bounds. The function parfor is defined recursively: it returns immediately if ğ‘â‰¤ğ‘, executes the closure ğ‘˜[ğ‘] if ğ‘âˆ’ğ‘= 1, and otherwise calls itself recursively in parallel, splitting the range in two. The type we give to parfor appears in the lower part of Figure 17, and is as one could expect. Indeed, the type quantifies over two timestamps ğ›¿, at which parfor will be called, and ğ›¿ğ‘˜, the (irrelevant) timestamp of the closure. The function then requires two integers, and a closure that will be called at some timestamp ğ›¿â€² that succeeds ğ›¿. The type-checking of parfor is non-trivial because it involves polymorphic recursion. Indeed, parforâ€™s type universally quantifies over the calling timestamp, but calls itself recursively after a parâ€” that is, at another (subsequent) timestamp. TypeDis supports natively such a pattern thanks to T-Abs. Interestingly, polymorphic recursion introduce a need for subtiming. Indeed, while type-checking parforâ€™s body at current timestamp ğ›¿, the closure ğ‘˜has type (âˆ€ğ›¿â€² ğ›¿â‰¼ğ›¿â€². int â†’ğ›¿â€² ()). However, the recursive call happens after a par, hence at a new current timestamp ğ›¿1 such that ğ›¿â‰¼ğ›¿1. But in order to type-check the recursive call, the user has to give to ğ‘˜the type (âˆ€ğ›¿â€² ğ›¿1 â‰¼ğ›¿â€². int â†’ğ›¿â€² ())â€”notice the difference between the precedence information on ğ›¿â€². This is a typical use of subtiming, and because ğ›¿â‰¼ğ›¿1, we conclude using S-Abs. 6.2 Internals of the Deduplication Case Study Let us now focus on the code for our deduplication algorithm, which appears in the upper part of Figure 18. This code assumes a maximum size ğ¶for the underlying hash set. The function dedup takes three arguments: a hashing function â„, a dummy element ğ‘‘in order to populate the result array, and the array to deduplicate â„“. The function first allocates the hash set ğ‘and then calls in parallel the add function for every index in â„“. The function add consists of a CAS loop, that tries to insert the element in the first available slot. Finally, dedup filters the remaining dummy elements ğ‘‘ using an omitted function filter_compact. Because it involves no fork or join, the function add admits a simple polymorphic type, shown in the lower part of Figure 18, quantifying over the Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:25 add â‰œ ğœ†[â„;ğ‘;ğ‘‘;ğ‘¥]. let ğ‘ğ‘¢ğ‘¡= ğœ‡ğ‘“.ğœ†[ğ‘–]. if (CASğ‘ğ‘–ğ‘‘ğ‘¥âˆ¨ğ‘.[ğ‘–] ==ğ‘¥) then () else ğ‘“[(ğ‘–+ 1) mod ğ¶] in ğ‘ğ‘¢ğ‘¡[â„[ğ‘¥] mod ğ¶] dedup â‰œ ğœ†[â„;ğ‘‘; â„“]. let ğ‘= alloc ğ¶ğ‘‘in let ğ‘˜= ğœ†[ğ‘–]. add [â„;ğ‘;ğ‘‘; â„“.[ğ‘–]] in parfor [0; length â„“;ğ‘˜] ; filter_compact [ğ‘;ğ‘‘] add : âˆ€ğ›¼:: â˜…. âˆ€ğ›¿ğ›¿1 ğ›¿2. (ğ›¼â†’ğ›¿int)@ğ›¿1 â†’array(ğ›¼)@ğ›¿2 â†’ğ›¼â†’ğ›¼â†’ğ›¿() dedup : âˆ€ğ›¼:: â˜…. âˆ€ğ›¿ğ›¿1 ğ›¿2. (âˆ€ğ›¿â€² ğ›¿â‰¼ğ›¿â€². ğ›¼â†’ğ›¿â€² int)@ğ›¿1 â†’ğ›¼â†’array(ğ›¼)@ğ›¿2 â†’ğ›¿array(ğ›¼)@ğ›¿ Fig. 18. Case study: deduplication of an array by concurrent hashing type ğ›¼of the elements of the array to deduplicate, the calling timestamp ğ›¿and two timestamps ğ›¿1 and ğ›¿2. The first argument is a closure of a hashing function on ğ›¼that will be called at timestamp ğ›¿. The second argument is the hash set, a array(ğ›¼). The third and fourth arguments are of type ğ›¼and correspond to the dummy element and the element to insert, respectively. Using this type for add, we are able to type-check dedup with the type shown in the lower part of Figure 18. This type quantifies again over the type ğ›¼of the elements of the array to deduplicate, and then quantifies over ğ›¿, the calling timestamp, and ğ›¿1 and ğ›¿2, the (irrelevant) allocation timestamps of the first and third argument, respectively. The first argument is a closure of a hashing function on ğ›¼, that will be called at subsequent tasks ğ›¿â€². The second argument is a dummy element. The third argument is the array to deduplicate. Again, type-checking dedup requires subtiming: the add function expects a hashing function at its calling timestamp ğ›¿, whereas the supplied â„is more general, because it is polymorphic with respect to its calling timestamp. We use subtiming (S-Abs and S-Inst) to convert the latter into the former. 7 Related Work Disentanglement. The specific property we consider in this paper is based on the definition by Westrick et al. [2020] which was later formalized by Moine et al. [2024]. Most of the existing work on disentanglement considers structured fork-join parallel code, as we do in this paper. More recently, Arora et al. [2024] showed that disentanglement is applicable in a more general setting involving parallel futures, and specifically prove deadlock-freedom in this setting. We plan to investigate whether TypeDis could be extended to support futures. Verification of Disentanglement. Two approaches to check for and/or verify disentanglement have been proposed prior to TypeDis. First, as currently implemented in the MaPLe compiler, the programmer can rely on a runtime entanglement detector [Westrick et al. 2022]. This approach is similar in principle to dynamic race detection [Flanagan and Freund 2009]. In the case of entanglement, dynamic detection has been shown to have low overhead, making it suitable for automatic run-time management of entanglement [Arora et al. 2023]. However, run-time detection cannot guarantee disentanglement due to the inherent non-determinism of entanglement, which typically arises due to race conditions and may or may not occur in individual executions. The second approach, as developed by Moine et al. [2024], is full-blown static verification of disentanglement using a separation logic called DisLog, proven sound in Rocq. This approach can be used to statically verify disentanglement for a wide variety of programsâ€”for example, even for non- deterministic programs that utilize intricate lock-free data structures in shared memory. However, static verification with DisLog is difficult, requiring significant effort even to verify small examples. Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:26 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick Region-based Systems. TypeDis associates timestamp variables with values in their types. Im- mediately, we note similarities with region-based type and effect systems [Grossman et al. 2002; Tofte et al. 2004; Tofte and Talpin 1997] which have also recently received attention in supporting parallelism [Elsman and Henriksen 2023]. The timestamps in our setting are somewhat analogous to regions, with parent-child relationships between timestamps and the up-pointer invariant of TypeDis bearing resemblance to the stack discipline of region-based memory management systems. However, there are a number of key differences. In region-based systems, allocations may occur within any region, and all values within a region are all deallocated at the same moment; one chal- lenge in such systems is statically predicting or conservatively bounding the lifetime of every value. In contrast, in TypeDis, allocations only ever occur at the â€œcurrentâ€ timestamp, and timestamps tell you nothing about deallocationâ€”every value in our approach is dynamically garbage collected. Each timestamp in TypeDis is associated with a task within a nested fork-join task structure, and values with the same timestamp are all allocated by the same task (or one of its subtasks). Possible Worlds Type Systems. Our type system falls into what can broadly be categorized as a possible worlds type system. These type systems augment the typing judgment with world modalities (in our case timestamp variables ğ›¿) that occur as syntactic objects in propositions (a.k.a. types), and typing is then carried out relative to an accessibility relation (in our case the logical graph Î”). While our work is the first to contribute a possible worlds type system for disentanglement, world modalities have been successfully used for other purposes. In the context of fork-join parallelism, Muller et al. [2017] employed world modalities to track priorities of tasks and guarantee absence of priority inversions, ensuring responsiveness and interactivity. While Muller et al. [2017] also require their priorities to be partially ordered, as we require timestamps to be partially ordered, their priorities are fixed, whereas ours are not. In the context of message-passing concurrency, world modalities have been employed to verify deadlock-freedom [Balzer et al. 2019], domain accessibility [Caires et al. 2019], and information flow control [Derakhshan et al. 2021, 2024]. This line of work not only differs in underlying computation model, considering a process calculus, but also adopts linear typing to control data races and non-determinism. While disentanglement does not forbid races, adopting some form of linear typing may be an interesting avenue for future work, to admit even more disentangled programs as well-typed, e.g. those with down-pointers. Information Flow Control Type Systems. Information flow type systems [Sabelfeld and Myers 2003; Smith and Volpano 1998; Volpano et al. 1996] can also be viewed as representatives of possible worlds type systems, where modalities capture confidentiality (or integrity) and pc labels, and the accessibility relation is a lattice. Typically, modalities can change by typing. For example, when type-checking the branches of an if statement the pc label is increased to the join of its current value and the confidentiality label of the branching condition. A similar phenomenon happens in TypeDis upon type-checking a fork, where the sibling threads are type-checked at a later timestamp. Besides these similarities in techniques employed, the fundamental invariants preserved by type-checking are different. In our setting it is the â€œno cross-pointers invariantâ€, whereas it is noninterference for IFC type systems. As a result, the metatheory employed also differs: whereas we use a unary logical relation, noninterference demands a binary logical relation. Such a binary logical relation for termination-insensitive noninterference in the context of a sequential, higher-order language with higher-order store, for example, has been contributed by Gregersen et al. [2021]. The authors develop an IFC type system, in the spirit of Flow Caml [Pottier and Simonet 2003; Simonet 2003], with label polymorphism, akin to our timestamp polymorphism. Like our work, the authors use the semantic typing approach supported by the Iris separation logic framework. Similarly, the authors support subtyping on labels, allowing a label to be raised in accordance with the lattice, akin to our subtiming, in accordance with the precedence relation. Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:27 Type Systems for Parallelism and Concurrency. There has been significant work on developing static techniques, especially type systems, to guarantee correctness and safety properties (such as race-freedom, deadlock-freedom, determinism, etc.) for parallel and concurrent programs. For example, the idea of ownership [Clarke et al. 1998; Dietl and MÃ¼ller 2005; MÃ¼ller 2002; Noble et al. 1998] has been exploited to rule out races and deadlocks among threads [Boyapati et al. 2002, 2003; Boyapati and Rinard 2001]. Ownership is also enforced by linear type systems [Wadler 1990], which rule out races by construction and have been successfully employed in message-passing concurrency [Caires et al. 2019; Wadler 2012]. The approach has then been popularized by Rust [Klabnik and Nichols 2023], in particular, focusing on statically restricting aliasing and mutability [Jung et al. 2018a], which in Rust takes the form of ownership and borrowing as well as reference-counted mutexes for maximal flexibility. Recently flexible mode-based systems have been explored, as present in the work on DRFCaml [Georges et al. 2025], which exploits modes (extending Lorenzen et al. [2024]) to distinguish values that can and cannot be safely shared between threads. Other systems leverage region-based techniques to restrict concurrent threads, ensuring safe disjoint access to the heap with minimal annotations [Milano et al. 2022], or leveraging explicit annotations to limit the set of permissible effects on shared parts of the heap [Bocchino Jr. et al. 2009]. Much of these related works focus on the hazards of concurrency: data races, race conditions, non-determinism, and similar issues. Disentanglement (and by extension, TypeDis) focuses on an equally important but different issue, namely, the performance of parallel programs. TypeDis in particular is designed to allow for unrestricted sharing of immutable data (as demonstrated in Section 2.4) mixed with disentangled sharing of mutable data (for example, in Section 6). This support for data sharing is motivated by the implementation of efficient parallel algorithms, many of which rely upon access to shared memory with irregular and/or data-dependent access patterns, which are difficult to statically analyze for safety. For example, Abdi et al. [2024] find that many standard implementations of parallel algorithms are rejected by the Rust type system, yet these same implementations have been shown to be disentangled [Westrick et al. 2022]. We consider one such implementation as a case study in Section 6 and confirm that it is typeable under TypeDis. 8 Conclusion and Future Work Disentanglement is an important property of parallel programs, which can in particular serve for improving performance. This paper introduces TypeDis, a static type system that proves disentanglement. TypeDis annotates types with timestamps, recording for each object the task that allocated it. Moreover, TypeDis supports iso-recursive types, as well as type and timestamp polymorphism. TypeDis allows restamping the timestamps in types using a particular form of subtyping we dub subtiming. This paper focuses on type-checking, that is, given a program annotated with types, checking if these types are valid. We are currently working on a prototype type-checker, written in OCaml. An immediate direction for future work is type inference, that is, generating a valid type for a program. For future work, we plan to use the framework of Odersky et al. [1999], which adapts Hindley-Milner to a system with constrained universal quantification. We believe subtiming and backtiming will be inferrable. One challenging case will be mixing polymorphic recursion with par, which might require annotations in order to remain decidable (this is a known problem in region-based type systems [Tofte and Birkedal 1998]). Acknowledgments We thank Umut A. Acar for sharing his insights during early design discussions and helping us shape the context for this work. We also thank Kashish Raimalani for reviewing an initial draft, and we thank the anonymous reviewers for their helpful comments. Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:28 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick A Appendix A.1 The Kinding Judgment K-Var ğ‘¥:: ğœ…âˆˆÎ“ Î“ âŠ¢ğ‘¥:: ğœ… K-Unboxed Î“ âŠ¢ğœ:: â˜… K-At Î“ âŠ¢ğœ:: â˜… Î“ âŠ¢ğœ@ğ›¿:: â˜… K-Lam Î“ âŠ¢ğœŒ:: ğœ… Î“ âŠ¢ğœ†ğ›¿. ğœŒ:: âŠ²âŠ³ â‡’ğœ… K-App Î“ âŠ¢ğœŒ:: âŠ²âŠ³ â‡’ğœ… Î“ âŠ¢ğœŒğ›¿:: ğœ… K-TAbs ğ›¼:: ğœ…, Î“ âŠ¢ğœŒ:: â˜… Î“ âŠ¢âˆ€ğ›¼:: ğœ…. ğœŒ:: â˜… K-Rec ğ›¼:: â˜…, Î“ âŠ¢ğœ:: â˜… Î“ âŠ¢ğœ‡ğ›¼. ğœ@ğ›¿:: â˜… K-Array Î“ âŠ¢ğœŒ:: â˜… Î“ âŠ¢array(ğœŒ) :: â˜… K-Pair Î“ âŠ¢ğœŒ1 :: â˜… Î“ âŠ¢ğœŒ2 :: â˜… Î“ âŠ¢(ğœŒ1 Ã— ğœŒ2) :: â˜… K-Sum Î“ âŠ¢ğœŒ1 :: â˜… Î“ âŠ¢ğœŒ2 :: â˜… Î“ âŠ¢(ğœŒ1 + ğœŒ2) :: â˜… K-Arrow (âˆ€ğœŒ. ğœŒâˆˆÂ®ğœŒ1 =â‡’Î“ âŠ¢ğœŒ:: â˜…) Î“ âŠ¢ğœŒ2 :: â˜… Î“ âŠ¢âˆ€Â®ğ›¿1 Î”. Â®ğœŒ1 â†’ğ›¿2 ğœŒ2 :: â˜… Fig. 19. Kinding judgment Figure 19 presents the kinding judgment Î“ âŠ¢ğœŒ:: ğœ…, asserting that type ğœŒhas kind ğœ…considering the environment Î“. A.2 The veryPure Predicate VP-Val veryPureğ‘£ VP-Abs veryPure (ğœ‡ğ‘“. ğœ†Â®ğ‘¥.ğ‘’) VP-Var veryPureğ‘¥ VP-Prim veryPureğ‘’1 veryPureğ‘’2 ğ‘’1 âŠ²âŠ³ğ‘’2 VP-Let veryPureğ‘’1 veryPureğ‘’2 letğ‘¥= ğ‘’1 inğ‘’2 VP-Pair veryPureğ‘’1 veryPureğ‘’2 (ğ‘’1,ğ‘’2) VP-Fold veryPureğ‘’ veryPure foldğ‘’ VP-Fold veryPureğ‘’ veryPure unfoldğ‘’ VP-If veryPureğ‘’1 veryPureğ‘’2 veryPureğ‘’3 ifğ‘’1 thenğ‘’2 elseğ‘’3 Fig. 20. The veryPure predicate Figure 20 presents the veryPure predicate over an expression. This predicate ensures that the expression does not contain any array allocation, load, store, par, projection, case, or function call. A.3 Reachability Predicates R-Refl Î” âŠ¢ğ›¿â‰¼ğ›¿ R-Cons (ğ›¿1,ğ›¿2) âˆˆÎ” Î” âŠ¢ğ›¿2 â‰¼ğ›¿3 Î” âŠ¢ğ›¿1 â‰¼ğ›¿3 R-Logical âˆ€ğ›¿1 ğ›¿2. (ğ›¿1,ğ›¿2) âˆˆÎ”â€² =â‡’Î” âŠ¢ğ›¿1 â‰¼ğ›¿2 Î” âŠ¢Î”â€² Fig. 21. The reachability predicates Figure 21 presents the reachability predicates that appear in T-App and in Figure 13. R-Refl asserts that a timestamp can always reach itself. R-Cons asserts that if there is an edge between ğ›¿1 and ğ›¿2 and if ğ›¿2 can reach ğ›¿3, then ğ›¿1 can reach ğ›¿3. R-Logical asserts that a logical graph Î” subsumes a logical graph Î”â€² if every edge between ğ›¿1 and ğ›¿2 in Î”â€² can be simulated in Î”. Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:29 A.4 The â€œValid Variableâ€ Judgment VA-Var ğ›¼= ğ›¼â€² =â‡’Î” âŠ¢ğ›¿1 â‰¼ğ›¿2 Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿2 ğ›¼â€² VA-Base Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿2 ğœ VA-At Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿ğœ Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿2 ğœ@ğ›¿ VA-TAbs ğ›¼â‰ ğ›¼â€² =â‡’Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿2 ğœŒ Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿2 âˆ€ğ›¼â€² :: ğœ…. ğœŒ VA-Pair Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿2 ğœŒ1 Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿2 ğœŒ2 Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿2 (ğœŒ1 Ã— ğœŒ2) VA-Sum Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿2 ğœŒ1 Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿2 ğœŒ2 Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿2 (ğœŒ1 + ğœŒ2) VA-TRec ğ›¼âˆ‰fv(ğœŒ) \ {ğ›¼â€²} Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿2 ğœ‡ğ›¼â€². ğœ@ğ›¿ VA-Array ğ›¼âˆ‰fv(ğœŒ) Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿2 array(ğœŒ) VA-Abs ğ›¼âˆ‰fv( Â®ğœŒâ€²) âˆªfv(ğœŒâ€²â€²) Î” | ğ›¼â†¦â†’ğ›¿1 âŠ¢ğ›¿2 âˆ€Â®ğ›¿â€² Î”â€². Â®ğœŒâ€² â†’ğ›¿ğ‘“ğœŒâ€²â€² Fig. 22. The â€œvalid variableâ€ judgment Figure 22 presents the â€œvalid variableâ€ judgment that is used for subtiming recursive types (S-Rec). A.5 The Root Functions and Assertions answer â‰œTimestampğ›¿| Unboxed | Nonsense rootfâ„ğ‘šğœ…ğœŒ : fkindğœ…answer rootfâ„ğ‘šğœ…ğ›¼â‰œifğ‘š(ğ›¼) = (ğœ…, (_,ğ‘Ÿ)) thenğ‘Ÿelse Nonsenseğœ… rootfâ„ğ‘šâ˜…ğœâ‰œUnboxed rootfâ„ğ‘šâ˜…(ğœ@ğ›¿) â‰œTimestampğ›¿ rootfâ„ğ‘š( âŠ²âŠ³ â‡’ğœ…) (ğœ†ğ›¿. ğœŒ) â‰œğœ†ğ‘¡. rootf ([ğ›¿:= ğ‘¡]â„) ğ‘šğœ…ğœŒ rootfâ„ğ‘šğœ…(ğœŒğ›¿) â‰œ(rootfâ„ğ‘š( âŠ²âŠ³ â‡’ğœ…) ğœŒ) (â„(ğ›¿)) rootfâ„ğ‘šâ˜…(âˆ€ğ›¼:: ğœ…. ğœŒ) â‰œrootfâ„([ğ›¼:= Nonsenseğœ…]ğ‘š) â˜…ğœŒ rootfâ„ğ‘šâ˜…(ğœ‡ğ›¼. ğœ@ğ›¿) â‰œTimestampğ›¿ root ğœŒâ‰¼â„ ğ‘šğ›¿â‰œmatch (rootfâ„ğ‘šâ˜…ğœŒ) with | Unboxed â‡’âŒœğ‘‡ğ‘Ÿğ‘¢ğ‘’âŒ | Nonsense â‡’âŒœğ¹ğ‘ğ‘™ğ‘ ğ‘’âŒ | Timestampğ›¿â€² â‡’â„(ğ›¿â€²) â‰¼â„(ğ›¿) Fig. 23. Root-related functions and assertions Figure 23 presents the rootf function, expecting a timestamp mapping â„, a type mapping ğ‘š, a kind ğœ…and a type ğœŒ, and produces a function expecting ğœ…timestamps and returning an â€œanswerâ€, representing the root timestamp of ğœŒ. An answer is either a timestamp, Unboxed to indicate an unboxed type, of Nonsense if the type has no sensible root timestamp (for example, âˆ€ğ›¼:: ğœ…. ğ›¼). In this definition, we write Nonsenseğœ…the function expecting ğœ…arguments and returning Nonsense. The assertion root ğœŒâ‰¼â„ ğ‘šğ›¿, also presented in Figure 23 matches root timestamp of ğœŒ. If it is unboxed, the assertion is true, if it is nonsensical, the assertion is false, and if it is a regular timestamp ğ›¿â€², then â„(ğ›¿â€²) must precede â„(ğ›¿). A.6 Definition of our Logical Relations Figure 24 presents the logical relations we define. Formally, we define the (meta-type-level) function fkindğœ…ğ´producing a function waiting for ğœ…timestamps and returning something of type ğ´. This function is defined by induction over the kind ğœ…. Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:30 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick fkind â˜…ğ‘â‰œğ´ fkind ( âŠ²âŠ³ â‡’ğœ…) ğ´â‰œT â†’fkindğœ…ğ´ JğœŒKâ„ ğ‘šğœ… : fkindğœ…(V â†’iProp) Jğ›¼Kâ„ ğ‘šğœ…â‰œ ( Î¨ âˆ—ğœ… ğœ…ğ‘Ÿ if ğ‘š(ğ›¼) = (ğœ…, (Î¨,ğ‘Ÿ)) âŠ¥ğœ… else JğœKâ„ ğ‘šâ˜…â‰œğœ†ğ‘£. âŒœğœ= () âˆ§ğ‘£= ()âŒâˆ¨âŒœğœ= bool âˆ§ğ‘£âˆˆ{true, false}âŒâˆ¨âŒœğœ= int âˆ§ğ‘£âˆˆZâŒ Jğœ@ğ›¿Kâ„ ğ‘šâ˜…â‰œğœ†ğ‘£. ğ‘£ â„(ğ›¿) âˆ—JJğœKKâ„ ğ‘šğ›¿ğ‘£ Jğœ‡ğ›¼. ğœ@ğ›¿Kâ„ ğ‘šâ˜…â‰œğœ‡(Î¨ : V â†’iProp). ğœ†ğ‘£. âˆƒğ‘¤. âŒœğ‘£= vfoldğ‘¤âŒâˆ—ğ‘¤ â„(ğ›¿) âˆ—âŠ²JJğœKKâ„ [ğ›¼:=(â˜…,(Î¨,â„(ğ›¿)))]ğ‘šğ›¿ğ‘£ Jâˆ€ğ›¼:: ğœ…. ğœŒKâ„ ğ‘šâ˜…â‰œğœ†ğ‘£. âˆ€(Î¨ : fkindğœ…(V â†’iProp)) (ğ‘Ÿ: fkindğœ…T). âŒœproperğœ…Î¨ âˆ§regularğœ…ğ‘ŸâŒâˆ’âˆ—JğœŒKâ„ [ğ›¼:=(ğœ…,(Î¨,ğ‘Ÿ))]ğ‘šâ˜…ğ‘£ Jğœ†ğ›¿. ğœŒKâ„ ğ‘š( âŠ²âŠ³ â‡’ğœ…) â‰œğœ†ğ‘¡. JğœŒK[ğ›¿:=ğ‘¡]â„ ğ‘š ğœ… JğœŒğ›¿Kâ„ ğ‘šğœ…â‰œJğœŒKâ„ ğ‘š( âŠ²âŠ³ â‡’ğœ…) â„(ğ›¿) LğœŒMâ„ ğ‘šâ‰œğœ†ğ›¿ğ‘£. root ğœŒâ‰¼â„ ğ‘šğ›¿âˆ—JğœŒKâ„ ğ‘šâ˜…ğ‘£ JJğœKKâ„ ğ‘š : T â†’V â†’iProp JJarray(ğœŒ)KKâ„ ğ‘šâ‰œğœ†ğ›¿ğ‘£. âˆƒâ„“. âŒœğ‘£= â„“âŒâˆ—âˆƒÂ®ğ‘¤. â„“â†¦â†’Â®ğ‘¤âˆ—âˆ—ğ‘£â€²âˆˆÂ®ğ‘¤(LğœŒMâ„ ğ‘šğ›¿ğ‘£â€²) JJ(ğœŒ1 Ã— ğœŒ2)KKâ„ ğ‘šâ‰œğœ†ğ›¿ğ‘£. âˆƒâ„“ğ‘£1 ğ‘£2. âŒœğ‘£= â„“âŒâˆ—â„“â†¦â†’ (ğ‘£1, ğ‘£2) âˆ—LğœŒ1Mâ„ ğ‘šğ›¿ğ‘£1 âˆ—LğœŒ2Mâ„ ğ‘šğ›¿ğ‘£2 JJ(ğœŒ1 + ğœŒ2)KKâ„ ğ‘šâ‰œğœ†ğ›¿ğ‘£. âˆƒâ„“ğ‘£â€². âŒœğ‘£= â„“âŒâˆ— (â„“â†¦â†’ inj1 ğ‘£â€² âˆ—LğœŒ1Mâ„ ğ‘šğ›¿ğ‘£â€²) âˆ¨(â„“â†¦â†’ inj2 ğ‘£â€² âˆ—LğœŒ2Mâ„ ğ‘šğ›¿ğ‘£â€²) JJâˆ€Â®ğ›¿1 Î”1. Â®ğœŒ1 â†’ğ›¿ğ‘“ğœŒ2KKâ„ ğ‘šâ‰œğœ†ğ›¿ğ‘£. âˆ€Â®ğ‘¡Â®ğ‘¤. âŒœ| Â®ğ›¿1| = |Â®ğ‘¡| âˆ§| Â®ğœŒ1| = | Â®ğ‘¤|âŒâˆ’âˆ— letâ„â€² = [ Â®ğ›¿1 := Â®ğ‘¡]â„in â„(ğ›¿) â‰¼â„â€²(ğ›¿ğ‘“) âˆ’âˆ—JÎ”1Kâ„â€² âˆ’âˆ—âˆ—ğœŒâˆˆÂ®ğœŒ1, ğ‘£â€²âˆˆÂ®ğ‘¤(LğœŒMâ„â€² ğ‘šğ‘£â€²) âˆ’âˆ— âˆ€ğ‘¡â€². ğ‘¡â€² â‰ˆâ„â€²(ğ›¿ğ‘“) âˆ’âˆ—wp âŸ¨ğ‘¡â€², ğ‘£Â®ğ‘¤âŸ©{ğœ†ğ‘£â€². LğœŒ2Mâ„â€² ğ‘šğ‘£â€²} Fig. 24. The interpretation of types More precisely, Figure 24 presents the type relation and the boxed type relation. The type relation JğœŒKâ„ ğ‘šğœ…produces a function waiting for ğœ…timestamps, a value ğ‘£, and captures that ğ‘£is of type ğœŒ, within the timestamp mapping â„and type mapping ğ‘š. The boxed type relation JJğœKKâ„ ğ‘š produces a predicate over a timestamp ğ›¿and a value ğ‘£, capturing that ğ‘£is of type ğœallocated at ğ›¿, within the timestamp mapping â„and type mapping ğ‘š. The type relation and the boxed type relation are defined by mutual induction over their type argument. The omitted cases are all sent to âŠ¥ğœ…, the always false predicate ignoring its ğœ…arguments. Interpretation of types. Let us first present the relation JğœŒKâ„ ğ‘šğœ…. If ğœŒis a variable ğ›¼, then ğ›¼must have kind ğœ…in the type mapping ğ‘š, linked with predicate Î¨ and timestamp function ğ‘Ÿ. The relation returns the predicate Î¨ âˆ—ğœ… ğœ…ğ‘Ÿ. The operator âˆ—ğœ…lifts the separating conjunction to predicated in fkindğœ…(V â†’iProp) by distributing ğœ…timestamp arguments and a value to Î¨ and ğœ…ğ‘Ÿ. The predicate ğœ…ğ‘Ÿis of type fkindğœ…(V â†’iProp); it feeds ğœ… timestamps to ğ‘Ÿ, and asserts that the value argument was allocated before the result of ğ‘Ÿ. For example, in the particular case of ğœ…= âŠ²âŠ³ â‡’â˜…, we have that Î¨ âˆ—ğœ… ğœ…ğ‘Ÿ= ğœ†ğ›¿ğ‘£. Î¨ğ›¿ğ‘£âˆ—ğ‘£ (ğ‘Ÿğ›¿). If ğœŒis a base type ğœ, the kind must be the base kind â˜…, and the relation binds a value which must correspond to the particular base type under consideration. If ğœŒis a boxed type ğœ@ğœŒ, the kind must be â˜…, and the relation binds a value ğ‘£which must have been allocated before â„(ğ›¿), the timestamp associated to ğ›¿in â„. The relation also ensures that ğ‘£ recursively satisfies the interpretation of ğœ. Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:31 If ğœŒis a recursive type ğœ‡ğ›¼. ğœ@ğ›¿, the kind must be â˜…, and the relation is expressed as a guarded fixed-point. Intuitively, the predicate Î¨, from a value to iProp, captures the interpretation of the recursive type itself. The interpretation binds a value ğ‘£and asserts that it is of the form vfoldğ‘¤. The interpretation is then similar to a boxed type: ğ‘¤must have been allocated before â„(ğ›¿) and be in relation with the interpretation of ğœ, with a type environment updated to bind ğ›¼to Î¨ as well as the root timestamp â„(ğ›¿). If ğœŒis a type abstraction âˆ€ğ›¼:: ğœ…. ğœŒ, the kind must be â˜…, and the relation binds a value ğ‘£. The relation universally quantifies over the predicate Î¨ and the timestamp function ğ‘Ÿ, which will be instantiated during the T-TApp rule. Both Î¨ and ğ‘Ÿare constrained. The property properğœ…Î¨ captures that any timestamp parameter of Î¨ can be replaced by an equivalent one. The property regularğœ…ğ‘Ÿ captures that the function ğ‘Ÿeither ignores all its arguments or returns one of them. These two properties are needed in order to prove that T-Par is sound. The relation then calls itself recursively on ğœŒ, augmenting the type mapping by associating ğ›¼to its kind ğœ…and the pair of Î¨ and ğ‘Ÿ. If ğœŒis a timestamp abstraction ğœ†ğ›¿. ğœŒ, the kind must be of the form âŠ²âŠ³ â‡’ğœ…, and the relation expands to a function waiting for a timestamp ğ›¿and adding it to the timestamp mapping â„. If ğœŒis a timestamp application ğœŒğ›¿at some kind ğœ…, then the relation applies the timestamp â„(ğ›¿) to the interpretation of ğœŒat kind âŠ²âŠ³ â‡’ğœ…. Interpretation of boxed types. The enriched type interpretation LğœŒMâ„ ğ‘š, defined next in Figure 24, is a predicate over a timestamp ğ›¿and a value ğ‘£. It asserts that the root timestamp of ğœŒcomes before ğ›¿ and that ğ‘£is in relation with the interpretation of ğœŒ. This wrapper in used for the interpretation of boxed types, which we present next. The interpretation of boxed types is written JJğœKKâ„ ğ‘šand is a predicate over a timestamp variable ğ›¿and a value ğ‘£. If ğœis an array array(ğœŒ), then ğ‘£must be a location â„“, such that â„“points-to an array Â®ğ‘¤and that for each value ğ‘£â€² in Â®ğ‘¤is in relation with the enriched interpretation of ğœŒ. The points-to assertion and the relation on the values of the array appears inside an invariant, ensuring their persistence. If ğœis a pair (ğœŒ1 Ã— ğœŒ2), then ğ‘£must be a location â„“pointing to a pair of values (ğ‘£1, ğ‘£2) such that ğ‘£1 (resp. ğ‘£2) is in relation with the enriched interpretation of ğœŒ1 (resp. ğœŒ2). The sum case is similar. If ğœis an arrow âˆ€Â®ğ›¿1 Î”1. Â®ğœŒ1 â†’ğ›¿ğ‘“ğœŒ2, then the interpretation quantifies over the list of timestamp arguments Â®ğ‘¡and the list of arguments of the function Â®ğ‘¤, which must both have the correct length. The relation then defines â„â€², the new timestamp environment, being â„where Â®ğ›¿1 are instantiated with Â®ğ‘¡. The relation next requires that the allocation timestamp â„(ğ›¿) precedes the timestamp of the caller â„â€²(ğ›¿ğ‘“), and that every value in Â®ğ‘¤is of the correct type. Last, the relation requires that for any timestamp equivalent to â„â€²(ğ›¿ğ‘“), the WP of the function call holds, and that the returned value is in relation with the enriched interpretation of the return type ğœŒ2. Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:32 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick References Javad Abdi, Gilead Posluns, Guozheng Zhang, Boxuan Wang, and Mark C. Jeffrey. 2024. When Is Parallelism Fearless and Zero-Cost with Rust?. In Proceedings of the 36th ACM Symposium on Parallelism in Algorithms and Architectures, SPAA 2024, Nantes, France, June 17-21, 2024, Kunal Agrawal and Erez Petrank (Eds.). ACM, 27â€“40. doi:10.1145/3626183.3659966 Umut A. Acar, Jatin Arora, Matthew Fluet, Ram Raghunathan, Sam Westrick, and Rohan Yadav. 2020. MPL: A high- performance compiler for Parallel ML. https://github.com/MPLLang/mpl Umut A. Acar, Guy E. Blelloch, Matthew Fluet, Stefan K. Muller, and Ram Raghunathan. 2015. Coupling Memory and Computation for Locality Management. In 1st Summit on Advances in Programming Languages, SNAPL 2015, May 3-6, 2015, Asilomar, California, USA (LIPIcs, Vol. 32), Thomas Ball, Rastislav BodÃ­k, Shriram Krishnamurthi, Benjamin S. Lerner, and Greg Morrisett (Eds.). Schloss Dagstuhl - Leibniz-Zentrum fÃ¼r Informatik, 1â€“14. doi:10.4230/LIPICS.SNAPL.2015.1 Umut A. Acar, Arthur CharguÃ©raud, Mike Rainey, and Filip Sieczkowski. 2016. Dag-calculus: a calculus for parallel computation. In International Conference on Functional Programming (ICFP). 18â€“32. https://doi.org/10.1145/2951913. 2951946 Daniel Anderson, Guy E. Blelloch, Laxman Dhulipala, Magdalen Dobson, and Yihan Sun. 2022. The problem-based benchmark suite (PBBS), V2. In PPoPP â€™22: 27th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, Seoul, Republic of Korea, April 2 - 6, 2022, Jaejin Lee, Kunal Agrawal, and Michael F. Spear (Eds.). ACM, 445â€“447. doi:10.1145/3503221.3508422 Andrew W. Appel. 1992. Compiling with Continuations. Cambridge University Press. http://www.cambridge.org/ 9780521033114 Jatin Arora, Stefan K. Muller, and Umut A. Acar. 2024. Disentanglement with Futures, State, and Interaction. Proc. ACM Program. Lang. 8, POPL (2024), 1569â€“1599. doi:10.1145/3632895 Jatin Arora, Sam Westrick, and Umut A. Acar. 2021. Provably space-efficient parallel functional programming. Proc. ACM Program. Lang. 5, POPL (2021), 1â€“33. doi:10.1145/3434299 Jatin Arora, Sam Westrick, and Umut A. Acar. 2023. Efficient Parallel Functional Programming with Effects. Proc. ACM Program. Lang. 7, PLDI (2023), 1558â€“1583. doi:10.1145/3591284 Stephanie Balzer, Bernardo Toninho, and Frank Pfenning. 2019. Manifest Deadlock-Freedom for Shared Session Types. In 28th European Symposium on Programming (ESOP) (Lecture Notes in Computer Science, Vol. 11423). Springer, 611â€“639. doi:10.1007/978-3-030-17184-1_22 Henk P. Barendregt. 1984. The Lambda Calculus, Its Syntax and Semantics. Elsevier. http://www.elsevier.com/wps/find/ bookdescription.cws_home/501727/description Robert L. Bocchino Jr., Vikram S. Adve, Danny Dig, Sarita V. Adve, Stephen Heumann, Rakesh Komuravelli, Jeffrey Overbey, Patrick Simmons, Hyojin Sung, and Mohsen Vakilian. 2009. A type and effect system for deterministic parallel Java. In Proceedings of the 24th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2009, October 25-29, 2009, Orlando, Florida, USA, Shail Arora and Gary T. Leavens (Eds.). ACM, 97â€“116. doi:10.1145/1640089.1640097 Chandrasekhar Boyapati, Robert Lee, and Martin C. Rinard. 2002. Ownership types for safe programming: preventing data races and deadlocks. In ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages and Applications (OOPSLA). ACM, 211â€“230. doi:10.1145/582419.582440 Chandrasekhar Boyapati, Barbara Liskov, and Liuba Shrira. 2003. Ownership types for object encapsulation. In 30th SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL). ACM, 213â€“223. doi:10.1145/604131.604156 Chandrasekhar Boyapati and Martin C. Rinard. 2001. A Parameterized Type System for Race-Free Java Programs. In ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages and Applications (OOPSLA). ACM, 56â€“69. doi:10.1145/504282.504287 LuÃ­s Caires, Jorge A. PÃ©rez, Frank Pfenning, and Bernardo Toninho. 2019. Domain-Aware Session Types. In 30th International Conference on Concurrency Theory (CONCUR) (LIPIcs, Vol. 140). Schloss Dagstuhl - Leibniz-Zentrum fÃ¼r Informatik, 39:1â€“39:17. doi:10.4230/LIPICS.CONCUR.2019.39 David G. Clarke, John Potter, and James Noble. 1998. Ownership Types for Flexible Alias Protection. In ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages and Applications (OOPSLA). ACM, 48â€“64. doi:10.1145/ 286936.286947 Robert L. Constable, Stuart F. Allen, Mark Bromley, Rance Cleaveland, J. F. Cremer, Robert Harper, Douglas J. Howe, Todd B. Knoblock, Nax Paul Mendler, Prakash Panangaden, James T. Sasaki, and Scott F. Smith. 1986. Implementing Mathematics with the Nuprl Proof Development System. Prentice Hall. http://dl.acm.org/citation.cfm?id=10510 Paulo EmÃ­lio de Vilhena. 2022. Proof of Programs with Effect Handlers. Theses. UniversitÃ© Paris CitÃ©. https://inria.hal. science/tel-03891381 Farzaneh Derakhshan, Stephanie Balzer, and Limin Jia. 2021. Session Logical Relations for Noninterference. In 36th Annual ACM/IEEE Symposium on Logic in Computer Science (LICS). IEEE Computer Society, 1â€“14. doi:10.1109/LICS52264.2021. 9470654 Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. TypeDis: A Type System for Disentanglement 13:33 Farzaneh Derakhshan, Stephanie Balzer, and Yue Yao. 2024. Regrading Policies for Flexible Information Flow Control in Session-Typed Concurrency. In 38th European Conference on Object-Oriented Programming (ECOOP) (LIPIcs, Vol. 313). Schloss Dagstuhl - Leibniz-Zentrum fÃ¼r Informatik, 11:1â€“11:29. doi:10.4230/LIPICS.ECOOP.2024.11 Werner Dietl and Peter MÃ¼ller. 2005. Universes: Lightweight Ownership for JML. Journal of Object Technology 4, 8 (2005), 5â€“32. doi:10.5381/JOT.2005.4.8.A1 Martin Elsman and Troels Henriksen. 2023. Parallelism in a Region Inference Context. Proc. ACM Program. Lang. 7, PLDI (2023), 884â€“906. doi:10.1145/3591256 Cormac Flanagan and Stephen N. Freund. 2009. FastTrack: efficient and precise dynamic race detection. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI). ACM, 121â€“133. doi:10.1145/1542476.1542490 AÃ¯na Linn Georges, Benjamin Peters, Laila Elbeheiry, Leo White, Stephen Dolan, Richard A. Eisenberg, Chris Casinghino, FranÃ§ois Pottier, and Derek Dreyer. 2025. Data Race Freedom Ã  la Mode. Proc. ACM Program. Lang. 9, POPL (2025), 656â€“686. doi:10.1145/3704859 Jean-Yves Girard. 1972. InterprÃ©tation fonctionnelle et Ã©limination des coupures de lâ€™arithmÃ©tique dâ€™ordre supÃ©rieur. ThÃ¨se dâ€™Ã‰tat. UniversitÃ© Paris 7. https://girard.perso.math.cnrs.fr/These.pdf Simon Oddershede Gregersen, Johan Bay, Amin Timany, and Lars Birkedal. 2021. Mechanized logical relations for termination-insensitive noninterference. Proc. ACM Program. Lang. 5, POPL (2021), 1â€“29. doi:10.1145/3434291 Dan Grossman, J. Gregory Morrisett, Trevor Jim, Michael W. Hicks, Yanling Wang, and James Cheney. 2002. Region-Based Memory Management in Cyclone. In Proceedings of the 2002 ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), Berlin, Germany, June 17-19, 2002, Jens Knoop and Laurie J. Hendren (Eds.). ACM, 282â€“293. doi:10.1145/512529.512563 Adrien Guatto, Sam Westrick, Ram Raghunathan, Umut A. Acar, and Matthew Fluet. 2018. Hierarchical memory management for mutable state. In Proceedings of the 23rd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPoPP 2018, Vienna, Austria, February 24-28, 2018, Andreas Krall and Thomas R. Gross (Eds.). ACM, 81â€“93. doi:10.1145/ 3178487.3178494 Ralf Jung, Jacques-Henri Jourdan, Robbert Krebbers, and Derek Dreyer. 2018a. RustBelt: Securing the Foundations of the Rust Programming Language. Proceedings of the ACM on Programming Languages 2, POPL (2018), 66:1â€“66:34. https://people.mpi-sws.org/~dreyer/papers/rustbelt/paper.pdf Ralf Jung, Robbert Krebbers, Jacques-Henri Jourdan, AleÅ¡ Bizjak, Lars Birkedal, and Derek Dreyer. 2018b. Iris from the ground up: A modular foundation for higher-order concurrent separation logic. Journal of Functional Programming 28 (2018), e20. https://people.mpi-sws.org/~dreyer/papers/iris-ground-up/paper.pdf Steve Klabnik and Carol Nichols. 2023. The Rust programming language. No Starch Press. Donald E. Knuth. 1998. The Art of Computer Programming, Volume 3: (2nd Ed.) Sorting and Searching. Addison Wesley Longman Publishing Co., Inc., USA. Peter J. Landin. 1964. The Mechanical Evaluation of Expressions. Computer Journal 6, 4 (Jan. 1964), 308â€“320. Anton Lorenzen, Leo White, Stephen Dolan, Richard A. Eisenberg, and Sam Lindley. 2024. Oxidizing OCaml with Modal Memory Management. Proc. ACM Program. Lang. 8, ICFP (2024), 485â€“514. doi:10.1145/3674642 Per Martin-LÃ¶f. 1982. Constructive Mathematics and Computer Programming. In Logic, Methodology and Philosophy of Science VI. Studies in Logic and the Foundations of Mathematics, Vol. 104. Elsevier, 153â€“175. doi:10.1016/S0049-237X(09)70189-2 Mae Milano, Joshua Turcotti, and Andrew C. Myers. 2022. A flexible type system for fearless concurrency. In PLDI â€™22: 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation, San Diego, CA, USA, June 13 - 17, 2022, Ranjit Jhala and Isil Dillig (Eds.). ACM, 458â€“473. doi:10.1145/3519939.3523443 Robin Milner. 1978. A Theory of Type Polymorphism in Programming. J. Comput. System Sci. 17, 3 (Dec. 1978), 348â€“375. http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.67.5276 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick. 2025. TypeDis: A Type System for Disentanglement (Artifact). doi:10.5281/zenodo.17336385 Alexandre Moine, Sam Westrick, and Stephanie Balzer. 2024. DisLog: A Separation Logic for Disentanglement. Proc. ACM Program. Lang. 8, POPL, Article 11 (Jan. 2024), 30 pages. doi:10.1145/3632853 Peter MÃ¼ller. 2002. Modular Specification and Verification of Object-Oriented Programs. Lecture Notes in Computer Science, Vol. 2262. Springer. doi:10.1007/3-540-45651-1 Stefan K. Muller, Umut A. Acar, and Robert Harper. 2017. Responsive parallel computation: bridging competitive and cooperative threading. In 38th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI). ACM, 677â€“692. doi:10.1145/3062341.3062370 James Noble, Jan Vitek, and John Potter. 1998. Flexible Alias Protection. In 12th European Conference on Object-Oriented Programming (ECOOP) (Lecture Notes in Computer Science, Vol. 1445). Springer, 158â€“185. doi:10.1007/BFB0054091 Martin Odersky, Martin Sulzmann, and Martin Wehr. 1999. Type Inference with Constrained Types. Theory and Practice of Object Systems 5, 1 (1999), 35â€“55. https://doi.org/10.1002/(SICI)1096-9942(199901/03)5:1%3C35::AID-TAPO4%3E3.0.CO;2- 4 Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026. 13:34 Alexandre Moine, Stephanie Balzer, Alex Xu, and Sam Westrick Benjamin C. Pierce. 2002. Types and Programming Languages. MIT Press. Andrew M. Pitts and Ian Stark. 1998. Operational Reasoning for Functions with Local State. Higher Order Operational Techniques in Semantics (HOOTS) (1998), 227â€“273. Gordon D. Plotkin. 1973. Lambda-definability and logical relations. Technical Report. University of Edinburgh. FranÃ§ois Pottier and Vincent Simonet. 2003. Information flow inference for ML. ACM Transactions on Programming Languages and Systems (TOPLAS) 25, 1 (2003), 117â€“158. doi:10.1145/596980.596983 Ram Raghunathan, Stefan K. Muller, Umut A. Acar, and Guy E. Blelloch. 2016. Hierarchical memory management for parallel programs. In Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming, ICFP 2016, Nara, Japan, September 18-22, 2016, Jacques Garrigue, Gabriele Keller, and Eijiro Sumii (Eds.). ACM, 392â€“406. doi:10.1145/2951913.2951935 Andrei Sabelfeld and Andrew C. Myers. 2003. Language-Based Information-Flow Security. IEEE J. Sel. Areas Commun. 21, 1 (2003), 5â€“19. Julian Shun, Guy E. Blelloch, Jeremy T. Fineman, Phillip B. Gibbons, Aapo Kyrola, Harsha Vardhan Simhadri, and Kanat Tangwongsan. 2012. Brief announcement: the problem based benchmark suite. In 24th ACM Symposium on Parallelism in Algorithms and Architectures, SPAA â€™12, Pittsburgh, PA, USA, June 25-27, 2012, Guy E. Blelloch and Maurice Herlihy (Eds.). ACM, 68â€“70. doi:10.1145/2312005.2312018 Vincent Simonet. 2003. Flow Caml in a Nutshell. In 1st APPSEM-II Workshop, Graham Hutton (Ed.). Geoffrey Smith and Dennis M. Volpano. 1998. Secure Information Flow in a Multi-Threaded Imperative Language. In POPL. ACM, 355â€“364. Richard Statman. 1985. Logical Relations and the Typed ğœ†-calculus. Information and Control 65, 2/3 (1985), 85â€“97. doi:10. 1016/S0019-9958(85)80001-2 William W. Tait. 1967. Intensional Interpretations of Functionals of Finite Type I. The Journal of Symbolic Logic 32, 2 (1967), 198â€“212. http://www.jstor.org/stable/2271658 Amin Timany, Robbert Krebbers, Derek Dreyer, and Lars Birkedal. 2024. A Logical Approach to Type Soundness. J. ACM 71, 6, Article 40 (Nov. 2024), 75 pages. doi:10.1145/3676954 Mads Tofte and Lars Birkedal. 1998. A Region Inference Algorithm. ACM Trans. Program. Lang. Syst. 20, 4 (1998), 724â€“767. doi:10.1145/291891.291894 Mads Tofte, Lars Birkedal, Martin Elsman, and Niels Hallenberg. 2004. A Retrospective on Region-Based Memory Management. Higher-Order and Symbolic Computation 17, 3 (Sept. 2004), 245â€“265. https://doi.org/10.1023/B: LISP.0000029446.78563.a4 Mads Tofte and Jean-Pierre Talpin. 1997. Region-based memory management. Information and Computation 132, 2 (1997), 109â€“176. http://www.irisa.fr/prive/talpin/papers/ic97.pdf VerifyThis. 2022. Challenge 3 - The Worldâ€™s Simplest Lock-Free Hash Set. https://ethz.ch/content/dam/ethz/special- interest/infk/chair-program-method/pm/documents/Verify%20This/Challenges2022/verifyThis2022-challenge3.pdf Simon Friis Vindum and Lars Birkedal. 2021. Contextual refinement of the Michael-Scott queue. In Certified Programs and Proofs (CPP). 76â€“90. https://cs.au.dk/~birke/papers/2021-ms-queue-final.pdf Dennis M. Volpano, Cynthia E. Irvine, and Geoffrey Smith. 1996. A Sound Type System for Secure Flow Analysis. J. Comput. Secur. 4, 2/3 (1996), 167â€“188. Philip Wadler. 1990. Linear Types Can Change the World!. In IFIP Working Group 2.2, 2.3 on Programming Concepts and Methods. North-Holland, 561. Philip Wadler. 2012. Propositions as Sessions. In ACM SIGPLAN International Conference on Functional Programming (ICFP). ACM, 273â€“286. doi:10.1145/2364527.2364568 Sam Westrick. 2022. Efficient and Scalable Parallel Functional Programming through Disentanglement. Ph. D. Dissertation. Department of Computer Science, Carnegie Mellon University. Sam Westrick, Jatin Arora, and Umut A. Acar. 2022. Entanglement Detection with Near-Zero Cost. Proc. ACM Program. Lang. 6, ICFP, Article 115 (aug 2022), 32 pages. doi:10.1145/3547646 Sam Westrick, Rohan Yadav, Matthew Fluet, and Umut A. Acar. 2020. Disentanglement in Nested-Parallel Programs. Proc. ACM Program. Lang. 4, POPL, Article 47 (jan 2020), 32 pages. doi:10.1145/3371115 Andrew K. Wright. 1995. Simple Imperative Polymorphism. Lisp and Symbolic Computation 8, 4 (Dec. 1995), 343â€“356. http://www.cs.rice.edu/CS/PLT/Publications/Scheme/lasc95-w.ps.gz Received 2025-07-10; accepted 2025-11-06 Proc. ACM Program. Lang., Vol. 10, No. POPL, Article 13. Publication date: January 2026.