IEEE Copyright Notice ©2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works. Accepted to be Published in: Proceedings of the 2022 International Joint Conference on Neural Networks (IJCNN 2022), 18-23 July, 2022, Padua, Italy. arXiv:2205.13273v1 [cs.CV] 26 May 2022 Acute Lymphoblastic Leukemia Detection Using Hypercomplex-Valued Convolutional Neural Networks 1st Guilherme Vieira Department of Applied Mathematics University of Campinas Campinas, Brazil email: vieira.g@ime.unicamp.br 2nd Marcos Eduardo Valle Department of Applied Mathematics University of Campinas Campinas, Brazil email: valle@ime.unicamp.br Abstract—This paper features convolutional neural networks deﬁned on hypercomplex algebras applied to classify lymphocytes in blood smear digital microscopic images. Such classiﬁcation is helpful for the diagnosis of acute lymphoblast leukemia (ALL), a type of blood cancer. We perform the classiﬁcation task using eight hypercomplex-valued convolutional neural networks (HvCNNs) along with real-valued convolutional networks. Our results show that HvCNNs perform better than the real-valued model, showcasing higher accuracy with a much smaller number of parameters. Moreover, we found that HvCNNs based on Clifford algebras processing HSV-encoded images attained the highest observed accuracies. Precisely, our HvCNN yielded an average accuracy rate of 96.6% using the ALL-IDB2 dataset with a 50% train-test split, a value extremely close to the state- of-the-art models but using a much simpler architecture with signiﬁcantly fewer parameters. Index Terms—Convolutional neural network, hypercomplex algebras, Clifford algebras, Acute Lymphoblastic Leukemia, computer assisted diagnosis. I. INTRODUCTION Over the past few decades, artiﬁcial neural networks (ANN) have been employed on various classiﬁcation tasks, many of them previously performed by humans. One popular ex- ample is the computer-assisted diagnosis (CAD), in which the output of the ANN may assist doctors in making more accurate decisions [1]. Most applications in CAD consist of a machine learning model performing tasks that would be handmade by specialists, reducing the ﬁnancial and human costs while also avoiding possible mistakes caused by fatigue [2], [3]. Moreover, computers have been repeatedly appointed as outperforming unaided professionals in these tasks [3], [4]. CAD applications have been effectively used, for example, for leukemia identiﬁcation [5]. Acute lymphoblastic leukemia (ALL) is a blood pathology that can be lethal in only a few weeks if left unchecked. ALL is a type of blood cancer identiﬁed by immature lymphocytes, known as lymphoblasts, in the blood and bone marrow. The peak incidence lies in children ages 2-5 years, and one of This work was supported in part by CNPq under grant no. 315820/2021-7, FAPESP under grant no. 2019/02278-2, and Coordenac¸˜ao de Aperfeic¸oamento de Pessoal de N´ıvel Superior - Brasil (CAPES) - Finance Code 001. the primary forms of ALL detection is through microscopic blood sample inspection. Computer-aided leukemia diagnosis has been achieved using many different approaches in the past years, including deep learning models combined with transfer learning and unsharpening techniques [6], [7], [8], [9]. Also, it has been reported in the literature that a quaternion-valued convolutional neural network exhibited better generalization capability than its corresponding real-valued model to classify white cells as lymphoblasts [10]. Furthermore, the quaternion- valued CNN has about 34% of the total number of param- eters of the corresponding real-valued network. This paper investigates further the application of hypercomplex-valued convolutional neural networks (HvCNN) ALL detection. Like complex numbers, quaternions are hypercomplex num- bers with a wide range of applications in science and engineering. For example, quaternions provide an efﬁcient tool for describing 3D rotations used in computer graphics. Furthermore, quaternion-valued neural networks have been effectively applied for signal processing and control [11], [12], image classiﬁcation [13], [14], and many other pattern recognition tasks [15], [16]. However, besides the quaternions, many other hypercomplex-valued algebras exist, including the coquaternions, the tessarines, Clifford algebras, and Cayley- Dickson algebras. The tessarines, introduced by Cockle a few years after the introduction of quaternions, is a commuta- tive hypercomplex algebra that has been effectively used for signal processing and the development of neural networks [17], [18], [19], [20], [21]. The Clifford algebras comprise a broad family of associative hypercomplex algebras with interesting geometrical properties [22], [23], [24]. A family of hypercomplex algebras, obtained from the recursive process of Cayley-Dickson, can be used to develop effective HvNNs [25], [26]. Furthermore, four-dimensional hypercomplex algebras have been used for designing neural networks for controlling a robot manipulator [12]. This paper considers the hypercomplex algebra framework proposed by Kantor and Solodovnikov [27]. This approach furnishes a broad class of hypercomplex algebras which com- prises the tessarines, the Clifford algebras, and the Cayley- Dickson algebras. On the downside, the general framework by Kantor and Solodovnikov also contains many hypercomplex algebras with no attractive features. Thus, we shall focus only on eight four-dimensional associative hypercomplex algebras, four of which are commutative. We consider the tessarines, the bi-complex numbers, and the Klein 4-group algebra among the commutative algebras [12], [28]. The four non-commutative hypercomplex algebras include quaternions and coquaternions. Also, they are isomorphic to Clifford as well as Cayley- Dickson algebras [26], [29]. The paper is organized as follows: Next section presents the basic concepts of hypercomplex algebras and explores notable four-dimensional algebras. Section III addresses hypercomplex-valued CNN models and shows how to emulate them using a real-valued convolutional network. Section IV describes the computational experiments conducted using the ALL-IDB dataset. The paper ﬁnishes with some concluding remarks in Section V. II. HYPERCOMPLEX NUMBERS AND SOME NOTABLE ASSOCIATIVE FOUR-DIMENSIONAL ALGEBRAS Let us present a few basic deﬁnitions regarding hypercom- plex numbers. Hypercomplex algebras can be deﬁned in any ﬁeld, but we focus on algebras over the real numbers in this work. As pointed out in the introduction, we consider the general framework proposed by Kantor and Solodovnikov, which includes the most used hypercomplex algebras [27]. We ﬁnish this section by presenting eight notable associative four-dimensional hypercomplex algebras. A. A Brief Review on Hypercomplex Number Systems A hypercomplex algebra A of dimension n + 1 over R is a set A = {x = x0 +x1i1 +x2i2 +· · ·+xnin : xµ ∈R, ∀µ}, (1) equipped with two operations, namely addition and multipli- cation [27]. The symbols iµ, with iµ /∈R for all µ = 1, . . . , n, denote the so-called hyperimaginary units of A. The addition of two hypercomplex numbers x = x0 + x1i1 + · · · + xnin and y = y0 + y1i1 + · · · + ynin is simply deﬁned as x + y = (x0 + y0) + (x1 + y1)i1 + . . . + (xn + yn)in. (2) The multiplication operation is carried out distributively and replacing the product of two hypercomplex units iµ and iν by an hypercomplex number pµν := iµiν, where pµν = (pµν)0 + (pµν)1i1 + · · · + (pµν)nin ∈A, (3) for all µ, ν = 1, . . . , n. Precisely, the multiplication of two hypercomplex numbers is given by the equation xy = x0y0 + n X µ,ν=1 xµyν(pµν)0 ! + x0y1 + x1y0 + n X µ,ν=1 xµyν(pµν)1 ! i1 + . . . + x0yn + xny0 + n X µ,ν=1 xµyν(pµν)n ! in. (4) Note that hyperimaginary units products characterize a hypercomplex algebra A. In other words, the hypercomplex numbers pµν given by (3) determine A. It is common practice to arrange the hypercomplex numbers pµν in a table, called the multiplication table. Examples of multiplication tables are given in Tables I and II. Algebraic properties of an hypercomplex algebra A can be inferred from its multipli- cation tables. For example, symmetric multiplication tables represent commutative hypercomplex algebras [27]. Note that the four multiplication tables in Table II are symmetric. Thus, they represent commutative hypercomplex algebras. We will discuss in detail the multiplication tables provided in Tables I and II in the following subsection. A scalar α ∈A can be identiﬁed with the hypercomplex number α = α+0i1 +· · ·+0in, and vice-versa. Furthermore, from (4), the product by scalar in any algebra A satisﬁes αx = αx0 + αx1i1 + · · · + αxnin. (5) This remark shows that a hypercomplex algebra A can be identiﬁed with an (n + 1)-dimensional vector space with the vector addition and the product by a scalar given by (2) and (5), respectively. Moreover, the basis elements of such (n+1)-dimensional vector space are 1, i1, . . . , in. Besides the addition and the product by a scalar, a hypercomplex algebra is equipped with the multiplication of vectors given by (4). We would like to point out that different multiplication tables do not necessarily yield different hypercomplex alge- bras. Precisely, we know from linear algebra that a vector space can be represented using different bases. Similarly, a hypercomplex algebra can be obtained from different bases or, equivalently, using different hypercomplex units. Since the multiplication table determines the outcome of the product of any two hypercomplex units, a change of basis results in a different multiplication table. Because of this remark, we say two hypercomplex algebras A and A′ are isomorphic if they differ by a change of basis. In other words, A and A′ are isomorphic hypercomplex algebras if the multiplication table of A′ can be obtained from the multiplication table of A through a change of basis. B. Four-dimensional Hypercomplex Algebras Let us now focus on four-dimensional hypercomplex alge- bras, i.e., hypercomplex algebras of the form A = {x = x0 + x1i + x2j + x3k : x0, . . . , x3 ∈R}, (6) where i ≡i1, j ≡i2, and k ≡i3 are the three hy- percomplex units. Four-dimensional hypercomplex algebras are particularly useful for image processing because a color can be represented using a single hypercomplex number. In other words, four-dimensional hypercomplex algebras allows representing a color by a single entity. Note that the hypercomplex numbers pµν = (pµν)0 + (pµν)1i+(pµν)2j +(pµν)3k in the multiplication table results in a large number of algebras. Some of these algebras are isomorphic, and many of them have no attractive features. Therefore, we present a construction rule that yields eight associative four-dimensional hypercomplex algebras in the following. Like in the construction of Clifford algebras [30], we assume the product of hypercomplex units is associative. Furthermore, we let the identity k = ij, (7) hold true. Finally, we assume the four-dimensional hypercom- plex algebra is either commutative or anti-commutative. 1) Anticommutative Algebras: We obtain an anticommu- tative four-dimensional hypercomplex algebra by imposing ij = −ji. From the associativity and (7), we obtain k2 = (ij)(ij) = i(ji)j = i(−ij)j = −i2j2, (8) ik = i(ij) = i2j, (9) jk = j(ij) = j(−ji) = −j2i. (10) To simplify the exposition, let i2 = γ1 and j2 = γ2. From (7)-(10), we obtain an associative and anticommutative four- dimensional algebra denoted by A[γ1, γ2], whose multiplica- tion table is then A[γ1, γ2] i j k i γ1 k γ1j j −k γ2 −γ2i k −γ1j γ2i −γ1γ2 (11) By considering γ1, γ2 ∈{−1, +1}, we obtain the four- dimensional hypercomplex algebras A[−1, −1], A[−1, +1], A[+1, −1], and A[+1, +1] whose multiplication tables are depicted in Table I. Remark 1. The hypercomplex algebra A[−1, −1] coincides with the quaternions because they have the same multipli- cation table. The algebra A[−1, +1] corresponds to the co- quaternions, also known as split-quaternions [12]. Similarly, A[+1, +1] and A[+1, −1] can be identiﬁed with the Clifford algebras Cℓ2,0 and Cℓ1,1, respectively. Furthermore, the alge- bras A[−1, +1], A[+1, −1], and A[+1, +1] are all isomorphic. Finally, we would like to remark that the algebras A[−1, −1], A[−1, +1], A[+1, −1], and A[+1, +1] can be derived using the generalized Cayley-Dickson process [25], [26]. 2) Commutative Algebras: In a similar fashion, we impose the condition ij = ji to obtain the commutative four- dimensional hypercomplex algebras. Again, using associativity and (7), we are able to write the identities k2 = (ij)(ij) = i(ji)j = i(ij)j = i2j2, (12) ik = i(ij) = i2j, (13) jk = j(ij) = j(ji) = j2i. (14) By expressing i2 = γ1 and j2 = γ2, we obtain a commutative hypercomplex algebra B[γ1, γ2] whose multiplication table is B[γ1, γ2] i j k i γ1 k γ1j j k γ2 γ2i k γ1j γ2i γ1γ2 (15) Analogously, we end up with the four-dimensional alge- bras B[−1, −1], B[−1, +1], B[+1, −1], B[+1, +1] by taking γ1, γ2 ∈{−1, +1}. Table II contains the multiplication table of these four algebras. Remark 2. Because they have the same multiplication ta- ble, the hypercomplex algebra B[−1, +1] corresponds to the tessarines, also known as commutative quaternions [19], [17]. Similarly, the algebra B[−1, −1] corresponds to the bi- complex numbers [12] while B[+1, +1] is equivalent to the Klein 4-group, a commutative algebra of great interest in symmetric group theory [28]. Finally, we would like to point out that the algebras B[−1, −1] and B[+1, −1] can be both obtained from B[−1, +1] by a change of bases. Therefore, the three algebras B[−1, −1], B[+1, −1] and B[−1, +1] are all isomorphic. Concluding, we have a total of eight four-dimensional hypercomplex algebras. All of them are associative, four are anticommutative and the remaining are commutative. Further- more, the hypercomplex units are well structured in their multiplication table. Precisely, their multiplication table can be written as follows i j k i s11 s12k s13j j s21k s22 s23i k s31j s32i s33 (16) where sij ∈{−1, +1}, for all i, j = 1, . . . , 3, depends on the parameters γ1 and γ2 as well as on the commutativity or anticommutativity of the multiplication. The multiplication table (16) helped us to efﬁciently implement convolutional neural networks based on the eight hypercomplex algebras presented in this section. We detail this remark in the following section. III. HYPERCOMPLEX-VALUED CONVOLUTIONAL NEURAL NETWORKS (HVCNN) Convolutional layers are crucial building blocks of convo- lutional neural networks. The main strength of convolutional layers is their ability to process data locally and, thus, learn lo- cal patterns. Convolutional neural networks have been widely applied to image processing tasks [31]. Let us brieﬂy describe a real-valued convolutional layer. A. Real-valued Convolutional Layers Suppose a convolutional layer is fed by a real-valued image I with C feature channels. Let I(p, c) ∈R denote the intensity of the cth channel of the image I at pixel p. The neurons of a convolutional layer are parameterized structures called ﬁlters. The ﬁlters have the same number C of channels as the image I. Let D, commonly a rectangular grid, denote the domain of the ﬁlters. Also, let the weights of a convolutional layer with K real-valued ﬁlters be arranged in an array F such that F(q, c, k) denotes the value of the cth channel of the kth ﬁlter at the point q ∈D, for c = 1, . . . , C and k = 1, . . . , K. A convolutional layer with K ﬁlters yields a real-valued image J TABLE I MULTIPLICATION TABLES OF THE ANTICOMMUTATIVE ALGEBRAS. Quaternions Cℓ2,0 Coquaternions Cℓ1,1 A[−1, −1] i j k i −1 k −j j −k −1 i k j −i −1 A [+1, +1] i j k i 1 k j j −k 1 −i k −j i −1 A [−1, +1] i j k i −1 k −j j −k 1 −i k j i 1 A [+1, −1] i j k i 1 k j j −k −1 i k −j −i 1 TABLE II MULTIPLICATION TABLES OF COMMUTATIVE ALGEBRAS. Bicomplex numbers Tessarines Klein 4-group B[−1, −1] i j k i −1 k −j j k −1 −i k −j −i 1 B[+1, −1] i j k i 1 k j j k −1 −i k j −i −1 B[−1, +1] i j k i −1 k −j j k 1 i k −j i −1 B[+1, +1] i j k i 1 k j j k 1 i k j i 1 with K feature channels obtained by evaluating an activation function on the addition of a bias term and the convolution of the image I by each of the K ﬁlters. Precisely, let (I∗F)(p, k) denote the convolution of the image I by the kth ﬁlter at pixel p. Intuitively, (I ∗F)(p, k) is the sum of the multiplication of the weights of the kth ﬁlter and the intensities of the pixels of the image in a window characterized by the translation of p by S(q), for q ∈D. The term S(q), for q in the domain D of the ﬁlter, represents a translation that can take vertical and horizontal strides into account. In mathematical terms, the convolution of the image I by the kth ﬁlter at pixel p is given by (I ∗F)(p, k) = C X c=1 X q∈D I  p + S(q), c  F(q, c, k). (17) Moreover, the intensity of the kth feature channel of the output of a convolutional layer at pixel p is deﬁned by J(p, k) = ϕ (b(k) + (I ∗F)(p, k)) , (18) where ϕ : R →R denotes the activation function. B. Hypercomplex-valued Convolutional Layers The hypercomplex-valued convolutional layer is deﬁned analogously to the real-valued convolutional layer by replacing the real numbers and operations with their corresponding hypercomplex versions in (17) and (18) [32], [33]. Precisely, the “intensity” of the kth channel of the hypercomplex-valued output image J(h) at pixel p is given by J(h)(p, k) = ϕA  b(h)(k) + (I(h) ∗F(h))(p, k)  , (19) where ϕA : A →A is a hypercomplex-valued activation function, b(h) k ∈A is the bias term, and (I(h) ∗F(h))(p, k) = C X c=1 X q∈D I(h)(p + S(q), c)F(h)(q, c, k), (20) is the convolution of I(h) by the kth hypercomplex-valued ﬁlter at pixel p. In this paper, we only consider split-functions deﬁned using a real-valued function ϕ : R →R as follows for all x ∈x0 + x1i1 + · · · + xnin ∈A: ϕA(x) = ϕ(x0) + ϕ(x1)i1 + . . . + ϕ(xn)in. (21) C. Emulating Hypercomplex-valued Convolutional Layers Since most deep neural network libraries are designed for real-valued inputs, we show how to emulate a four- dimensional hypercomplex-valued convolutional layer using a real-valued convolutional layer. The reasoning is quite similar to the approaches reported in the literature for complex- and quaternion-valued deep networks [32], [33]. First, an image I(h) with C channels deﬁned on a four- dimensional hypercomplex algebra can be represented by I(h) = I0 + I1i + I2j + I3k, (22) where I0, I1, I2, and I3 are real-valued images with C channels. Similarly, a bank of K hypercomplex-valued ﬁlters can be represented by F(h) = F0 + F1i + F2j + F3k, (23) where F0, F1, F2, and F3 are real-valued arrays representing each a bank of K ﬁlters with domain D and C feature channels. From the multiplication table (16) and omitting the arguments (p + S(q), c) and (q, c, k) to simplify the notation, we obtain I(h)(p + S(q), c)F(h)(q, c, k) = (I0 + I1i + I2j + I3k)(F0 + F1i + F2j + F3k) = I0F0 + s11I1F1 + s22I2F2 + s33I3F3 + (I0F1 + I1F0 + s23I2F3 + s32I3F2)i + (I0F2 + s13I1F3 + I2F0 + s31I3F1)j + (I0F3 + s12I1F2 + s21I2F1 + I3F0)k Therefore, the real-part of the convolution given by (20) satisﬁes the equation  I(h) ∗F(h) 0(p, k) = C X c=1 X q∈D h I0(p + S(q), c)F0(q, c, k) + s11I1(p + S(q), c)F1(q, c, k) (24) + s22I2(p + S(q), c)F2(q, c, k) + s33I3(p + S(q), c)F3(q, c, k) i , Equivalently, the real-part of the convolution of the image I(h) by the kth hypercomplex-valued ﬁlter at pixel p can be computed using the real-valued convolution  I(h) ∗F(h) 0(p, k) =  I(r) ∗F(r) 0  (p, k), (25) where I(r) is the real-valued image with 4C features channels obtained by concatenating the real and imaginary parts of I(h) as follows I(r)(p, :) = [I0(p, :), I1(p, :), I2(p, :), I3(p, :)], (26) for all pixels p, and F(r) 0 is the real-valued ﬁlter deﬁned by F(r) 0 (q, 1 : C, k) = F0(q, 1 : C, k), (27) F(r) 0 (q, C + 1 : 2C, k) = s11F1(q, 1 : C, k), (28) F(r) 0 (q, 2C + 1 : 3C, k) = s22F2(q, 1 : C, k), (29) F(r) 0 (q, 3C + 1 : 4C, k) = s33F3(q, 1 : C, k), (30) for all q ∈D and k = 1, . . . , K. For short, the notation F(r) 0 = [F0, s11F1, s22F2, s33F3], (31) means that F(r) 0 is obtained by concatenating F0, s11F1, s22F2, and s33F3 as prescribed above. Note from (17) that  I(r) ∗F(r) 0  (p, k) = 4C X c=1 X q∈D I(r) p + S(q), c  F(r) 0 (q, c, k) = X q∈D " C X c=1 I(r) p + S(q), c  F(r) 0 (q, c, k) + . . . + 4C X c=3C+1 I(r) p + S(q), c  F(r) 0 (q, c, k) # = X q∈D " C X c=1 I0  p + S(q), c  F0(q, c, k) + . . . + C X c′=1 s33I3  p + S(q), c′ F3(q, c′, k) # , which coincides with  I(h) ∗F(h) 0(p, k) given by (24). Therefore, using a split-function, the real-part J0(p, k) of the output J(h)(p, k) of the hypercomplex-valued convolutional layer given by (20) can be computed using a real-valued convolutional layer as follows J0(p, k) = ϕ  b0(k) +  I(r) ∗F(r) 0  (p, k)  , (32) a) Probable lymphoblast b) Healthy cell Fig. 1. Examples of candidate cells for the classiﬁcation task. Images from the ALL-IDB dataset [35]. where the bias term b0(k) corresponds to the real-part of b(k) while I(r) and F(r) 0 are given by (26) and (31), respectively. In a similar vein, the three imaginary parts J1(p, k), J2(p, k), and J3(p, k) of the kth channel of the hypercomplex-valued image J(h) at pixel p can be computed using real-valued convolutional layers with bias terms b1(k), b2(k), and b3(k) and real-valued ﬁlters F(r) 1 = [F1, F0, s23F3, s32F2], (33) F(r) 2 = [F2, s13F3, F0, s31F1], (34) F(r) 3 = [F3, s12F2, s21F1, F0], (35) respectively. We would like to ﬁnish this section with few remarks: First, emulating a hypercomplex-valued convolutional layer allow us to take advantage of open-source deep libraries such as Tensorflow and PyTorch for python and Flux for Julia Language. Consequently, hypercomplex- valued versions of well-known deep neural networks can be implemented in current deep learning libraries. On top of that, although not properly designed for hypercomplex-valued models, pooling layers, sophisticated optimizers, and speed-up training techniques such as batch normalization and weight initialization can be incorporated as the ﬁrst attempt into hypercomplex-valued deep networks. In the following section, we consider a hypercomplex-valued deep neural network for the classiﬁcation of lymphocytes from smear blood images that resembles the LeNet architecture [34]. IV. LYMPHOBLAST IMAGE CLASSIFICATION TASK One of the primary forms of diagnosis of acute lymphoblas- tic leukemia (ALL) is through microscopic blood smear image inspection [6], [7], [8], [9]. Precisely, physicians diagnose ALL by the presence of many lymphoblasts in a blood smear image in which white cells are stained with bluish-purple coloration. A candidate cell image is selected, cut from the blood smear image, and fed into a machine learning classiﬁer for a computer-aided leukemia diagnosis. For illustrative pur- poses, Fig. 1 shows two candidate cell images used in such a classiﬁcation task. The classiﬁer predicts if the candidate image is a lymphoblast in the simplest binary case. In our model, the candidate images have 100 × 100 pixels and have been saved using either the RGB (red-green-blue) TABLE III PARAMETER DISTRIBUTION PER LAYER FOR EACH ARCHITECTURE. RvCNN HvCNN Conv Layer 1 (3,3) ﬁlters 32 8 Parameters 896 320 Conv Layer 2 (3,3) ﬁlters 64 16 Parameters 18,496 4,672 Conv Layer 3 (3,3) ﬁlters 128 32 Parameters 73,856 18,560 Dense Layer Units 1 1 Parameters 12,801 12,801 Total 106,049 36,353 or the HSV (hue-saturation-value) color encodings. Using the RGB encoding, an image is characterized by the intensities of red (R), green (G), and blue (B), respectively. An RGB encoded image has been mapped into a hypercomplex-valued image I(h) RGB by means of the equation I(h) RGB = Ri + Gj + Bk. (36) Similarly, a HSV-encoded image is characterized by the hue H ∈[0, 2π), the value V ∈[0, 1], and the saturation S ∈[0, 1]. A hypercomplex-valued image I(h) HSV is derived from an HSV- encoded image as follows [10]: I(h) HSV =  cos(H) + sin(H)i  (S + V j). (37) Note that, because ij = k in all the considered hypercomplex algebras, (37) is equivalent to I(h) HSV = S cos(H) + S sin(H)i + V cos(H)j + V sin(H)k. (38) We performed the lymphocyte classiﬁcation task using real- valued CNNs (RvCNNs) and the proposed HvCNNs. Similar architectures are adopted for both real- and hypercomplex- valued models, as suggested in [10]. The RvCNN features three convolutional layers with 3 × 3 ﬁlters followed by a max-pooling layer with 2 × 2 kernels. A dense layer with 1 unit yields the output. The hypercomplex-valued models have the same layer layout but a much smaller number of ﬁl- ters per convolution layer because each hypercomplex-valued channel is equivalent to four real-valued feature channels. The activation function adopted for all convolutional layers is the rectiﬁed linear unit (ReLU). The dense layer for both architectures is a single neuron that outputs the label 0 for a healthy white cell and 1 for a lymphoblast image. Table III shows a breakdown of total parameters per layer for each architecture. All deep network models in this work were imple- mented using the python libraries Keras and Tensorflow. The source codes are available at https://github.com/mevalle/ Hypercomplex-valued-Convolutional-Neural-Networks. A. Computational Experiments Let us now describe the outcome of the computational ex- periments performed using the acute lymphoblastic leukemia image database (ALL-IDB), a popular public dataset for segmentation and classiﬁcation tasks directed at ALL detection [35]. The ALL-image database (ALL-IDB) consists of two sets of images. The ALL-IDB1 contains 108 blood smear images for segmentation and classiﬁcation tasks. The ALL- IDB2 contains 260 segmented images, each containing a single blood element like the images depicted in Fig. 1, and is aimed exclusively for the classiﬁcation task [35]. We used all the 260 images from the ALL-IDB2 dataset in our computational experiments. Like Genovese et al. [7], [8], we randomly split the dataset into the training and test sets containing each 50% of the total number of images. The training set is enlarged using horizontal and vertical ﬂips. We conducted 100 simulations per experiment. Each simulation consists of splitting training and test set, augmenting the training set, initializing the network parameters, training for 100 epochs using ADAM optimizer and the binary cross- entropy loss function, and predicting test images. We evaluate the performances using the accuracy score in the test set. We derive a total of 18 network conﬁgurations using the real numbers and the eight hypercomplex algebras detailed in Section II. Namely, each of the nine models (1 RvCNN and 8 HvCNNs) is used in the classiﬁcation tasks of both RGB and HSV encoded image sets. The box plots depicted in Fig. 2 summarize the outcome of the computational experiment. Note that all models performed well for the RGB encoded images, with medians close to 95% accuracy except for the HvCNN based on the algebra B[−1, +1] that yields a median accuracy rate of 93.8%. In the HSV case, however, perfor- mances vary more drastically. The real-valued model exhibits poor performance compared to all the hypercomplex-valued ones, with a median accuracy rate of 91.5%. The HvCNNs based on the algebras A[−1, −1], B[−1, −1], and B[−1, +1] yielded all a median accuracy score of 96.2% while the HvCNN based on the algebra B[+1, −1] achieved a median accuracy score of 96.5%. Moreover, the HvCNNs based on the isomorphic algebras A[−1, +1], A[+1, −1], and A[+1, +1] as well as the HvCNN based on B[+1, +1] yielded all a median accuracy score of 96.9%. The signiﬁcant improvement in the accuracy scores of the HvCNN models indicates they can take advantage of the locally cohesive structure of the HSV encoding. To better depict the outcome of this computational experi- ment, we summarize the performance of the network classiﬁers in the Hasse diagram shown in Fig. 3. This ﬁgure depicts a single HvCNN model of each isomorphic hypercomplex algebra group to simplify the exposition. Precisely, Fig. 3 compares the performance of the HvCNNs based on the hypercomplex algebras A[−1, −1] (quaternions), A[−1, +1] (coquaternions), B[−1, +1] (tessarines), B[+1, +1] (Klein 4- group), along with the real-valued models. In this diagram, a solid line connecting two models indicates that the one above achieved better performance than the one below, with a conﬁdence level of 0.99 according to a Student’s t-test. In other words, models higher up in the diagram perform signiﬁcantly better than those on the lower end. Furthermore, the solid lines indicate a transitive relation. Thus, if model A is better than B and B is better than C, then A is better than C. First off, Fig. 3 conﬁrms that the HvCNN models performed better using the a) RGB-encoded images b) HSV-encoded images Real+RGB A[-1,-1]+RGB A[-1,+1]+RGB A[+1,-1]+RGB A[+1,+1]+RGB B[-1,-1]+RGB B[-1,+1]+RGB B[+1,-1]+RGB B[+1,+1]+RGB 85 87 89 91 93 95 97 99 Accuracies (%) Real+HSV A[-1,-1]+HSV A[-1,+1]+HSV A[+1,-1]+HSV A[+1,+1]+HSV B[-1,-1]+HSV B[-1,+1]+HSV B[+1,-1]+HSV B[+1,+1]+HSV 85 87 89 91 93 95 97 99 Accuracies (%) Fig. 2. Boxplot of test set accuracies produced by real-valued and hypercomplex-valued neural networks. Real+RGB Real+HSV A[-1,-1]+RGB (quaternions) B[-1,+1]+RGB (tessarines) A[-1,+1]+RGB (coquaternions) B[+1,+1]+RGB (Klein 4-group) A[-1,-1]+HSV (quaternions) A[-1,+1]+HSV (coquaternions) B[-1,+1]+HSV (tessarines) B[+1,+1]+HSV (Klein 4-group) Fig. 3. Hasse diagram of representative experiment conﬁgurations. HSV than the RGB encoding, and HvCNNs on HSV encoded images outperform the real-valued models on both encodings. In addition, it shows the real-valued model on HSV encoded images as the poorest performer. Moreover, coquaternion- and tessarine-based HvCNNs outperformed the HvCNN based on quaternions, the four-dimensional algebra most widely used in applications. At this point, we would like to recall that superior performance of neural networks based on non-usual hypercomplex algebras has been previously reported in the literature [26], [29], despite quaternion-based neural network yielding better performance in applications like controlling a robot manipulator [12]. Finally, we would like to recall that Genovese et al. ob- tained average accuracy rates of 97.92% using a ResNet18 combined with histopathological transfer learning [7]. The top-performing HvCNNs achieved average accuracy scores of 96.51% and 96.39%. However, in contrast to the ResNet18 network with approximately 11.4M parameters, the HvC- NNs have only 36K trainable parameters. In particular, the coquaternion-valued HvCNN with HSV encoding achieved 98% of the average accuracy score of the ResNet18 with transfer learning but with only 0.3% of its total number of trainable parameters. V. CONCLUDING REMARKS In this work, we extended the concept of a quaternion- valued CNN to general hypercomplex algebras. We con- structed eight such algebras with desirable properties ac- cording to Kantor and Solodovnikov framework. These alge- bras are isomorphic to well-known four-dimensional algebras: quaternions, coquaternions, tessarines, Klein 4-group, Cayley- Dickson algebras, and Clifford algebras. The hypercomplex- valued neural networks have been applied for lymphoblast image classiﬁcation. Using the public dataset ALL-IDB2, we conducted exper- iments featuring real-valued and hypercomplex-valued mod- els. We observed that the HvCNNs performed similarly to the real-valued models in the RGB-encoded images while outperforming the RvCNNs with HSV-encoded images. The superior performance of the HvCNN indicates that they take better advantage of the HSV color system, which is more akin to human vision and more widely used in computer vision applications [36]. Consequently, HvCNN models seem more efﬁcient at comprising information in its ﬁlters and four- dimensional entities than the real-valued models. Moreover, coquaternion- and tessarine-valued models outperformed the quaternion-valued CNNs. Lastly, the performance attained by the top-performing HvCNN models is signiﬁcant and com- parable to notable results in the literature. Indeed, Genovese et al. observed an average accuracy score of 97.92% with the ResNet18, a deep network containing around 11 million parameters [7]. The coquaternion-valued CNN yielded an average accuracy of 96.51% with approximately 0.3% of the total of trainable parameters of the real-valued ResNet18. REFERENCES [1] L. H. Eadie, P. Taylor, and A. P. Gibson, “A systematic review of computer-assisted diagnosis in diagnostic cancer imaging,” European journal of radiology, vol. 81, no. 1, pp. e70–e76, 2012. [2] C. R. Pereira, D. R. Pereira, S. A. Weber, C. Hook, V. H. C. de Al- buquerque, and J. P. Papa, “A survey on computer-assisted parkinson’s disease diagnosis,” Artiﬁcial intelligence in medicine, vol. 95, pp. 48–63, 2019. [3] W. Qian, L. P. Clarke, B. Zheng, M. Kallergi, and R. Clark, “Computer assisted diagnosis for digital mammography,” IEEE Engineering in Medicine and Biology Magazine, vol. 14, no. 5, pp. 561–569, 1995. [4] D. Leaper, J. C. Horrocks, J. Staniland, and F. De Dombal, “Computer- assisted diagnosis of abdominal pain using “estimates” provided by clinicians,” Br Med J, vol. 4, no. 5836, pp. 350–354, 1972. [5] H. T. Salah, I. N. Muhsen, M. E. Salama, T. Owaidah, and S. K. Hashmi, “Machine learning applications in the diagnosis of leukemia: Current trends and future directions,” International Journal of Laboratory Hema- tology, vol. 41, no. 6, pp. 717–725, 12 2019. [6] N. Bibi, M. Sikandar, I. U. Din, A. Almogren, and S. Ali, “Iomt-based automated detection and classiﬁcation of leukemia using deep learning,” Journal of Healthcare Engineering, 2020. [7] A. Genovese, M. S. Hosseini, V. Piuri, K. N. Plataniotis, and F. Scotti, “Histopathological transfer learning for acute lymphoblastic leukemia detection,” CIVEMSA 2021 - IEEE International Conference on Compu- tational Intelligence and Virtual Environments for Measurement Systems and Applications, Proceedings, 6 2021. [8] ——, “Acute lymphoblastic leukemia detection based on adaptive un- sharpening and deep learning,” ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings, vol. 2021- June, pp. 1205–1209, 2021. [9] M. Zolfaghari and H. Sajedi, “A survey on automated detection and classiﬁcation of acute leukemia and WBCs in microscopic blood cells,” Multimedia Tools and Applications, pp. 1–31, 1 2022. [Online]. Avail- able: https://link.springer.com/article/10.1007/s11042-022-12108-7 [10] M. A. Granero, C. X. Hern´andez, and M. E. Valle, “Quaternion-valued convolutional neural network applied for acute lymphoblastic leukemia diagnosis,” in Intelligent Systems, A. Britto and K. Valdivia Delgado, Eds. Cham: Springer International Publishing, 2021, pp. 280–293. [11] S. P. Talebi, S. Werner, and D. P. Mandic, “Quaternion-Valued Dis- tributed Filtering and Control,” IEEE Transactions on Automatic Con- trol, vol. 65, no. 10, pp. 4246–4257, 10 2020. [12] K. Takahashi, “Comparison of high-dimensional neural networks using hypercomplex numbers in a robot manipulator control,” Artiﬁcial Life and Robotics, vol. 26, no. 3, pp. 367–377, 8 2021. [Online]. Available: https://link.springer.com/article/10.1007/s10015-021-00687-x [13] F. Shang and A. Hirose, “Quaternion Neural-Network-Based PolSAR Land Classiﬁcation in Poincare-Sphere-Parameter Space,” IEEE Trans- actions on Geoscience and Remote Sensing, vol. 52, pp. 5693–5703, 2014. [14] M. E. Valle and R. A. Lobo, “Quaternion-valued recurrent projection neural networks on unit quaternions,” Theoretical Computer Science, vol. 843, pp. 136–152, 12 2020. [15] T. Parcollet, M. Morchid, and G. Linar`es, “A survey of quaternion neural networks,” Artiﬁcial Intelligence Review, vol. 53, no. 4, pp. 2957–2982, 4 2020. [Online]. Available: https://doi.org/10.1007/ s10462-019-09752-1 [16] E. Bayro-Corrochano, S. Solis-Gamboa, G. Altamirano-Escobedo, L. Lechuga-Gutierres, and J. Lisarraga-Rodriguez, “Quaternion Spiking and Quaternion Quantum Neural Networks: Theory and Applications,” https://doi.org/10.1142/S0129065720500598, vol. 31, no. 2, 9 2020. [17] J. Navarro-Moreno, R. M. Fern´andez-Alcal´a, J. D. Jim´enez-L´opez, and J. C. Ruiz-Molina, “Tessarine Signal Processing under the T-Properness Condition,” Journal of the Franklin Institute, 8 2020. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S0016003220305391 [18] J. Navarro-Moreno and J. C. Ruiz-Molina, “Wide-sense Markov signals on the tessarine domain. A study under properness conditions,” Signal Processing, vol. 183, p. 108022, 6 2021. [19] F. Ortolani, D. Comminiello, M. Scarpiniti, A. Uncini, F. Ortolani, D. Comminiello, M. Scarpiniti, A. Uncini, D. Comminiello, M. Scarpiniti, and A. Uncini, “On 4-Dimensional Hypercomplex Algebras in Adaptive Signal Processing,” Smart Innovation, Systems and Technologies, vol. 102, pp. 131–140, 6 2017. [Online]. Available: https://link.springer.com/chapter/10.1007/978-3-319-95098-3 12 [20] R. Carniello, W. Vital, and M. Valle, “Universal approximation theorem for tessarine-valued neural networks,” in Anais do XVIII Encontro Nacional de Inteligˆencia Artiﬁcial e Computacional. Porto Alegre, RS, Brasil: SBC, 2021, pp. 233–243. [Online]. Available: https://sol.sbc.org.br/index.php/eniac/article/view/18256 [21] F. Senna and M. Valle, “Tessarine and quaternion-valued deep neural networks for image classiﬁcation,” in Anais do XVIII Encontro Nacional de Inteligˆencia Artiﬁcial e Computacional. Porto Alegre, RS, Brasil: SBC, 2021, pp. 350–361. [Online]. Available: https://sol.sbc.org.br/index.php/eniac/article/view/18266 [22] D. Hestenes and G. Sobczyk, Clifford algebra to geometric calculus: a uniﬁed language for mathematics and physics. Springer Science & Business Media, 2012, vol. 5. [23] E. Hitzer, T. Nitta, and Y. Kuroe, “Applications of Clifford’s Geometric Algebra,” Advances in Applied Clifford Algebras, vol. 23, no. 2, pp. 377–404, 6 2013. [24] J. Vaz and R. da Rocha, An Introduction to Clifford Algebras and Spinors. Oxford University Press, 2016. [25] R. B. Brown, “On generalized Cayley-Dickson algebras.” Paciﬁc Journal of Mathematics, vol. 20, no. 3, pp. 415–422, 1967. [Online]. Available: https://projecteuclid.org/euclid.pjm/1102992693 [26] G. Vieira and M. Eduardo Valle, “Extreme Learning Machines on Cayley-Dickson Algebra Applied for Color Image Auto-Encoding,” in 2020 International Joint Conference on Neural Networks (IJCNN). IEEE, 7 2020, pp. 1–8. [Online]. Available: https://ieeexplore.ieee.org/ document/9207495/ [27] I. L. Kantor and A. S. Solodovnikov, Hypercomplex Numbers: An Elementary Introduction to Algebras. Springer New York, 1989. [28] M. Kobayashi, “Hopﬁeld neural networks using Klein four-group,” Neurocomputing, vol. 387, pp. 123–128, 4 2020. [29] G. Vieira and M. E. Valle, “A general framework for hypercomplex- valued extreme learning machines,” Journal of Computational Mathe- matics and Data Science, vol. 3, p. 100032, 6 2022. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S2772415822000062 [30] P. Renaud and P. R. Clifford, “CLIFFORD ALGEBRAS LECTURE NOTES ON APPLICATIONS IN PHYSICS,” ALGEBRAS LECTURE NOTES ON APPLICATIONS IN PHYSICS, 11 2020. [Online]. Available: https://hal.archives-ouvertes.fr/hal-03015551https: //hal.archives-ouvertes.fr/hal-03015551/document [31] Aurelien G´eron, Hands–On Machine Learning with Scikit–Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Sys- tems, 2nd ed. Sebastopol, California, USA.: O Reilly, 10 2019. [32] C. Trabelsi, O. Bilaniuk, Y. Zhang, D. Serdyuk, S. Subramanian, J. F. Santos, S. Mehri, N. Rostamzadeh, Y. Bengio, and C. J. Pal, “Deep complex networks,” 5 2017. [Online]. Available: http: //github.com/ChihebTrabelsi/deep complex [33] C. Gaudet and A. Maida, “Deep Quaternion Networks,” arXiv, 12 2017. [Online]. Available: http://arxiv.org/abs/1712.04604 [34] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,” Proceedings of the IEEE, vol. 86, no. 11, pp. 2278–2323, 1998. [35] R. D. Labati, V. Piuri, and F. Scotti, “All-IDB: The acute lymphoblastic leukemia image database for image processing,” in Proceedings - International Conference on Image Processing, ICIP, 2011, pp. 2045– 2048. [36] H.-D. Cheng, X. H. Jiang, Y. Sun, and J. Wang, “Color image segmen- tation: advances and prospects,” Pattern recognition, vol. 34, no. 12, pp. 2259–2281, 2001.