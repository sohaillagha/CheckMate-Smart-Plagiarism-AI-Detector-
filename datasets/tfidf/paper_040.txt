Screening Mammography Breast Cancer Detection Debajyoti Chakraborty Northeastern University 360 Huntington Ave, Boston, MA 02115 chakraborty.de@northeastern.edu Abstract Breast cancer is a leading cause of cancer-related deaths, but current programs are expensive and prone to false positives, leading to unnecessary follow-up and pa- tient anxiety. This paper proposes a solution to automated breast cancer detection, to improve the efficiency and accu- racy of screening programs. Different methodologies were tested against the RSNA dataset of radiographic breast im- ages of roughly 20,000 female patients and yielded an av- erage validation case pF1 score of 0.56 across methods. 1. Introduction Breast cancer is one of the most commonly occurring cancer in the world with 2.3 million new breasts cancer di- agnoses and 685,000 deaths in 2020 alone [6]. Although the mortality rate in developed nations have dropped by 40% over the last 40 years due to regular mammography screen- ing programs, such in not the case in many other countries due a looming shortage of radiologists. As with any cancer or disease in general, early detec- tion and treatment is critical to reducing complications and fatalities. However, currently such procedures require the expertise of highly-trained human observers, primarily ra- diologists, making the overall process expensive to conduct and prone to human error, worsening the problem. 2. Problem Statement A major problem in mammography screening is that it often leads to a high incidence of false positive results. This is usually followed by further screening tests, inconvenient follow-up, and sometimes, unneeded tissue sampling (nee- dle biopsy) which may lead to further unrelated complica- tions, causing unnecessary anxiety. This paper aims to improve the automatic detection of breast cancer in screening mammograms obtained from reg- ular screening programs, with the goal being to reduce the occurrences of false positives in a clinical setting. 2.1. Dataset [This dataset contains radiographic breast images of female subjects.] The dataset [2] has been generously provided by the Ra- diological Society of North America (RSNA). RSNA is a non-profit organization that represents 31 radio-logic sub- specialties from 145 countries around the world. It contains radiographic breast images of roughly 20,000 female patients with usually four images per patient with two lateral [left, right] images per view [mediolateral- oblique (MLO), crainal-caudal (CC)]. Table 1. Metadata for each patient and image site id ID code for the source hospital machine id ID code for the imaging device patient id ID code for the patient image id ID code for the respective image laterality whether the image is of the left or right breast view orientation of the image age patient’s age in years implant whether the patient had breast im- plants at the patient level density rating for how dense the breast tis- sue is, with A being the least dense and D being the most dense biopsy whether a follow-up biopsy was performed on the breast invasive whether or not the cancer (if true) proved to be invasive BIRADS 0 if the breast required follow-up, 1 if the breast was rated as nega- tive for cancer, and 2 if the breast was rated as normal difficult negative case true if the case was unusually dif- ficult to diagnose cancer whether or not the breast was pos- itive for malignant cancer arXiv:2307.11274v1 [eess.IV] 21 Jul 2023 Figure 1. Example MLO and CC view of left(L) and right(R) breasts for patient id 32254. The raw dataset contains around 54,700 mammogra- phy images in the Digital Imaging and Communications in Medicine (DICOM) [4] format. There is a significant class imbalance in the target variable cancer, with 1,158 data-points for the positive class and 53,548 data-points for the negative class. For the purpose of this paper, image id serves as the input data, cancer as the binary target, along with only age and implant information as addi- tional metadata. The rest of the metadata will be included in a future implementation for better inference. 3. Approach 3.1. Image encoding Majority of the work was involved in pre-processing the DICOM images and converting them into png files for eas- ier post-processing and training. Most of the dicoms in the dataset contained JPEG2000 encoded images. The bit- stream was extracted and decoded on the GPU, saved as png files. Although this process was not lossless, it saved a lot of overhead for processing them individually, as they were quite high-dimensional. 3.2. Pre-processing Different pre-processing techniques were tried to im- prove the chances of accurate classification. Two of the pri- mary techniques were Region of Interest ROI cropping and normalization. However, upon further research, it was only decided to use normalization and drop cropping, due to the variability in image dimensions and loss of information by resizing. Photometric interpretation, an attribute that speci- fies the intended interpretation of the raw pixel data were ei- ther MONOCHROME1 or MONOCHROME2. MONOCHROME1 is usually used when the mammogram is intended to be viewed in a white background and MONOCHROME2 is usu- ally used when the mammogram is intended to be viewed in a black background. The author chose to invert all MONOCHROME1 images and keep all MONOCHROME2 im- ages intact, as they display more lesion-based information when viewed by a machine. All original image arrays were normalized to between 0 and 1 for uniformity, and resized into 512 × 512 gray-scale images for consistency. Figure 2. (left) Random sample of a MONOCHROME1 image show- ing the minimum pixel value and (right) the same image after in- verting and normalizing all pixel values to between 0 and 1. 3.3. Feature extraction An EfficientNetV2 [8] with pre-trained weights was used to extract essential features from the images, en- coding them to a 1000-dimensional feature vector. It was developed by researchers at Google [3] that achieved im- proved accuracy and efficiency than conventional Convolu- tional Neural Networks (CNNs), lowering parameter size and execution time by an order of magnitude. An modification of the dataset was later prepared by combining the exported image feature vectors with two meta features: normalized age and implant information. For the purpose of improving predictions, a combination of synthetic under-sampling and over-sampling techniques were also tested for performance. [1]. 3.4. Classification methods These popular machine learning techniques for classifi- cation were trained on this data to derive inference. 3.4.1 Logistic Regression (LR) A simple LR model with L2 regularization was trained on the unbalanced dataset with individually assigned class weights and has been described below. Given Xi as the input feature vector and yi ∈{0, 1} as the target variable for data point i, the probability of the positive class yi = 1 was predicted by the fitted model as: ˆp(Xi) = P(yi = 1|x) = 1 1 + exp(−Xiw −w0) (1) The cost function that was minimized using a solver was: min w C Nn X i=1 (−yilog(ˆp(Xi))− (1 −yi) log(1 −ˆp(Xi))) + 1 2∥x∥2 2 (2) 3.4.2 Support Vector Machine (SVM) For implementing a SVM model, a scalable, input data independent polynomial kernel approximation method [7] was used. Given x, y as input features and d as the polyno- mial kernel degree, a simple kernel function used was: k(x, z) = (γx⊤z + c0)d (3) Next, given that Xi ∈Rd and yi ∈{−1, 1} as the target variable for data point i, the following problem was solved:      minw,b,ξ 1 2∥w∥+ C Pn i=1 ξi such that yi(w⊤k(x, z) + b) ≥1 −ξi ξi ≥0, ∀ i = 1, · · · , n (4) Equivalently formulated, it was written as: min w,b 1 2∥w∥+ C n X i=1 max(0, 1 −yi(w⊤k(x, z) + b)) (5) 3.4.3 Breast-level single-view-single-laterality model A simple deep-neural network was designed to perform in- ference on the ensemble of features described above. • Input: Each 1000×1 vector was fed into an image en- coder part of the network and after two hidden dense layers was concatenated with the feature outputs from a metadata encoder. • Activation: Each intermediate layer had a ReLU ac- tivation function, except for the output layer, where a Sigmoid activation was used. ReLU: f(z) = max(0, z) ∈[0, z] (6) Sigmoid: f(z) = 1 1 + exp(−z) ∈[0, 1] (7) • Loss: The loss with respect to the target variable was calculated using Binary Cross-entropy (BCE) loss, once while using categorical class weights and another without. −1 N N X i=0 yi log( ˆyi) + (1 −yi) log(1 −ˆyi) (8) • Class imbalance: In the latter case, a Straified Batch Sampling (SBS) methodology was used when ran- domly sampling from the dataset during training. SBS = Total sample size Dataset population × Class population (9) • Optimizer: Adam [5] was chosen as the optimizer for our minimization problem. Given η = 0.0003 as ini- tial learning rate, gt as gradient at time t along wj, νt as exponential average of gradients along wj, st as ex- ponential average of squares of gradients along wj and β1, β2 as hyper-parameters: νt = β1νt−1 −(1 −β1)gt (10) st = β2st−1 −(1 −βs)g2 t (11) ∂wt = −η νt √st + ϵgt (12) wt+1 = wt + ∂wt (13) • Metrics: A range of different metrics were tried to un- derstand the maximum efficiency of the model. As for a problem with a class imbalance, accuracy was unreliable because of the major bias towards negative class. In this regard, performances of binary area under the receiver operating characteristic curve (AUROC), binary precision, binary recall, binary F1 score were compared. A comprehensive comparison of these met- rics have been provided in Figure 3. The model was finally evaluated using the probabilis- tic F1 score (pF1) [9] as this extension accepts proba- bilities instead of binary classifications. With px as the probabilistic version of X: pF1 = 2 PprecisionPrecall Pprecision + Precall (14) Pprecision = Ptrue positive Ptrue positive + Pfalse positive (15) Precall = Ptrue positive true positive + false negative (16) Table 2. Simple Single-view-single-laterality model architecture Layer Input Output Parameters SimpleFCN [,1002] [,1] – Sequential: 1-1 [,1000] [,10] – Linear: 2-1 [,1000] [,100] 100, 100 ReLU: 2-2 [,100] [,100] – Linear: 2-3 [,100] [,10] 1, 010 ReLU: 2-4 [,10] [,10] – Linear: 2-3 [,10] [,1] 11 Sigmoid: 2-4 [,1] [,1] – Sequential: 1-2 [,2] [,1] – Linear: 2-5 [,2] [,2] 6 ReLU: 2-6 [,2] [,2] – Linear: 2-7 [,2] [,1] 3 Sigmoid: 2-8 [,1] [,1] – Concatenate: 1-3 [,2] [,1] – Sigmoid: 1-4 [,1] [,1] – The total parameters in the model was estimated at 101, 130, all of which were trainable. The total model size excluding the feature extractor was estimated at 20.56 MB, with input size at 16.42 MB, forward/backward pass size at 3.74 MB and all parameter size at 0.40 MB. Figure 3. Comparison of different evaluation metrics. 4. Results An extensive array of experiments were carried out to estimate the best machine learning model suited for this dataset. This not only included varying hyper-parameters and trying out different models, but also making efforts in transforming, augmenting and generating synthetic data points for the imbalanced classes. Figure 4. Validation loss graph trained for 1000 iterations with breast-level single-view-single-laterality DNN model. The results for pF1 score were compared as well in or- der to have a more holistic view at all the approaches, and served well to gauge different model performances com- pared to each other and state of the art at present. This was due to lack to good test data, lack of sufficient positive classes, and personally, lack of time and resources. Table 3. Probabilistic F-1 scores Model pF1 score State-of-the-art 0.630 Logistic Regression 0.627 Support Vector Machine 0.572 Random Forest Classifier 0.626 Complement Naive Bayes 0.579 Deep Neural Network 0.481 5. Summary As it can be inferred from the above table, the current state of any of the models is not better than 0.50 probability, that is a 50% chance of providing the correct class predic- tion, which is not any better than random chance. Compar- ing the results to the current state-of-the-art shows that the topic needs more correct predictions to be relevant. Other investigations that did not produce significant results include Region-of-interest (ROI) cropping, down- sampling, up-sampling or synthetically generating new samples for the dataset, and almost certainly leading to over-fitting. The rest of the metadata was not part of future test samples, so they were not included as well. Literature survey shows that the use of intense data aug- mentation pipelines and training models externally on sim- ilar datasets work well. This is mainly done to lessen the possibility of detection of false positives due to exposure to more data points in the positive class. There is also strong evidence that networks that capture both spatial and tempo- ral information for a single patient, in a multi-view-multi- lateral model show drastically improved performance. The recent use of transformers for vision tasks has shown signif- icant promise as well, but that calls for further investigation and is also outside the scope of this paper. References [1] Mateusz Buda, Atsuto Maki, and Maciej A. Mazurowski. A systematic study of the class imbalance problem in convolu- tional neural networks. Neural Networks, 106:249–259, oct 2018. 2 [2] George Partridge inversion Jayashree Kalpathy-Cramer John Mongan Katherine Andriole Lavender Maryam Vazirabad Michelle Riopel Robyn Ball Sohier Dane Yan Chen Chris Carr, FelipeKitamura. Rsna screening mammography breast cancer detection, 2022. 1 [3] Mingxing Tan [Staff Software Engineer and Google AI] Quoc V. Le, Principal Scientist. EfficientNet: Improving Accuracy and Efficiency through AutoML and Model Scaling, 5 2019. 2 [4] Llc Innolitics. Digital Mammography X-Ray Image CIOD. 2 [5] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017. 3 [6] World Health Organization. World health organization: Who. (2021). breast cancer., 2021. https://www.who.int/news- room/fact-sheets/detail/breast-cancer. 1 [7] Ninh Pham and Rasmus Pagh. Fast and scalable polynomial kernels via explicit feature maps. In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Dis- covery and Data Mining, KDD ’13, page 239–247, New York, NY, USA, 2013. Association for Computing Machinery. 3 [8] Mingxing Tan and Quoc V. Le. Efficientnetv2: Smaller mod- els and faster training, 2021. 2 [9] Reda Yacouby and Dustin Axman. Probabilistic extension of precision, recall, and f1 score for more thorough evaluation of classification models. In Proceedings of the First Workshop on Evaluation and Comparison of NLP Systems, pages 79– 91, Online, Nov. 2020. Association for Computational Lin- guistics. 3